### Список вопросов к экзамену первого семестра

 * Линейная классификация и регрессия
   - Выписать постановки задач линейной регресии, логистической регрессии
   - Полиномиальная регрессия, гребневая регрессия (RIDGE), LASSO-регрессия
   - Формула модели нейрона МакКаллока-Питтса
   - Метод стохастического градиента. Расписать градиентный шаг для квадратичной функции потерь и сигмоидной функции активации
   - Достоинства и недостатки метода стохастического градиента
   - Формула принципа максимума апостериорной вероятности
   - Постановка задачи многомерной линейной регрессии. Матричная запись
   - Cвязь метода наименьших квадратов и матричного сингулярного разложения
   - Взвешенный метод наименьших квадратов
   - Разложение Холецкого
   - Метод опорных векторов (support vector machine, SVM)
   - Преимущества и недостатки SVM

 * Нелинейные модели машинного обучения
   - Нелинейный метод наименьших квадратов
   - Нелинейное обобщение метода опорных векторов (SVM)
   - Что такое ядро в SVM? Зачем вводятся ядра? Любая ли функция может быть ядром? Какое ядро порождает полиномиальные разделяющие поверхности?

 * Композиции алгоритмов классификации
   - Выписать формулу, определяющую алгоритмическую композицию
   - Какие две эвристики лежат в основе алгоритма AdaBoost? Достоинства и недостатки алгоритма AdaBoost
   - Основная идея бэггинга (bagging)
   - Основная идея метода случайных подпространств (RSM, random subspace method)
   - Сравнение бустинга, бэггинга и метода случайных подпространств

 * Логические алгоритмы классификации
   - Определение логической закономерности. Примеры закономерностей
   - Часто используемые семейства логических правил для составления закономерностей
   - В чём заключается процедура бинаризации признака?
   - Модель классификации на основе решающего дерева
   - Информационный выигрыш, критерии информативности при синтезе решающего дерева
   - Достоинства и недостатки решающих деревьев
   - Построение CART (деревья регрессии и классификации)

 * Метрическая классификация
   - Обобщённый метрический классификатор. Какие вы знаете частные случаи?
   - Метод окна Парзена. В каких случаях его стоит использовать?
   - Метод потенциальных функций
   - Непараметрическая регрессия, формула Надарая-Ватсона
   - На что влияет ширина окна, а на что вид ядра в непараметрической регрессии?
   - Что общего между ядром в непараметрической регрессии и ядром SVM?
   - Что такое «выбросы»? Как осуществляется фильтрация выбросов в непараметрической регрессии?

 * Оценивание качества модели машинного обучения
   - Определения метрик: accuracy, precision, recall. Примеры применения
   - PR-кривая и ROC-кривая: определения и метод построения. Площадь под кривой (AUC)
   - В каких алгоритмах классификации можно узнать не только класс объекта, но и вероятность того, что данный объект принадлежит каждому из классов?
   - Регуляризация, её вероятностный смысл, примеры регуляризаторов
   - Формула логарифма правдоподобия (log-loss)
   - Разложение ошибки на смещение и разброс (bias-variance decomposition)

 * Отбор и преобразования признаков
   - Основная идея отбора признаков методом полного перебора. Действительно ли это полный перебор?
   - Основная идея отбора признаков методом добавлений и исключнений
   - Основная идея отбора признаков методом поиска в ширину
   - Отбор признаков с помощью генетического алгоритма
   - Основные свойства сингулярного разложения
   - Метод главных компонент и его основная теорема

 * Кластеризация и частичное обучение
   - Каковы основные цели кластеризации? Корректная ли это задача? Почему?
   - Постановка задачи частичного обучения
   - Приведите несколько примеров кластерных структур и для каждой из них пример алгоритма кластеризации, который для неё НЕ подходит
   - Какие существуют функционалы качества кластеризации и для чего они применяются?
   - Основная идея алгоритма k-средних и его модификации
   - Что такое дендрограмма? Всегда ли её можно построить?
   - Почему задачи с частичным обучением выделены в отдельный класс? Приведите примеры, когда методы классификации и кластеризации дают неадекватное решение задачи с частичным обучением

 * Нейронные сети
   - Приведите пример выборки, которую невозможно классифицировать без ошибок с помощью линейного алгоритма классификации. Какова минимальная длина выборки, обладающая данным свойством? Какие существуют способы модифицировать линейный алгоритм так, чтобы данная выборка стала линейно разделимой?
   - Алгоритм обратного распространения ошибок. Основная идея. Основные недостатки и способы их устранения
   - Расскажите про обучение по мини-подвыборкам
   - Какие функции активации вы знаете, назовите их преимущества и недостатки

 * Байесовская классификация и ЕМ-алгоритм
   - Формула Байеса, правило суммы и правило произведения для вероятностей
   - Что такое наивный байесовский классификатор?
   - Определение и свойства расстояния Кульбака-Лейблера (KL-дивергенции)
   - Основная идея ЕМ-алгоритма. Какая задача решается на Е-шаге, на М-шаге? Каков вероятностный смысл скрытых переменных?
