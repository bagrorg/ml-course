{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><img src=\"./images/logo_fmkn.png\" width=300 style=\"display: inline-block;\"></center> \n",
    "\n",
    "## Машинное обучение 2\n",
    "### Семинар 6. Тематическое моделирование\n",
    "\n",
    "<br />\n",
    "<br />\n",
    "24 марта 2022"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L21UkIe42j2i",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Введение\n",
    "\n",
    "В данной работе рассмотрены две модели тематического моделирования библиотеки `gensim`:\n",
    "\n",
    "  - Модель LDA (Latent Dirichlet Allocation)\n",
    "  - Модель word2vec\n",
    "\n",
    "Источники вдохновения: \n",
    "\n",
    "  - https://radimrehurek.com/gensim/auto_examples/tutorials/run_lda.html\n",
    "  - https://radimrehurek.com/gensim/auto_examples/tutorials/run_word2vec.html\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L0fw1oPDs6wY",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Модель LDA (Latent Dirichlet Allocation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vUO6BCtnwzUc",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Подготовка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A4CJ6yN-yb28",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Подключаем библиотеку тематического моделирования gensim (http://radimrehurek.com/gensim/) и загружаем библиотеку NLTK (http://nltk.org/), которая понадобится при лемматизации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gensim\n",
      "  Downloading gensim-4.1.2-cp39-cp39-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (24.0 MB)\n",
      "     |████████████████████████████████| 24.0 MB 3.9 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: scipy>=0.18.1 in /home/avalur/mkn_env/lib/python3.9/site-packages (from gensim) (1.7.1)\n",
      "Collecting smart-open>=1.8.1\n",
      "  Downloading smart_open-5.2.1-py3-none-any.whl (58 kB)\n",
      "     |████████████████████████████████| 58 kB 4.7 MB/s             \n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.17.0 in /home/avalur/mkn_env/lib/python3.9/site-packages (from gensim) (1.20.2)\n",
      "Installing collected packages: smart-open, gensim\n",
      "Successfully installed gensim-4.1.2 smart-open-5.2.1\n",
      "\u001b[33mWARNING: You are using pip version 21.3.1; however, version 22.0.3 is available.\n",
      "You should consider upgrading via the '/home/avalur/mkn_env/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: nltk in /home/avalur/mkn_env/lib/python3.9/site-packages (3.6.5)\n",
      "Collecting nltk\n",
      "  Downloading nltk-3.7-py3-none-any.whl (1.5 MB)\n",
      "     |████████████████████████████████| 1.5 MB 3.8 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: joblib in /home/avalur/mkn_env/lib/python3.9/site-packages (from nltk) (1.1.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /home/avalur/mkn_env/lib/python3.9/site-packages (from nltk) (2021.11.10)\n",
      "Requirement already satisfied: tqdm in /home/avalur/mkn_env/lib/python3.9/site-packages (from nltk) (4.62.3)\n",
      "Requirement already satisfied: click in /home/avalur/mkn_env/lib/python3.9/site-packages (from nltk) (8.0.3)\n",
      "Installing collected packages: nltk\n",
      "  Attempting uninstall: nltk\n",
      "    Found existing installation: nltk 3.6.5\n",
      "    Uninstalling nltk-3.6.5:\n",
      "      Successfully uninstalled nltk-3.6.5\n",
      "Successfully installed nltk-3.7\n",
      "\u001b[33mWARNING: You are using pip version 21.3.1; however, version 22.0.3 is available.\n",
      "You should consider upgrading via the '/home/avalur/mkn_env/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade gensim\n",
    "!pip install --upgrade nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "gdyoxngvyleT",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "\n",
    "from gensim import corpora, models, similarities\n",
    "from math import log\n",
    "from time import time\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0MBeC_QT3wz3",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Считываем коллекцию исходных текстов в список документов. Каждый документ — список лемм (токенов). В этом примере мы загружаем всю коллекцию в оперативную память. На самом деле, `gensim` позволяет этого избежать на всех этапах построения модели.\n",
    "\n",
    "Используемая коллекция — статьи с конференции NeurIPS, одна из стандартных коллекций для тематического моделирования. Число документов — около 1700, длина каждого документа в словах 1000-2000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JNi0iXA-1WS1",
    "outputId": "cf89826a-16a6-4100-fd10-4c10151eb683",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import tarfile\n",
    "import re\n",
    "import urllib.request, zipfile\n",
    "\n",
    "\n",
    "tarfile_url = 'https://cs.nyu.edu/~roweis/data/nips12raw_str602.tgz'\n",
    "filename = 'nips12raw_str602.tgz'\n",
    "urllib.request.urlretrieve(tarfile_url, filename)\n",
    "\n",
    "def extract_documents(fname=filename):\n",
    "    with tarfile.open(fname, mode='r:gz') as tar:\n",
    "        # Ignore directory entries, as well as files like README, etc.\n",
    "        files = [\n",
    "            m for m in tar.getmembers()\n",
    "            if m.isfile() and re.search(r'nipstxt/nips\\d+/\\d+\\.txt', m.name)\n",
    "        ]\n",
    "        for member in sorted(files, key=lambda x: x.name):\n",
    "            member_bytes = tar.extractfile(member).read()\n",
    "            yield member_bytes.decode('utf-8', errors='replace')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1740\n",
      "1 \n",
      "CONNECTIVITY VERSUS ENTROPY \n",
      "Yaser S. Abu-Mostafa \n",
      "California Institute of Technology \n",
      "Pasadena, CA 91125 \n",
      "ABSTRACT \n",
      "How does the connectivity of a neural network (number of synapses per \n",
      "neuron) relate to the complexity of the problems it can handle (measured by \n",
      "the entropy)? Switching theory would suggest no relation at all, since all Boolean \n",
      "functions can be implemented using a circuit with very low connectivity (e.g., \n",
      "using two-input NAND gates). However, for a network that learns a pr\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "docs = list(extract_documents())\n",
    "print(len(docs))\n",
    "print(print(docs[0][:500]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q1jWGQ6143kc"
   },
   "source": [
    "Подготовка данных:\n",
    "- строим словарь\n",
    "- делаем лемматизацию\n",
    "- строим n-граммы\n",
    "- отсеиваем слишком часто\\редко встречающиеся токены"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "BPPS5jSN4Fy9"
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "# Split the documents into tokens.\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "for idx in range(len(docs)):\n",
    "    docs[idx] = docs[idx].lower()  # Convert to lowercase.\n",
    "    docs[idx] = tokenizer.tokenize(docs[idx])  # Split into words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "K-kzrHz65gQh",
    "outputId": "fbb1e8cf-3b42-4c95-f75c-deef3efad1d0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5461201\n",
      "5115888\n"
     ]
    }
   ],
   "source": [
    "print(np.sum([len(doc) for doc in docs]))\n",
    "\n",
    "# Remove numbers, but not words that contain numbers.\n",
    "docs = [[token for token in doc if not token.isnumeric()] for doc in docs]\n",
    "\n",
    "print(np.sum([len(doc) for doc in docs]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['stochastic', 'learning', 'networks', 'and', 'their', 'electronic', 'implementation', 'joshua', 'alspector', 'robert', 'b', 'allen', 'victor', 'hut', 'and', 'srinagesh', 'satyanarayana', 'bell', 'communications', 'research', 'morristown', 'nj', 'abstract', 'we', 'describe', 'a', 'family', 'of', 'learning', 'algorithms', 'that', 'operate', 'on', 'a', 'recurrent', 'symmetrically', 'connected', 'neuromorphic', 'network', 'that', 'like', 'the', 'boltzmann', 'machine', 'settles', 'in', 'the', 'presence', 'of', 'noise']\n"
     ]
    }
   ],
   "source": [
    "print(docs[1][:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MQkmqQQ97bIj",
    "outputId": "65967b8f-6af2-462f-b550-525e07f82452"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4629808\n"
     ]
    }
   ],
   "source": [
    "# Remove words that are only one character.\n",
    "docs = [[token for token in doc if len(token) > 1] for doc in docs]\n",
    "print(np.sum([len(doc) for doc in docs]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KSjycOUfGhCw",
    "outputId": "7f6d019c-6f18-4cf3-c6ae-d91cbf923185"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4626035\n"
     ]
    }
   ],
   "source": [
    "docs = [[token for token in doc if '_' not in token] for doc in docs]\n",
    "print(np.sum([len(doc) for doc in docs]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "HUBuhfJNERyR"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/avalur/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
     ]
    }
   ],
   "source": [
    "nltk.download('wordnet')\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WtGLu8yaEkvU",
    "outputId": "77dca455-dd2a-4cbe-f17b-4a5759feaa57"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abstract document\n"
     ]
    }
   ],
   "source": [
    "print(lemmatizer.lemmatize('abstracts'),\n",
    "      lemmatizer.lemmatize('documents'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "fCkF1Hqm50BK"
   },
   "outputs": [],
   "source": [
    "docs = [[lemmatizer.lemmatize(token) for token in doc] for doc in docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mdyb94Br6OZh",
    "outputId": "792d541f-af70-45a3-bcc5-4e37b99add50"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-22 16:24:47,605 : INFO : collecting all words and their counts\n",
      "2022-02-22 16:24:47,606 : INFO : PROGRESS: at sentence #0, processed 0 words and 0 word types\n",
      "2022-02-22 16:24:57,926 : INFO : collected 1114019 token types (unigram + bigrams) from a corpus of 4626035 words and 1740 sentences\n",
      "2022-02-22 16:24:57,927 : INFO : merged Phrases<1114019 vocab, min_count=20, threshold=10.0, max_vocab_size=40000000>\n",
      "2022-02-22 16:24:57,928 : INFO : Phrases lifecycle event {'msg': 'built Phrases<1114019 vocab, min_count=20, threshold=10.0, max_vocab_size=40000000> in 10.32s', 'datetime': '2022-02-22T16:24:57.928760', 'gensim': '4.1.2', 'python': '3.9.7 (default, Nov 25 2021, 21:01:41) \\n[GCC 9.3.0]', 'platform': 'Linux-4.4.0-22000-Microsoft-x86_64-with-glibc2.31', 'event': 'created'}\n"
     ]
    }
   ],
   "source": [
    "# Compute bigrams.\n",
    "from gensim.models import Phrases\n",
    "\n",
    "# Add bigrams to docs (only ones that appear 20 times or more).\n",
    "bigram = Phrases(docs, min_count=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iT1DIBdvG3jq",
    "outputId": "ce101124-b0c0-49b7-e295-ae4ba21c8ac7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abu_mostafa\n",
      "california_institute\n",
      "technology_pasadena\n",
      "ca_abstract\n",
      "neural_network\n",
      "boolean_function\n",
      "can_be\n",
      "very_low\n",
      "learning_rule\n",
      "lower_bound\n"
     ]
    }
   ],
   "source": [
    "for token in bigram[docs[0][:100]]:\n",
    "    if '_' in token:\n",
    "        print(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rBnDw_SwHJvv",
    "outputId": "668b3088-fd02-470c-b612-20b7f277664c"
   },
   "outputs": [],
   "source": [
    "for idx in range(len(docs)):\n",
    "    for token in bigram[docs[idx]]:\n",
    "        if '_' in token:\n",
    "            # Token is a bigram, add to document.\n",
    "            docs[idx].append(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2jHGBhVnHl2h",
    "outputId": "755c1324-0cf8-43f1-b84f-201ec90fa8ac"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-22 16:25:22,772 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2022-02-22 16:25:27,340 : INFO : built Dictionary(77874 unique tokens: ['0a', '2h', '2h2', '2he', '2n']...) from 1740 documents (total 4944899 corpus positions)\n",
      "2022-02-22 16:25:27,341 : INFO : Dictionary lifecycle event {'msg': \"built Dictionary(77874 unique tokens: ['0a', '2h', '2h2', '2he', '2n']...) from 1740 documents (total 4944899 corpus positions)\", 'datetime': '2022-02-22T16:25:27.341599', 'gensim': '4.1.2', 'python': '3.9.7 (default, Nov 25 2021, 21:01:41) \\n[GCC 9.3.0]', 'platform': 'Linux-4.4.0-22000-Microsoft-x86_64-with-glibc2.31', 'event': 'created'}\n"
     ]
    }
   ],
   "source": [
    "from gensim.corpora import Dictionary\n",
    "\n",
    "# Create a dictionary representation of the documents.\n",
    "dictionary = Dictionary(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m7xPnzbJHhpO"
   },
   "source": [
    "Удалим слишком редкие слова (например, опечатки) и слишком частые слова (например, стоп-слова или просто частотные нетематические термины). Функция filter_extremes удаляет из словаря токены, которые встретились менее чем в no_below документов или более чем в доле no_above от общего числа документов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "U51EpaqXHazK",
    "outputId": "6d01d22a-f75b-40ad-88c3-45422c434ac1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-22 16:25:35,231 : INFO : discarding 69258 tokens: [('0a', 19), ('2h', 16), ('2h2', 1), ('2he', 3), ('a', 1740), ('about', 1058), ('abstract', 1740), ('after', 1087), ('alently', 2), ('all', 1658)]...\n",
      "2022-02-22 16:25:35,232 : INFO : keeping 8616 tokens which were in no less than 20 and no more than 870 (=50.0%) documents\n",
      "2022-02-22 16:25:35,297 : INFO : resulting dictionary: Dictionary(8616 unique tokens: ['2n', 'a2', 'a_follows', 'ability', 'abu']...)\n"
     ]
    }
   ],
   "source": [
    "# Remove rare and common tokens\n",
    "# Filter out words that occur less than 20 documents, or more than 50% of the documents.\n",
    "dictionary.filter_extremes(no_below=20, no_above=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FXgntzvDIaSc"
   },
   "source": [
    "Представим все документы в векторном виде (Bag-of-words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "GH6NNGAKH5OD"
   },
   "outputs": [],
   "source": [
    "corpus = [dictionary.doc2bow(doc) for doc in docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2yKG6JJ9Ili4",
    "outputId": "fc7dab88-81ef-4cc9-e96e-921fa7499252"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique tokens: 8616\n",
      "Number of documents: 1740\n"
     ]
    }
   ],
   "source": [
    "print('Number of unique tokens: %d' % len(dictionary))\n",
    "print('Number of documents: %d' % len(corpus))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QGMtwCDqxg8N"
   },
   "source": [
    "## Обучение модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pVCSypJuMt4O"
   },
   "source": [
    "Теперь мы готовы к тому, чтобы строить тематическую модель нашей коллекции. Мы строим модель online LDA, реализованную в библиотеке gensim. Указываем векторизованный корпус текстов, словарь, число тем 10. Остальные параметры обсудим позже."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "gRKTaHpENyAM"
   },
   "outputs": [],
   "source": [
    "id2word = dictionary.id2token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GGrywSb9MvMK",
    "outputId": "cc0be619-05ae-46ca-8546-77cee2305076"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-22 16:25:53,889 : INFO : using autotuned alpha, starting with [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1]\n",
      "2022-02-22 16:25:53,892 : INFO : using serial LDA version on this node\n",
      "2022-02-22 16:25:53,902 : INFO : running online (multi-pass) LDA training, 10 topics, 5 passes over the supplied corpus of 1740 documents, updating model once every 1740 documents, evaluating perplexity every 0 documents, iterating 400x with a convergence threshold of 0.001000\n",
      "2022-02-22 16:25:53,903 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2022-02-22 16:25:53,904 : INFO : PROGRESS: pass 0, at document #1740/1740\n",
      "2022-02-22 16:26:24,637 : INFO : optimized alpha [0.058923192, 0.08117263, 0.10330559, 0.057845123, 0.0694567, 0.07500869, 0.07700171, 0.062445663, 0.08848998, 0.085008636]\n",
      "2022-02-22 16:26:24,650 : INFO : topic #3 (0.058): 0.006*\"image\" + 0.006*\"tree\" + 0.005*\"object\" + 0.004*\"recognition\" + 0.004*\"node\" + 0.003*\"hidden\" + 0.003*\"density\" + 0.003*\"matrix\" + 0.003*\"layer\" + 0.002*\"training_set\"\n",
      "2022-02-22 16:26:24,651 : INFO : topic #0 (0.059): 0.008*\"neuron\" + 0.005*\"cell\" + 0.003*\"layer\" + 0.003*\"response\" + 0.003*\"stimulus\" + 0.003*\"class\" + 0.003*\"rule\" + 0.003*\"field\" + 0.003*\"connection\" + 0.003*\"visual\"\n",
      "2022-02-22 16:26:24,652 : INFO : topic #9 (0.085): 0.007*\"neuron\" + 0.006*\"hidden\" + 0.003*\"noise\" + 0.003*\"layer\" + 0.003*\"field\" + 0.003*\"map\" + 0.003*\"matrix\" + 0.003*\"spike\" + 0.003*\"hidden_unit\" + 0.003*\"kernel\"\n",
      "2022-02-22 16:26:24,654 : INFO : topic #8 (0.088): 0.008*\"image\" + 0.004*\"recognition\" + 0.004*\"neuron\" + 0.003*\"speech\" + 0.003*\"class\" + 0.003*\"rule\" + 0.003*\"hidden\" + 0.003*\"signal\" + 0.002*\"cell\" + 0.002*\"matrix\"\n",
      "2022-02-22 16:26:24,655 : INFO : topic #2 (0.103): 0.004*\"neuron\" + 0.004*\"control\" + 0.003*\"signal\" + 0.003*\"rule\" + 0.003*\"node\" + 0.003*\"layer\" + 0.002*\"net\" + 0.002*\"distance\" + 0.002*\"threshold\" + 0.002*\"dynamic\"\n",
      "2022-02-22 16:26:24,656 : INFO : topic diff=1.175407, rho=1.000000\n",
      "2022-02-22 16:26:24,668 : INFO : PROGRESS: pass 1, at document #1740/1740\n",
      "2022-02-22 16:26:43,312 : INFO : optimized alpha [0.047556438, 0.060918763, 0.07615949, 0.04984976, 0.057425648, 0.06252827, 0.065957226, 0.056727584, 0.07107198, 0.065287255]\n",
      "2022-02-22 16:26:43,322 : INFO : topic #0 (0.048): 0.009*\"neuron\" + 0.004*\"cell\" + 0.004*\"activation\" + 0.003*\"connection\" + 0.003*\"rule\" + 0.003*\"layer\" + 0.003*\"response\" + 0.003*\"dynamic\" + 0.003*\"visual\" + 0.003*\"stimulus\"\n",
      "2022-02-22 16:26:43,324 : INFO : topic #3 (0.050): 0.007*\"image\" + 0.007*\"tree\" + 0.007*\"object\" + 0.005*\"recognition\" + 0.005*\"node\" + 0.003*\"character\" + 0.003*\"hidden\" + 0.003*\"density\" + 0.003*\"class\" + 0.003*\"mixture\"\n",
      "2022-02-22 16:26:43,325 : INFO : topic #6 (0.066): 0.010*\"cell\" + 0.010*\"neuron\" + 0.006*\"response\" + 0.005*\"stimulus\" + 0.005*\"visual\" + 0.004*\"synaptic\" + 0.004*\"activity\" + 0.004*\"control\" + 0.003*\"signal\" + 0.003*\"frequency\"\n",
      "2022-02-22 16:26:43,326 : INFO : topic #8 (0.071): 0.010*\"image\" + 0.006*\"recognition\" + 0.005*\"speech\" + 0.003*\"rule\" + 0.003*\"class\" + 0.003*\"neuron\" + 0.003*\"hidden\" + 0.003*\"word\" + 0.003*\"sequence\" + 0.003*\"signal\"\n",
      "2022-02-22 16:26:43,327 : INFO : topic #2 (0.076): 0.005*\"control\" + 0.003*\"neuron\" + 0.003*\"signal\" + 0.003*\"threshold\" + 0.003*\"rule\" + 0.003*\"dynamic\" + 0.003*\"optimal\" + 0.003*\"node\" + 0.003*\"bound\" + 0.002*\"circuit\"\n",
      "2022-02-22 16:26:43,327 : INFO : topic diff=0.288074, rho=0.577350\n",
      "2022-02-22 16:26:43,337 : INFO : PROGRESS: pass 2, at document #1740/1740\n",
      "2022-02-22 16:26:56,584 : INFO : optimized alpha [0.041221976, 0.051789768, 0.06275501, 0.04503293, 0.05063489, 0.05672078, 0.060094245, 0.05450342, 0.061569247, 0.055977564]\n",
      "2022-02-22 16:26:56,592 : INFO : topic #0 (0.041): 0.010*\"neuron\" + 0.005*\"activation\" + 0.004*\"rule\" + 0.004*\"connection\" + 0.004*\"cell\" + 0.003*\"layer\" + 0.003*\"dynamic\" + 0.003*\"response\" + 0.003*\"visual\" + 0.003*\"field\"\n",
      "2022-02-22 16:26:56,593 : INFO : topic #3 (0.045): 0.009*\"image\" + 0.008*\"object\" + 0.008*\"tree\" + 0.006*\"recognition\" + 0.005*\"node\" + 0.004*\"distance\" + 0.004*\"character\" + 0.003*\"class\" + 0.003*\"mixture\" + 0.003*\"decision\"\n",
      "2022-02-22 16:26:56,594 : INFO : topic #6 (0.060): 0.012*\"cell\" + 0.011*\"neuron\" + 0.007*\"response\" + 0.006*\"stimulus\" + 0.005*\"visual\" + 0.005*\"activity\" + 0.004*\"synaptic\" + 0.004*\"frequency\" + 0.004*\"signal\" + 0.004*\"field\"\n",
      "2022-02-22 16:26:56,595 : INFO : topic #8 (0.062): 0.011*\"image\" + 0.008*\"recognition\" + 0.007*\"speech\" + 0.005*\"word\" + 0.003*\"rule\" + 0.003*\"class\" + 0.003*\"sequence\" + 0.003*\"hidden\" + 0.003*\"signal\" + 0.003*\"hmm\"\n",
      "2022-02-22 16:26:56,596 : INFO : topic #2 (0.063): 0.007*\"control\" + 0.004*\"policy\" + 0.004*\"optimal\" + 0.003*\"threshold\" + 0.003*\"dynamic\" + 0.003*\"action\" + 0.003*\"signal\" + 0.003*\"bound\" + 0.003*\"neuron\" + 0.003*\"rule\"\n",
      "2022-02-22 16:26:56,597 : INFO : topic diff=0.250607, rho=0.500000\n",
      "2022-02-22 16:26:56,603 : INFO : PROGRESS: pass 3, at document #1740/1740\n",
      "2022-02-22 16:27:07,276 : INFO : optimized alpha [0.03735869, 0.046781294, 0.055692915, 0.04185274, 0.046644714, 0.053637836, 0.056776714, 0.053179417, 0.055654924, 0.050899915]\n",
      "2022-02-22 16:27:07,286 : INFO : topic #0 (0.037): 0.010*\"neuron\" + 0.006*\"activation\" + 0.005*\"rule\" + 0.004*\"connection\" + 0.004*\"dynamic\" + 0.003*\"layer\" + 0.003*\"cell\" + 0.003*\"field\" + 0.003*\"response\" + 0.002*\"let\"\n",
      "2022-02-22 16:27:07,288 : INFO : topic #3 (0.042): 0.010*\"image\" + 0.010*\"object\" + 0.009*\"tree\" + 0.007*\"recognition\" + 0.006*\"node\" + 0.005*\"distance\" + 0.005*\"character\" + 0.003*\"class\" + 0.003*\"digit\" + 0.003*\"decision\"\n",
      "2022-02-22 16:27:07,289 : INFO : topic #8 (0.056): 0.012*\"image\" + 0.009*\"recognition\" + 0.008*\"speech\" + 0.006*\"word\" + 0.004*\"class\" + 0.004*\"sequence\" + 0.003*\"rule\" + 0.003*\"hmm\" + 0.003*\"hidden\" + 0.003*\"face\"\n",
      "2022-02-22 16:27:07,291 : INFO : topic #2 (0.056): 0.008*\"control\" + 0.005*\"policy\" + 0.004*\"optimal\" + 0.004*\"dynamic\" + 0.004*\"threshold\" + 0.004*\"action\" + 0.003*\"bound\" + 0.003*\"controller\" + 0.003*\"node\" + 0.003*\"theorem\"\n",
      "2022-02-22 16:27:07,292 : INFO : topic #6 (0.057): 0.012*\"cell\" + 0.012*\"neuron\" + 0.007*\"response\" + 0.006*\"stimulus\" + 0.006*\"visual\" + 0.005*\"activity\" + 0.004*\"synaptic\" + 0.004*\"frequency\" + 0.004*\"signal\" + 0.004*\"spike\"\n",
      "2022-02-22 16:27:07,293 : INFO : topic diff=0.228768, rho=0.447214\n",
      "2022-02-22 16:27:07,307 : INFO : PROGRESS: pass 4, at document #1740/1740\n",
      "2022-02-22 16:27:17,746 : INFO : optimized alpha [0.034935974, 0.043625142, 0.051449496, 0.03975568, 0.044036742, 0.05186537, 0.05475627, 0.052424584, 0.05161011, 0.047824293]\n",
      "2022-02-22 16:27:17,758 : INFO : topic #0 (0.035): 0.010*\"neuron\" + 0.006*\"rule\" + 0.006*\"activation\" + 0.005*\"connection\" + 0.004*\"dynamic\" + 0.003*\"layer\" + 0.003*\"symbol\" + 0.003*\"cell\" + 0.003*\"binding\" + 0.003*\"energy\"\n",
      "2022-02-22 16:27:17,759 : INFO : topic #3 (0.040): 0.011*\"image\" + 0.011*\"object\" + 0.009*\"tree\" + 0.007*\"recognition\" + 0.006*\"node\" + 0.005*\"distance\" + 0.005*\"character\" + 0.004*\"digit\" + 0.004*\"class\" + 0.003*\"decision\"\n",
      "2022-02-22 16:27:17,761 : INFO : topic #5 (0.052): 0.009*\"hidden\" + 0.008*\"layer\" + 0.007*\"net\" + 0.006*\"generalization\" + 0.005*\"classifier\" + 0.005*\"class\" + 0.005*\"hidden_unit\" + 0.004*\"training_set\" + 0.004*\"trained\" + 0.004*\"classification\"\n",
      "2022-02-22 16:27:17,763 : INFO : topic #7 (0.052): 0.006*\"gaussian\" + 0.005*\"matrix\" + 0.005*\"mixture\" + 0.004*\"class\" + 0.004*\"approximation\" + 0.004*\"likelihood\" + 0.004*\"sample\" + 0.004*\"log\" + 0.004*\"prior\" + 0.004*\"bayesian\"\n",
      "2022-02-22 16:27:17,764 : INFO : topic #6 (0.055): 0.013*\"cell\" + 0.012*\"neuron\" + 0.007*\"response\" + 0.007*\"stimulus\" + 0.006*\"visual\" + 0.005*\"activity\" + 0.005*\"synaptic\" + 0.004*\"spike\" + 0.004*\"frequency\" + 0.004*\"field\"\n",
      "2022-02-22 16:27:17,765 : INFO : topic diff=0.215117, rho=0.408248\n",
      "2022-02-22 16:27:17,777 : INFO : LdaModel lifecycle event {'msg': 'trained LdaModel(num_terms=8616, num_topics=10, decay=0.5, chunksize=2000) in 83.87s', 'datetime': '2022-02-22T16:27:17.777066', 'gensim': '4.1.2', 'python': '3.9.7 (default, Nov 25 2021, 21:01:41) \\n[GCC 9.3.0]', 'platform': 'Linux-4.4.0-22000-Microsoft-x86_64-with-glibc2.31', 'event': 'created'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation time: 1.3982077638308208\n"
     ]
    }
   ],
   "source": [
    "start = time()\n",
    "# Set training parameters.\n",
    "num_topics = 10\n",
    "chunksize = 2000  # batch-size\n",
    "passes = 5   # epochs\n",
    "iterations = 400\n",
    "eval_every = None  # Don't evaluate model perplexity, takes too much time.\n",
    "\n",
    "# Make a index to word dictionary.\n",
    "temp = dictionary[0]  # This is only to \"load\" the dictionary.\n",
    "id2word = dictionary.id2token\n",
    "\n",
    "model = models.ldamodel.LdaModel(\n",
    "    corpus=corpus,\n",
    "    id2word=id2word,\n",
    "    chunksize=chunksize,\n",
    "    alpha='auto',\n",
    "    eta='auto',\n",
    "    iterations=iterations,\n",
    "    num_topics=num_topics,\n",
    "    passes=passes,\n",
    "    eval_every=eval_every\n",
    ")\n",
    "print('Evaluation time: {}'.format((time()-start) / 60))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5knApWshObLO"
   },
   "source": [
    "Посмотрим, что получилось. Нас интересует часть матрицы Phi - вероятностей слов в темах. Коллекция NeurIPS вся посвящена машинному обучению. Сложно оценить темы, хотя некоторая интерпретируемость прослеживается."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BJVQU_1rP2f2",
    "outputId": "a2e11a73-e3ff-4313-b926-7de2990f70fb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   neuron      chip     control     image      action     hidden      cell     gaussian    image      neuron  \n",
      "    rule     circuit     policy     object     robot      layer      neuron     matrix  recognition   hidden  \n",
      " activation   analog    optimal      tree    prediction    net      response   mixture     speech     noise   \n",
      " connection   signal     action  recognitionreinforcementgeneralization  stimulus    class       word      matrix  \n",
      "  dynamic     neuron    dynamic      node     control   classifier   visual  approximation  sequence   dynamic  \n",
      "   layer     voltage   threshold   distance    target     class     activity  likelihood   class   hidden_unit\n",
      "   symbol     memory     bound    character     goal   hidden_unit  synaptic    sample      face      kernel  \n",
      "    cell       vlsi     theorem     digit      image   training_set   spike       log        hmm       layer   \n",
      "  binding      cell    controller   class       hand     trained   frequency    prior     context      map    \n",
      "   energy  implementation    node     decision   position classification   field     bayesian     rule        eq    \n"
     ]
    }
   ],
   "source": [
    "for position in range(10):\n",
    "    row = []\n",
    "    for topic in range(10):\n",
    "        row.append(model.show_topic(topic)[position][0].center(11, ' '))\n",
    "    print(''.join(row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hLIuGnNpQpyP",
    "outputId": "8f33e7e4-9250-4898-cebe-db4e1a60c4ec"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-22 16:37:05,231 : INFO : CorpusAccumulator accumulated stats from 1000 documents\n"
     ]
    }
   ],
   "source": [
    "top_topics = model.top_topics(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KQ-5eVhBQrsQ",
    "outputId": "8d47a367-ccf1-4569-be41-f7ec6c372d4a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([(0.0073933867, 'neuron'),\n",
       "  (0.0071649444, 'hidden'),\n",
       "  (0.0054954486, 'noise'),\n",
       "  (0.00519319, 'matrix'),\n",
       "  (0.0041962005, 'dynamic'),\n",
       "  (0.0041336617, 'hidden_unit'),\n",
       "  (0.0035209463, 'kernel'),\n",
       "  (0.0033246516, 'layer'),\n",
       "  (0.003298026, 'map'),\n",
       "  (0.003261122, 'eq'),\n",
       "  (0.0031875812, 'component'),\n",
       "  (0.0030365295, 'solution'),\n",
       "  (0.002856641, 'connection'),\n",
       "  (0.0028020288, 'field'),\n",
       "  (0.0027057056, 'rule'),\n",
       "  (0.002698164, 'fig'),\n",
       "  (0.002629931, 'generalization'),\n",
       "  (0.0024733716, 'optimal'),\n",
       "  (0.0024529216, 'signal'),\n",
       "  (0.002380457, 'dimensional')],\n",
       " -0.9328473022670469)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_topics[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "K-2vzw2RSGFA",
    "outputId": "b4f7c699-b384-430f-83c5-953fe591bf0f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.4935974e-02, 4.3625142e-02, 7.7860468e+02, 3.9755680e-02,\n",
       "        4.4036742e-02, 5.1865373e-02, 5.4756276e-02, 1.9868952e+01,\n",
       "        5.1610108e-02, 4.7824293e-02]], dtype=float32)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.inference([corpus[0]])[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1X-HTzPGxs3F"
   },
   "source": [
    "## Оценка моделей с помощью перплексии"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lsO8NWSdR4Hh"
   },
   "source": [
    "Хочется оценить модель чем-то более убедительным, чем разглядывание профилей тем и профилей документов. Это необходимо для возможноси сравнения разных моделей, например полученных с разными параметрами запуска. Научимся измерять **перплексию**. Функция `model.state.get_lambda` возвращает ненормированную матрицу $\\Phi$, `model.inference` оценивает ненормированную матрицу $\\Theta$ для списка документов. \n",
    "\n",
    "Проходим по коллекции и считаем перплексию по формуле. Чем меньше перплексия, тем лучше."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "8gVV_PFRxmIP"
   },
   "outputs": [],
   "source": [
    "def perplexity(model, corpus):\n",
    "    corpus_length = 0\n",
    "    log_likelihood = 0\n",
    "    topic_profiles = model.state.get_lambda() / np.sum(model.state.get_lambda(), axis=1)[:, np.newaxis]\n",
    "    for document in corpus:\n",
    "        gamma, _ = model.inference([document])\n",
    "        document_profile = gamma / np.sum(gamma)\n",
    "        for term_id, term_count in document:\n",
    "            corpus_length += term_count\n",
    "            term_probability = np.dot(document_profile, topic_profiles[:, term_id])\n",
    "            log_likelihood += term_count * log(term_probability)\n",
    "    perplexity = np.exp(-log_likelihood / corpus_length)\n",
    "    return perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iN6amrvHTDKt",
    "outputId": "a268a642-2efd-4217-b899-cb3abeac1f31"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity: 2769.3908373846953\n"
     ]
    }
   ],
   "source": [
    "print('Perplexity: {}'.format(perplexity(model, corpus)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "k5_Sqil0TPYD",
    "outputId": "df2374d5-d768-4e5e-f741-15eb8ed0f0ea"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-22 16:37:31,649 : INFO : using autotuned alpha, starting with [0.2, 0.2, 0.2, 0.2, 0.2]\n",
      "2022-02-22 16:37:31,653 : INFO : using serial LDA version on this node\n",
      "2022-02-22 16:37:31,659 : INFO : running online (multi-pass) LDA training, 5 topics, 5 passes over the supplied corpus of 1740 documents, updating model once every 1740 documents, evaluating perplexity every 0 documents, iterating 400x with a convergence threshold of 0.001000\n",
      "2022-02-22 16:37:31,660 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2022-02-22 16:37:31,661 : INFO : PROGRESS: pass 0, at document #1740/1740\n",
      "2022-02-22 16:37:54,738 : INFO : optimized alpha [0.17777632, 0.20432077, 0.12614259, 0.07163164, 0.15984705]\n",
      "2022-02-22 16:37:54,745 : INFO : topic #0 (0.178): 0.003*\"neuron\" + 0.003*\"image\" + 0.003*\"recognition\" + 0.003*\"classifier\" + 0.003*\"word\" + 0.003*\"matrix\" + 0.003*\"class\" + 0.003*\"node\" + 0.003*\"memory\" + 0.003*\"layer\"\n",
      "2022-02-22 16:37:54,747 : INFO : topic #1 (0.204): 0.006*\"neuron\" + 0.004*\"signal\" + 0.004*\"cell\" + 0.003*\"class\" + 0.003*\"noise\" + 0.003*\"layer\" + 0.003*\"hidden\" + 0.003*\"matrix\" + 0.002*\"image\" + 0.002*\"optimal\"\n",
      "2022-02-22 16:37:54,748 : INFO : topic #2 (0.126): 0.005*\"hidden\" + 0.004*\"net\" + 0.004*\"layer\" + 0.003*\"image\" + 0.003*\"neuron\" + 0.003*\"recognition\" + 0.003*\"cell\" + 0.003*\"speech\" + 0.002*\"object\" + 0.002*\"signal\"\n",
      "2022-02-22 16:37:54,750 : INFO : topic #3 (0.072): 0.005*\"image\" + 0.004*\"rule\" + 0.003*\"noise\" + 0.003*\"neuron\" + 0.003*\"node\" + 0.003*\"class\" + 0.003*\"action\" + 0.002*\"response\" + 0.002*\"memory\" + 0.002*\"optimal\"\n",
      "2022-02-22 16:37:54,751 : INFO : topic #4 (0.160): 0.005*\"image\" + 0.004*\"layer\" + 0.004*\"neuron\" + 0.004*\"cell\" + 0.004*\"control\" + 0.003*\"field\" + 0.003*\"map\" + 0.003*\"visual\" + 0.003*\"response\" + 0.002*\"node\"\n",
      "2022-02-22 16:37:54,752 : INFO : topic diff=1.049644, rho=1.000000\n",
      "2022-02-22 16:37:54,760 : INFO : PROGRESS: pass 1, at document #1740/1740\n",
      "2022-02-22 16:38:09,714 : INFO : optimized alpha [0.09315672, 0.102232285, 0.089771375, 0.06176234, 0.10476385]\n",
      "2022-02-22 16:38:09,720 : INFO : topic #0 (0.093): 0.003*\"class\" + 0.003*\"classifier\" + 0.003*\"matrix\" + 0.003*\"node\" + 0.003*\"word\" + 0.003*\"gaussian\" + 0.003*\"recognition\" + 0.003*\"memory\" + 0.003*\"sample\" + 0.003*\"generalization\"\n",
      "2022-02-22 16:38:09,721 : INFO : topic #1 (0.102): 0.007*\"neuron\" + 0.005*\"signal\" + 0.004*\"noise\" + 0.004*\"cell\" + 0.003*\"matrix\" + 0.003*\"spike\" + 0.003*\"class\" + 0.003*\"hidden\" + 0.003*\"dynamic\" + 0.003*\"layer\"\n",
      "2022-02-22 16:38:09,723 : INFO : topic #2 (0.090): 0.006*\"hidden\" + 0.004*\"net\" + 0.004*\"layer\" + 0.004*\"recognition\" + 0.004*\"speech\" + 0.004*\"image\" + 0.003*\"hidden_unit\" + 0.003*\"object\" + 0.003*\"trained\" + 0.002*\"class\"\n",
      "2022-02-22 16:38:09,724 : INFO : topic #3 (0.062): 0.005*\"rule\" + 0.005*\"image\" + 0.004*\"action\" + 0.003*\"policy\" + 0.003*\"node\" + 0.003*\"optimal\" + 0.003*\"class\" + 0.003*\"noise\" + 0.003*\"face\" + 0.002*\"memory\"\n",
      "2022-02-22 16:38:09,725 : INFO : topic #4 (0.105): 0.006*\"cell\" + 0.006*\"neuron\" + 0.005*\"image\" + 0.004*\"layer\" + 0.004*\"control\" + 0.004*\"field\" + 0.004*\"visual\" + 0.004*\"response\" + 0.003*\"map\" + 0.003*\"circuit\"\n",
      "2022-02-22 16:38:09,726 : INFO : topic diff=0.194457, rho=0.577350\n",
      "2022-02-22 16:38:09,733 : INFO : PROGRESS: pass 2, at document #1740/1740\n",
      "2022-02-22 16:38:20,403 : INFO : optimized alpha [0.076478794, 0.08285691, 0.077720955, 0.054791342, 0.08748678]\n",
      "2022-02-22 16:38:20,409 : INFO : topic #0 (0.076): 0.004*\"class\" + 0.003*\"classifier\" + 0.003*\"gaussian\" + 0.003*\"sample\" + 0.003*\"node\" + 0.003*\"matrix\" + 0.003*\"generalization\" + 0.003*\"hidden\" + 0.003*\"bound\" + 0.003*\"component\"\n",
      "2022-02-22 16:38:20,410 : INFO : topic #1 (0.083): 0.008*\"neuron\" + 0.005*\"signal\" + 0.004*\"noise\" + 0.004*\"matrix\" + 0.004*\"spike\" + 0.003*\"cell\" + 0.003*\"dynamic\" + 0.003*\"class\" + 0.003*\"approximation\" + 0.002*\"hidden\"\n",
      "2022-02-22 16:38:20,412 : INFO : topic #2 (0.078): 0.006*\"hidden\" + 0.005*\"layer\" + 0.005*\"recognition\" + 0.005*\"net\" + 0.004*\"speech\" + 0.004*\"image\" + 0.003*\"hidden_unit\" + 0.003*\"trained\" + 0.003*\"word\" + 0.003*\"class\"\n",
      "2022-02-22 16:38:20,413 : INFO : topic #3 (0.055): 0.006*\"rule\" + 0.005*\"action\" + 0.005*\"image\" + 0.004*\"policy\" + 0.003*\"optimal\" + 0.003*\"face\" + 0.003*\"node\" + 0.003*\"class\" + 0.003*\"reinforcement\" + 0.002*\"memory\"\n",
      "2022-02-22 16:38:20,414 : INFO : topic #4 (0.087): 0.007*\"cell\" + 0.007*\"neuron\" + 0.005*\"image\" + 0.005*\"field\" + 0.005*\"visual\" + 0.005*\"control\" + 0.004*\"response\" + 0.004*\"layer\" + 0.003*\"map\" + 0.003*\"circuit\"\n",
      "2022-02-22 16:38:20,415 : INFO : topic diff=0.166147, rho=0.500000\n",
      "2022-02-22 16:38:20,422 : INFO : PROGRESS: pass 3, at document #1740/1740\n",
      "2022-02-22 16:38:29,284 : INFO : optimized alpha [0.06854149, 0.07278337, 0.071962245, 0.05003065, 0.078696966]\n",
      "2022-02-22 16:38:29,287 : INFO : topic #0 (0.069): 0.004*\"class\" + 0.004*\"gaussian\" + 0.004*\"sample\" + 0.003*\"classifier\" + 0.003*\"node\" + 0.003*\"matrix\" + 0.003*\"generalization\" + 0.003*\"mixture\" + 0.003*\"bound\" + 0.003*\"hidden\"\n",
      "2022-02-22 16:38:29,288 : INFO : topic #1 (0.073): 0.008*\"neuron\" + 0.005*\"signal\" + 0.005*\"noise\" + 0.004*\"spike\" + 0.004*\"matrix\" + 0.003*\"dynamic\" + 0.003*\"approximation\" + 0.003*\"cell\" + 0.002*\"class\" + 0.002*\"component\"\n",
      "2022-02-22 16:38:29,289 : INFO : topic #2 (0.072): 0.007*\"hidden\" + 0.006*\"recognition\" + 0.005*\"layer\" + 0.005*\"net\" + 0.005*\"speech\" + 0.004*\"image\" + 0.003*\"word\" + 0.003*\"hidden_unit\" + 0.003*\"trained\" + 0.003*\"classification\"\n",
      "2022-02-22 16:38:29,291 : INFO : topic #3 (0.050): 0.006*\"action\" + 0.006*\"rule\" + 0.005*\"image\" + 0.005*\"policy\" + 0.004*\"optimal\" + 0.003*\"reinforcement\" + 0.003*\"face\" + 0.003*\"node\" + 0.003*\"graph\" + 0.003*\"reinforcement_learning\"\n",
      "2022-02-22 16:38:29,292 : INFO : topic #4 (0.079): 0.008*\"cell\" + 0.008*\"neuron\" + 0.005*\"visual\" + 0.005*\"response\" + 0.005*\"field\" + 0.005*\"image\" + 0.005*\"control\" + 0.004*\"layer\" + 0.004*\"circuit\" + 0.003*\"map\"\n",
      "2022-02-22 16:38:29,293 : INFO : topic diff=0.140422, rho=0.447214\n",
      "2022-02-22 16:38:29,299 : INFO : PROGRESS: pass 4, at document #1740/1740\n",
      "2022-02-22 16:38:37,259 : INFO : optimized alpha [0.06396645, 0.0673293, 0.06907269, 0.04687484, 0.07333405]\n",
      "2022-02-22 16:38:37,263 : INFO : topic #0 (0.064): 0.004*\"class\" + 0.004*\"gaussian\" + 0.004*\"sample\" + 0.003*\"classifier\" + 0.003*\"mixture\" + 0.003*\"node\" + 0.003*\"matrix\" + 0.003*\"generalization\" + 0.003*\"bound\" + 0.003*\"hidden\"\n",
      "2022-02-22 16:38:37,265 : INFO : topic #1 (0.067): 0.009*\"neuron\" + 0.005*\"signal\" + 0.005*\"noise\" + 0.004*\"matrix\" + 0.004*\"spike\" + 0.003*\"dynamic\" + 0.003*\"approximation\" + 0.003*\"component\" + 0.003*\"let\" + 0.002*\"threshold\"\n",
      "2022-02-22 16:38:37,266 : INFO : topic #2 (0.069): 0.007*\"hidden\" + 0.006*\"recognition\" + 0.006*\"layer\" + 0.005*\"net\" + 0.005*\"speech\" + 0.004*\"image\" + 0.004*\"word\" + 0.004*\"trained\" + 0.004*\"hidden_unit\" + 0.003*\"classification\"\n",
      "2022-02-22 16:38:37,267 : INFO : topic #3 (0.047): 0.007*\"action\" + 0.006*\"rule\" + 0.005*\"policy\" + 0.005*\"image\" + 0.004*\"optimal\" + 0.004*\"reinforcement\" + 0.004*\"face\" + 0.003*\"control\" + 0.003*\"reinforcement_learning\" + 0.003*\"graph\"\n",
      "2022-02-22 16:38:37,268 : INFO : topic #4 (0.073): 0.009*\"cell\" + 0.008*\"neuron\" + 0.005*\"visual\" + 0.005*\"response\" + 0.005*\"field\" + 0.005*\"image\" + 0.004*\"control\" + 0.004*\"layer\" + 0.004*\"stimulus\" + 0.004*\"circuit\"\n",
      "2022-02-22 16:38:37,268 : INFO : topic diff=0.121090, rho=0.408248\n",
      "2022-02-22 16:38:37,274 : INFO : LdaModel lifecycle event {'msg': 'trained LdaModel(num_terms=8616, num_topics=5, decay=0.5, chunksize=2000) in 65.61s', 'datetime': '2022-02-22T16:38:37.274454', 'gensim': '4.1.2', 'python': '3.9.7 (default, Nov 25 2021, 21:01:41) \\n[GCC 9.3.0]', 'platform': 'Linux-4.4.0-22000-Microsoft-x86_64-with-glibc2.31', 'event': 'created'}\n",
      "2022-02-22 16:38:37,275 : INFO : using autotuned alpha, starting with [0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05]\n",
      "2022-02-22 16:38:37,277 : INFO : using serial LDA version on this node\n",
      "2022-02-22 16:38:37,302 : INFO : running online (multi-pass) LDA training, 20 topics, 5 passes over the supplied corpus of 1740 documents, updating model once every 1740 documents, evaluating perplexity every 0 documents, iterating 400x with a convergence threshold of 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-22 16:38:37,303 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2022-02-22 16:38:37,304 : INFO : PROGRESS: pass 0, at document #1740/1740\n",
      "2022-02-22 16:39:11,777 : INFO : optimized alpha [0.038862128, 0.05100475, 0.047491785, 0.048265025, 0.038935926, 0.04641892, 0.04216214, 0.032821245, 0.044396333, 0.04052047, 0.043786053, 0.038821142, 0.040446002, 0.04046346, 0.048172873, 0.04609909, 0.045116663, 0.03775596, 0.044976816, 0.040786207]\n",
      "2022-02-22 16:39:11,805 : INFO : topic #7 (0.033): 0.008*\"cell\" + 0.004*\"rule\" + 0.004*\"control\" + 0.004*\"correlation\" + 0.003*\"neuron\" + 0.003*\"spline\" + 0.003*\"muscle\" + 0.003*\"potential\" + 0.003*\"stimulus\" + 0.003*\"phase\"\n",
      "2022-02-22 16:39:11,806 : INFO : topic #17 (0.038): 0.008*\"hidden\" + 0.005*\"control\" + 0.005*\"policy\" + 0.004*\"hidden_unit\" + 0.004*\"optimal\" + 0.003*\"layer\" + 0.003*\"noise\" + 0.003*\"object\" + 0.003*\"action\" + 0.003*\"net\"\n",
      "2022-02-22 16:39:11,808 : INFO : topic #14 (0.048): 0.005*\"image\" + 0.004*\"recognition\" + 0.004*\"net\" + 0.004*\"hidden\" + 0.003*\"layer\" + 0.003*\"distance\" + 0.003*\"mixture\" + 0.003*\"sample\" + 0.003*\"class\" + 0.003*\"neuron\"\n",
      "2022-02-22 16:39:11,809 : INFO : topic #3 (0.048): 0.006*\"signal\" + 0.005*\"neuron\" + 0.005*\"image\" + 0.004*\"cell\" + 0.004*\"spike\" + 0.004*\"noise\" + 0.003*\"density\" + 0.003*\"component\" + 0.003*\"visual\" + 0.002*\"dynamic\"\n",
      "2022-02-22 16:39:11,810 : INFO : topic #1 (0.051): 0.005*\"class\" + 0.004*\"node\" + 0.004*\"optimal\" + 0.003*\"memory\" + 0.003*\"solution\" + 0.003*\"layer\" + 0.003*\"hidden\" + 0.003*\"dynamic\" + 0.003*\"control\" + 0.003*\"sample\"\n",
      "2022-02-22 16:39:11,811 : INFO : topic diff=1.810754, rho=1.000000\n",
      "2022-02-22 16:39:11,827 : INFO : PROGRESS: pass 1, at document #1740/1740\n",
      "2022-02-22 16:39:31,418 : INFO : optimized alpha [0.033851374, 0.04867345, 0.04459871, 0.042875595, 0.034988027, 0.041027743, 0.037707616, 0.02816142, 0.03973553, 0.036986597, 0.038942795, 0.035382476, 0.034878522, 0.035381243, 0.044777006, 0.039940253, 0.04030937, 0.034415722, 0.04035116, 0.0366272]\n",
      "2022-02-22 16:39:31,444 : INFO : topic #7 (0.028): 0.012*\"cell\" + 0.005*\"spline\" + 0.005*\"rule\" + 0.005*\"lesion\" + 0.005*\"correlation\" + 0.004*\"muscle\" + 0.004*\"potential\" + 0.004*\"fuzzy\" + 0.004*\"control\" + 0.004*\"interval\"\n",
      "2022-02-22 16:39:31,446 : INFO : topic #0 (0.034): 0.005*\"cell\" + 0.005*\"connection\" + 0.004*\"layer\" + 0.004*\"neuron\" + 0.004*\"region\" + 0.004*\"net\" + 0.003*\"visual\" + 0.003*\"target\" + 0.003*\"language\" + 0.003*\"human\"\n",
      "2022-02-22 16:39:31,448 : INFO : topic #2 (0.045): 0.004*\"gaussian\" + 0.004*\"noise\" + 0.004*\"image\" + 0.003*\"estimate\" + 0.003*\"map\" + 0.003*\"xi\" + 0.003*\"class\" + 0.003*\"prediction\" + 0.002*\"stochastic\" + 0.002*\"bound\"\n",
      "2022-02-22 16:39:31,450 : INFO : topic #14 (0.045): 0.006*\"image\" + 0.005*\"recognition\" + 0.004*\"distance\" + 0.004*\"net\" + 0.004*\"hidden\" + 0.004*\"mixture\" + 0.003*\"density\" + 0.003*\"class\" + 0.003*\"layer\" + 0.003*\"em\"\n",
      "2022-02-22 16:39:31,451 : INFO : topic #1 (0.049): 0.006*\"class\" + 0.005*\"node\" + 0.005*\"optimal\" + 0.004*\"bound\" + 0.003*\"solution\" + 0.003*\"layer\" + 0.003*\"hidden\" + 0.003*\"generalization\" + 0.003*\"sample\" + 0.003*\"memory\"\n",
      "2022-02-22 16:39:31,452 : INFO : topic diff=0.531913, rho=0.577350\n",
      "2022-02-22 16:39:31,473 : INFO : PROGRESS: pass 2, at document #1740/1740\n",
      "2022-02-22 16:39:46,696 : INFO : optimized alpha [0.030527325, 0.046618585, 0.043602005, 0.03902956, 0.032641254, 0.036935262, 0.035144877, 0.025366163, 0.036807045, 0.035123076, 0.03636228, 0.03377116, 0.03144106, 0.031912163, 0.04252684, 0.036010563, 0.03732918, 0.032584637, 0.037259415, 0.03408374]\n",
      "2022-02-22 16:39:46,720 : INFO : topic #7 (0.025): 0.013*\"cell\" + 0.008*\"spline\" + 0.006*\"rule\" + 0.006*\"lesion\" + 0.005*\"correlation\" + 0.005*\"muscle\" + 0.005*\"potential\" + 0.005*\"fuzzy\" + 0.005*\"interval\" + 0.004*\"membrane\"\n",
      "2022-02-22 16:39:46,722 : INFO : topic #0 (0.031): 0.005*\"connection\" + 0.005*\"cell\" + 0.005*\"region\" + 0.005*\"layer\" + 0.004*\"net\" + 0.004*\"neuron\" + 0.004*\"language\" + 0.004*\"receptor\" + 0.004*\"target\" + 0.003*\"protein\"\n",
      "2022-02-22 16:39:46,723 : INFO : topic #14 (0.043): 0.007*\"image\" + 0.006*\"recognition\" + 0.005*\"distance\" + 0.004*\"class\" + 0.004*\"hidden\" + 0.004*\"mixture\" + 0.004*\"net\" + 0.003*\"density\" + 0.003*\"em\" + 0.003*\"character\"\n",
      "2022-02-22 16:39:46,724 : INFO : topic #2 (0.044): 0.005*\"gaussian\" + 0.004*\"noise\" + 0.004*\"estimate\" + 0.003*\"xi\" + 0.003*\"prediction\" + 0.003*\"approximation\" + 0.003*\"stochastic\" + 0.003*\"matrix\" + 0.003*\"cluster\" + 0.003*\"map\"\n",
      "2022-02-22 16:39:46,725 : INFO : topic #1 (0.047): 0.006*\"class\" + 0.005*\"node\" + 0.005*\"bound\" + 0.005*\"optimal\" + 0.004*\"generalization\" + 0.004*\"solution\" + 0.003*\"layer\" + 0.003*\"hidden\" + 0.003*\"dimension\" + 0.003*\"sample\"\n",
      "2022-02-22 16:39:46,727 : INFO : topic diff=0.526407, rho=0.500000\n",
      "2022-02-22 16:39:46,748 : INFO : PROGRESS: pass 3, at document #1740/1740\n",
      "2022-02-22 16:39:59,827 : INFO : optimized alpha [0.028169567, 0.045416564, 0.04338347, 0.036309473, 0.031194063, 0.033987097, 0.033628356, 0.023418404, 0.03503689, 0.03399153, 0.035110675, 0.03293317, 0.029030181, 0.029392803, 0.041069146, 0.033395566, 0.035432603, 0.031195596, 0.03508821, 0.032348014]\n",
      "2022-02-22 16:39:59,852 : INFO : topic #7 (0.023): 0.013*\"cell\" + 0.010*\"spline\" + 0.007*\"rule\" + 0.007*\"lesion\" + 0.006*\"correlation\" + 0.005*\"fuzzy\" + 0.005*\"interval\" + 0.005*\"potential\" + 0.005*\"muscle\" + 0.005*\"basis\"\n",
      "2022-02-22 16:39:59,854 : INFO : topic #0 (0.028): 0.005*\"region\" + 0.005*\"connection\" + 0.005*\"cell\" + 0.005*\"layer\" + 0.004*\"protein\" + 0.004*\"receptor\" + 0.004*\"net\" + 0.004*\"language\" + 0.004*\"target\" + 0.004*\"human\"\n",
      "2022-02-22 16:39:59,855 : INFO : topic #14 (0.041): 0.008*\"image\" + 0.007*\"recognition\" + 0.005*\"distance\" + 0.004*\"character\" + 0.004*\"class\" + 0.003*\"hidden\" + 0.003*\"net\" + 0.003*\"digit\" + 0.003*\"mixture\" + 0.003*\"em\"\n",
      "2022-02-22 16:39:59,856 : INFO : topic #2 (0.043): 0.006*\"gaussian\" + 0.004*\"noise\" + 0.004*\"estimate\" + 0.003*\"xi\" + 0.003*\"approximation\" + 0.003*\"prediction\" + 0.003*\"matrix\" + 0.003*\"prior\" + 0.003*\"variance\" + 0.003*\"stochastic\"\n",
      "2022-02-22 16:39:59,857 : INFO : topic #1 (0.045): 0.006*\"class\" + 0.006*\"bound\" + 0.005*\"node\" + 0.005*\"optimal\" + 0.005*\"generalization\" + 0.004*\"solution\" + 0.004*\"theorem\" + 0.004*\"dimension\" + 0.004*\"let\" + 0.004*\"layer\"\n",
      "2022-02-22 16:39:59,859 : INFO : topic diff=0.525085, rho=0.447214\n",
      "2022-02-22 16:39:59,879 : INFO : PROGRESS: pass 4, at document #1740/1740\n",
      "2022-02-22 16:40:11,665 : INFO : optimized alpha [0.026436312, 0.044816233, 0.04357872, 0.034303747, 0.030225728, 0.031832483, 0.032643326, 0.022018243, 0.033936262, 0.03329948, 0.034689024, 0.032512628, 0.02726327, 0.027452642, 0.04003967, 0.031579997, 0.034166064, 0.030047826, 0.033498555, 0.031192908]\n",
      "2022-02-22 16:40:11,693 : INFO : topic #7 (0.022): 0.013*\"cell\" + 0.012*\"spline\" + 0.008*\"rule\" + 0.007*\"lesion\" + 0.006*\"basis\" + 0.006*\"fuzzy\" + 0.006*\"correlation\" + 0.006*\"interval\" + 0.005*\"basis_function\" + 0.005*\"potential\"\n",
      "2022-02-22 16:40:11,694 : INFO : topic #0 (0.026): 0.006*\"region\" + 0.005*\"protein\" + 0.005*\"connection\" + 0.005*\"receptor\" + 0.005*\"layer\" + 0.005*\"cell\" + 0.005*\"net\" + 0.004*\"language\" + 0.004*\"target\" + 0.004*\"human\"\n",
      "2022-02-22 16:40:11,696 : INFO : topic #14 (0.040): 0.008*\"image\" + 0.007*\"recognition\" + 0.006*\"distance\" + 0.005*\"character\" + 0.004*\"class\" + 0.004*\"digit\" + 0.003*\"net\" + 0.003*\"hidden\" + 0.003*\"sample\" + 0.003*\"tangent\"\n",
      "2022-02-22 16:40:11,697 : INFO : topic #2 (0.044): 0.006*\"gaussian\" + 0.005*\"noise\" + 0.004*\"estimate\" + 0.004*\"approximation\" + 0.004*\"xi\" + 0.003*\"matrix\" + 0.003*\"prior\" + 0.003*\"variance\" + 0.003*\"prediction\" + 0.003*\"bayesian\"\n",
      "2022-02-22 16:40:11,698 : INFO : topic #1 (0.045): 0.006*\"bound\" + 0.006*\"class\" + 0.005*\"node\" + 0.005*\"generalization\" + 0.005*\"optimal\" + 0.004*\"theorem\" + 0.004*\"let\" + 0.004*\"dimension\" + 0.004*\"solution\" + 0.004*\"hidden\"\n",
      "2022-02-22 16:40:11,699 : INFO : topic diff=0.521076, rho=0.408248\n",
      "2022-02-22 16:40:11,722 : INFO : LdaModel lifecycle event {'msg': 'trained LdaModel(num_terms=8616, num_topics=20, decay=0.5, chunksize=2000) in 94.42s', 'datetime': '2022-02-22T16:40:11.722232', 'gensim': '4.1.2', 'python': '3.9.7 (default, Nov 25 2021, 21:01:41) \\n[GCC 9.3.0]', 'platform': 'Linux-4.4.0-22000-Microsoft-x86_64-with-glibc2.31', 'event': 'created'}\n"
     ]
    }
   ],
   "source": [
    "model_5 = models.ldamodel.LdaModel(\n",
    "    corpus=corpus,\n",
    "    id2word=id2word,\n",
    "    chunksize=chunksize,\n",
    "    alpha='auto',\n",
    "    eta='auto',\n",
    "    iterations=iterations,\n",
    "    num_topics=5,\n",
    "    passes=passes,\n",
    "    eval_every=eval_every\n",
    ")\n",
    "model_20 = models.ldamodel.LdaModel(\n",
    "    corpus=corpus,\n",
    "    id2word=id2word,\n",
    "    chunksize=chunksize,\n",
    "    alpha='auto',\n",
    "    eta='auto',\n",
    "    iterations=iterations,\n",
    "    num_topics=20,\n",
    "    passes=passes,\n",
    "    eval_every=eval_every\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LYR1kXEFTWMg",
    "outputId": "2463aa3f-b0d7-4980-dcdf-43e7f62e41c7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity 5: 3071.2870198514443\n",
      "Perplexity 20: 2515.209696656869\n"
     ]
    }
   ],
   "source": [
    "print('Perplexity 5: {}'.format(perplexity(model_5, corpus)))\n",
    "print('Perplexity 20: {}'.format(perplexity(model_20, corpus)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n5yh-RhCxwcT"
   },
   "source": [
    "# Модель Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lg2OEYLpUU5u"
   },
   "source": [
    "Word2Vec — одна из основных нейросетевых моделей в «дотрансформерную» эпоху (2013-2018). Суть модели в построении отображения слов в $N$-мерное пространство (embeddings), имеющее определенные характеристики. Два слова имеют тем более близкие эмбеддинги, чем в более схожих контекстах они употребляются.\n",
    "\n",
    "В библиотеке `gensim` реализовано два метода построения word2vec:\n",
    "\n",
    "  - Skip-grams (SG)\n",
    "  - Continuous-bag-of-words (CBOW)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aYtz7rDrVyKS"
   },
   "source": [
    "## Demo готовой модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Oom3Pnc4V36e"
   },
   "source": [
    "Для демонстрации возьмем готовую модель, обученную на Google News dataset, содержащая ~3M английских слов и фраз."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gTcMvyG1V1wH",
    "outputId": "e1aac14d-a61b-4876-84e4-7a751e10ddaf"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-22 16:40:52,058 : INFO : Creating /home/avalur/gensim-data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[=================================================-] 99.9% 1661.5/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-22 16:45:17,215 : INFO : word2vec-google-news-300 downloaded\n",
      "2022-02-22 16:45:17,227 : INFO : loading projection weights from /home/avalur/gensim-data/word2vec-google-news-300/word2vec-google-news-300.gz\n",
      "2022-02-22 16:47:00,218 : INFO : KeyedVectors lifecycle event {'msg': 'loaded (3000000, 300) matrix of type float32 from /home/avalur/gensim-data/word2vec-google-news-300/word2vec-google-news-300.gz', 'binary': True, 'encoding': 'utf8', 'datetime': '2022-02-22T16:47:00.218484', 'gensim': '4.1.2', 'python': '3.9.7 (default, Nov 25 2021, 21:01:41) \\n[GCC 9.3.0]', 'platform': 'Linux-4.4.0-22000-Microsoft-x86_64-with-glibc2.31', 'event': 'load_word2vec_format'}\n"
     ]
    }
   ],
   "source": [
    "import gensim.downloader as api\n",
    "wv = api.load('word2vec-google-news-300')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-gUr1QvQWCg_",
    "outputId": "5fdde298-1dfe-4067-b132-b95e91e7c6da"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word #0/3000000 is </s>\n",
      "word #1/3000000 is in\n",
      "word #2/3000000 is for\n",
      "word #3/3000000 is that\n",
      "word #4/3000000 is is\n",
      "word #5/3000000 is on\n",
      "word #6/3000000 is ##\n",
      "word #7/3000000 is The\n",
      "word #8/3000000 is with\n",
      "word #9/3000000 is said\n"
     ]
    }
   ],
   "source": [
    "for index, word in enumerate(wv.index_to_key):\n",
    "    if index == 10:\n",
    "        break\n",
    "    print(f\"word #{index}/{len(wv.index_to_key )} is {word}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dqif1gRDYQA7"
   },
   "source": [
    "Возьмем вектор слова king"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ewckl1qAX7Cp",
    "outputId": "f7c5715c-3273-4933-f98b-ba68ca0616fd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.12597656  0.02978516  0.00860596  0.13964844 -0.02563477 -0.03613281\n",
      "  0.11181641 -0.19824219  0.05126953  0.36328125]\n"
     ]
    }
   ],
   "source": [
    "vec_king = wv['king']\n",
    "print(vec_king[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KqFjb72RYijh"
   },
   "source": [
    "При помощи модели можно считать расстояния до других слов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "359E_KR7YcQG",
    "outputId": "1cfcd100-166f-4efe-94aa-f7a0c0c21817"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'car'\t'minivan'\t0.69\n",
      "'car'\t'bicycle'\t0.54\n",
      "'car'\t'airplane'\t0.42\n",
      "'car'\t'cereal'\t0.14\n",
      "'car'\t'communism'\t0.06\n"
     ]
    }
   ],
   "source": [
    "pairs = [\n",
    "    ('car', 'minivan'),   # a minivan is a kind of car\n",
    "    ('car', 'bicycle'),   # still a wheeled vehicle\n",
    "    ('car', 'airplane'),  # ok, no wheels, but still a vehicle\n",
    "    ('car', 'cereal'),    # ... and so on\n",
    "    ('car', 'communism'),\n",
    "]\n",
    "for w1, w2 in pairs:\n",
    "    print('%r\\t%r\\t%.2f' % (w1, w2, wv.similarity(w1, w2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ofdJmw4mYqKz"
   },
   "source": [
    "Или находить наиболее близкие по смыслу слова"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 166
    },
    "id": "OJ1Gj7JMYtvp",
    "outputId": "c4ebce20-8cb3-41cb-bcc4-0cc2617b037d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('SUV', 0.8532191514968872), ('vehicle', 0.8175784349441528), ('pickup_truck', 0.7763689756393433), ('Jeep', 0.7567334175109863), ('Ford_Explorer', 0.7565719485282898)]\n"
     ]
    }
   ],
   "source": [
    "print(wv.most_similar(positive=['car', 'minivan'], topn=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('king', 0.8449392914772034), ('queen', 0.730051577091217), ('monarch', 0.6454662084579468), ('princess', 0.6156250834465027), ('crown_prince', 0.5818676948547363), ('prince', 0.5777117013931274), ('kings', 0.561366617679596), ('sultan', 0.5376775860786438), ('Queen_Consort', 0.5344247221946716), ('queens', 0.5289887189865112)]\n"
     ]
    }
   ],
   "source": [
    "vec_example = wv['king'] - wv['man'] + wv['woman']\n",
    "\n",
    "similars = wv.most_similar(positive=[vec_example])\n",
    "print(similars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('programmer', 0.8918285965919495), ('programmers', 0.5779235363006592), ('programer', 0.5624995827674866), ('Programmer', 0.5415107011795044), ('sysadmin', 0.5366033911705017), ('Jon_Shiring', 0.5260592699050903), ('coder', 0.5256212949752808), ('modder', 0.4957827925682068), ('animator', 0.4935148060321808), ('engineer', 0.48991018533706665)]\n"
     ]
    }
   ],
   "source": [
    "vec_example = wv['programmer'] - wv['woman'] + wv['man'] \n",
    "\n",
    "similars = wv.most_similar(positive=[vec_example])\n",
    "print(similars)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "rise": {
   "transition": "none"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
