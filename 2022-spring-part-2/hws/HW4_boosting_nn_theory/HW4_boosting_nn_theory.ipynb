{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G40l9lO2ObLr"
   },
   "source": [
    "## Домашнее задание №4, теоретическое. Бустинг, ЕМ-алгоритм, нейронные сети"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Решите предложенные задачи. Каждая задача должна быть подробно обоснована.\n",
    "\n",
    "Решения пишите в свободной форме, однако так, чтобы проверяющий смог разобраться. Если проверяющий не смог разобраться в решении какой-нибудь задачи, то она автоматически не засчитывается. Если используются какие-либо внешние источники, их нужно обязательно указывать."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задача 1 (2 балла) Композиции алгоритмов, бустинг, AdaBoost\n",
    "\n",
    "Обозначим через $\\tilde w^{(N)}$ нормированный вектор весов на $N$-й итерации алгоритма AdaBoost.\n",
    "\n",
    "Покажите, что взвешенная ошибка базового классификатора $b_N$ относительно весов со следующего шага $\\tilde w^{(N + 1)}$ равна $1/2$:\n",
    "$$\n",
    "       \\sum_{i = 1}^{\\ell}\n",
    "            \\tilde w^{(N + 1)}\n",
    "            [b_N(x_i) \\neq y_i]\n",
    "        =\n",
    "        \\frac{1}{2}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задача 2 (3 балла) Градиентный бустинг\n",
    "    \n",
    "1. (1 балл) Какой функции потерь будет соответствовать градиентный бустинг, который на каждой итерации настраивается на разность между текущим вектором предсказанных меток и вектором истинных меток?\n",
    "\n",
    "2. (1 балл) Градиентный бустинг обучается на пяти объектах с функцией потерь для одного объекта\n",
    "$$\n",
    "            \\mathcal{L}(\\tilde y, y) = (\\tilde y - y)^4\n",
    "$$\n",
    "На некоторой итерации полученная композиция дает ответ $(5, 10, 6, 3, 0)$. На какой вектор ответов будет настраиваться следующий базовый алгоритм, если истинный вектор ответов равен $(6, 8, 6, 4, 1)$?\n",
    "\n",
    "3. (1 балл) Рассмотрим задачу бинарной классификации, $Y = \\{0, 1\\}$. Будем считать, что все алгоритмы из базового семейства $\\mathcal{A}$ возвращают ответы из отрезка $[0, 1]$, которые можно интерпретировать как вероятности принадлежности объекта к классу $1$. В качестве функции потерь возьмем отрицательный логарифм правдоподобия~(negative log-likelihood):\n",
    "$$\n",
    "        L(y, z)\n",
    "        =\n",
    "        -\\bigl(\n",
    "        y \\log z\n",
    "        +\n",
    "        (1 - y) \\log(1 - z)\n",
    "        \\bigr),\n",
    "$$\n",
    "где $y$ — правильный ответ, а $z$ — ответ алгоритма.\n",
    "Выпишите формулы для поиска базовых алгоритмов $b_n$ и коэффициентов $\\gamma_n$ в градиентном бустинге."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задача 3 (2 балла) Композиции, устойчивость к шуму\n",
    "1. (1 балл) Рассмотрим алгоритм AdaBoost — бустинг с экспоненциальной функцией потерь\n",
    "      $$\\mathcal{L}(M)=\\exp(-M),$$\n",
    "где $M$ — отступ объекта. Покажите, что алгоритм неустойчив к шуму, т.е. возможен неограниченный рост отношения весов шумовых объектов по отношению к весам пороговых объектов.\n",
    "\n",
    "2. Покажите, что бустинг с логистической функцией потерь\n",
    "      $$\\mathcal{L}(M) = \\log (1+\\exp(-M))$$\n",
    "устойчив к шуму в описанном выше смысле смысле.\n",
    "    \n",
    "Примечание. Пороговые объекты — это те, для которых значение отступа положительно и порядка нуля, то есть они лежат близко к границе между классами и в своем классе. Шумовые объекты лежат глубоко в чужом классе, на них отступ принимает большие отрицательные значения."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C86UTDuUlQBk"
   },
   "source": [
    "### Задача 4 (2 балла). ЕМ-алгоритм и смеси распределений\n",
    "\n",
    "Рассмотрим модель смеси двух одномерных гауссовских распределений:\n",
    "    $$p(x) = w_1N(x|\\mu_1, \\sigma_1^2) + w_2N(x| \\mu_2, \\sigma_2^2).$$\n",
    "\n",
    "Пусть дана выборка $X^\\ell = \\{x_1, \\dots, x_\\ell\\}$.\n",
    "\n",
    " * (1 балл) Докажите, что правдоподобие этой выборки в данной модели не ограничено.\n",
    " * (1 балл) Пусть дисперсии $\\sigma_1^2$ и $\\sigma_2^2$ известны. Введите в модель скрытые переменные и выведите формулы шагов EM-алгоритма для настройки параметров $w_1, w_2, \\mu_1, \\mu_2$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZX6sPkky9jS6"
   },
   "source": [
    "### Задача 5 (1 балл). Нейронные сети\n",
    "\n",
    "Реализуйте следующую булеву функцию трех переменных с помощью нейронной сети:\n",
    "$$\n",
    "        f(x) =\n",
    "        (\\bar x_1 \\vee x_3) \\& (x_1 \\vee x_2 \\vee x_3).\n",
    "$$\n",
    "\n",
    "Все нейроны должны использовать функцию активации $\\sigma(x) = [x > 0]$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lG4d_zxADKDF"
   },
   "source": [
    "### Задача 6 (2 балла). word2vec, обратное распространение ошибки\n",
    "\n",
    "Рассмотрим нейронную сеть для модели семантической близости слов word2vec. Для простоты будем считать, что по слову $x$ предсказывается одно слово $y$ из его контекста. Эту задачу можно трактовать как задачу многоклассовой классификации, где в роли классов выступают слова словаря.\n",
    "    \n",
    "На вход нейронной сети подается слово $x$ из словаря $V$, закодированное с помощью вектора размерности $|V|$ из нулей и одной единицы (one-hot encoding):\n",
    "$$\n",
    "    x = (0, 0, \\dots 0, 1, 0, \\dots 0)_{|V|}\n",
    "$$\n",
    "    \n",
    "Полносвязный слой с матрицей весов $W$ размерности ${|V|\\times d}$ преобразует вектор $x$ в скрытое представление $h$ некоторой размерности $d \\approx 300$:\n",
    "$$\n",
    "    h = x W\n",
    "$$\n",
    "    \n",
    "Функции активации нет, еще один полносвязный слой c матрицей весов $W'$ размерности ${d \\times |V|}$ преобразует скрытое представление в вектор оценок $a$ за каждый класс, в данном случае --- за каждое слово: \n",
    "$$\n",
    "    a = h W'\n",
    "$$\n",
    "\n",
    "Чтобы получить из этих оценок вероятности, используется SoftMax. Например, вероятность встретить $j$-ое слово словаря в контексте слова $x$ согласно нейронной сети выглядит так:\n",
    "$$\n",
    "    p_j = \\frac{\\exp(a_j)}{\\sum_{k=1}^{|V|} \\exp(a_k)}\n",
    "$$\n",
    "\n",
    "В качестве функции потерь используется cross-entropy loss:\n",
    "$$\n",
    "    \\mathcal{L} = - \\sum_{j=1}^{|V|} y_j \\log p_j, \n",
    "$$\n",
    "где $y$ — one-hot encoding для истинного слова из контекста.\n",
    "    \n",
    "Итак, мы полностью описали проход по нейронной сети вперед: как по входному вектору $x$ найти вероятности классов $p_j$ и вычислить значение функции потерь, зная ответ $y$ на рассматриваемом объекте. Опишите обратный проход по нейронной сети: выпишите формулы изменения матриц весов $W$ и $W'$ в стохастическом градиентном спуске для метода обратного распространения ошибки (backpropagation)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NtrnMSYXKHRS"
   },
   "source": [
    "### Задача 7 (3 балла). Оптимальное вознаграждение\n",
    "\n",
    "Пусть мы решаем задачу показа рекламы на сайте.\n",
    "Всего имеется $n$ рекламных объявлений с некоторыми вознаграждениями.\n",
    "Вознаграждения выбираются из известного нам вероятностного распределения с плотностью $p(x)$, $x > 0$ и фиксируются перед началом эксперимента; при этом сами вознаграждения нам заранее не известны.\n",
    "Всего нужно сделать $n$ показов объявлений.\n",
    "  \n",
    "Будем следовать простой стратегии: сначала покажем несколько различных объявлений и узнаем их вознагражения, а затем будем использовать самое дорогое из них.\n",
    "Допустим, мы попробовали $t$ объявлений и выяснили, что вознаграждения за них равны $r_1, \\dots, r_t$ — это известные нам значения реализаций случайной величины.\n",
    "\n",
    "Поэтому теперь можно воспринимать их как фиксированные числа и оценить, что нас ждет в будущем.     Зафиксируем некоторое $\\alpha > 1$.\n",
    "    \n",
    "1. Покажем еще одно новое объявление. Какова вероятность того, что его вознаграждение $r_{t + 1}$ будет хотя бы в $\\alpha$ раз больше, чем лучшее из $r_1, \\dots, r_t$?\n",
    "2. Покажем $k$ новых объявлений. Какова вероятность того, что хотя бы одно из вознаграждений $r_{t + 1}, \\dots, r_{t + k}$ будет хотя бы в $\\alpha$ раз больше, чем лучшее из $r_1, \\dots, r_t$?\n",
    "3. Продолжим показывать новые объявления до тех пор, пока не найдем объявление с вознаграждением не меньше, чем $\\left[ \\alpha \\max(r_1, \\dots, r_t) \\right]$, или не достигнем лимита по количеству показов, а затем во всех оставшихся показах будем использовать это объявление. Оцените матожидание прибыли при такой стратегии. Ответ можно оставить в виде суммы.\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Practice5.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
