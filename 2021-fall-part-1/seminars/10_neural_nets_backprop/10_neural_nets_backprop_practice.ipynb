{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><img src=\"./images/logo_fmkn.png\" width=300 style=\"display: inline-block;\"></center> \n",
    "\n",
    "## Машинное обучение\n",
    "### Семинар 10. Введение в нейронные сети\n",
    "\n",
    "<br />\n",
    "<br />\n",
    "18 ноября 2021"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9aKcd5XVmkOE",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Загрузим датасет MNIST — базу данных рукописных цифр"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "yT2dLeFNhw4K",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow.keras as keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EIDN1ZwUh1D5",
    "outputId": "b72ee3d6-2895-437e-ceb3-5c2a0ac8a087",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "bl5iB2Jvifud",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 483
    },
    "id": "0rk0ETvtinu_",
    "outputId": "92b1b161-4cff-4ebb-b101-b938aca2d2cf",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1296x576 with 6 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, gs = plt.figure(figsize=(18, 8)), matplotlib.gridspec.GridSpec(2, 3)\n",
    "\n",
    "for i in range(6):\n",
    "    plot = fig.add_subplot(gs[i])\n",
    "    plot.imshow(x_train[i], cmap='gray')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zH5AR408iGmo",
    "outputId": "0baf6a4d-c5ad-47e4-a8de-78e6e3f8af5b",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 0, 4], dtype=uint8)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EOuWYvj4lgiz",
    "outputId": "abef4232-caa5-485e-9f02-47f90873f576",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 9, 2], dtype=uint8)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[3:6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gWJZz72P3TPy",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Для построения нейронной сети воспользуемся библиотекой keras.\n",
    "Это высокоуровневая надстройка над tensorflow. Большим ее преимуществом является интерфейс, совместимый с sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "MQkioCAzqtEJ",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(256, activation='relu'),\n",
    "    keras.layers.Dense(10, activation='sigmoid')\n",
    "])\n",
    "model.compile(optimizer='sgd', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DJhmS9jp4OHm",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Для того, чтобы градиенты были более стабильными, поделим входные данные на 255 (чтобы они были из диапазона [0,1]). И запустим обучение."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "H7ycpGSGpBQQ",
    "outputId": "1cc66863-4950-4301-fb48-fb0bfe6b3a74",
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.6346 - accuracy: 0.8417\n",
      "Epoch 2/20\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3329 - accuracy: 0.9069\n",
      "Epoch 3/20\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2841 - accuracy: 0.9202\n",
      "Epoch 4/20\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2536 - accuracy: 0.9285\n",
      "Epoch 5/20\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2301 - accuracy: 0.9357\n",
      "Epoch 6/20\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2110 - accuracy: 0.9410\n",
      "Epoch 7/20\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1952 - accuracy: 0.9457\n",
      "Epoch 8/20\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1816 - accuracy: 0.9494\n",
      "Epoch 9/20\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1697 - accuracy: 0.9526\n",
      "Epoch 10/20\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1593 - accuracy: 0.9556\n",
      "Epoch 11/20\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1501 - accuracy: 0.9580\n",
      "Epoch 12/20\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1419 - accuracy: 0.9611\n",
      "Epoch 13/20\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1346 - accuracy: 0.9628\n",
      "Epoch 14/20\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1279 - accuracy: 0.9646\n",
      "Epoch 15/20\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1217 - accuracy: 0.9668\n",
      "Epoch 16/20\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1163 - accuracy: 0.9684\n",
      "Epoch 17/20\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1111 - accuracy: 0.9700\n",
      "Epoch 18/20\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1067 - accuracy: 0.9713\n",
      "Epoch 19/20\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1023 - accuracy: 0.9723\n",
      "Epoch 20/20\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0984 - accuracy: 0.9739\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x29344f2dcc8>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train.astype(\"float32\") / 255, y_train, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a-SLgyzmr63H",
    "outputId": "b13877d3-797c-415d-9091-70cfb22fa9c6",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7, 2, 1, ..., 4, 5, 6], dtype=int64)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.argmax(model.predict(x_test.astype(\"float32\") / 255), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UbYbhv1yy5NP",
    "outputId": "d47c8e74-d30c-4964-f3a6-4bf5812d63bc",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9695"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy_score(np.argmax(model.predict(x_test.astype(\"float32\") / 255), axis=1), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uCXwg4vq5AR0",
    "outputId": "4a38103e-cd1d-414b-8baf-8073b1384c8c",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten (Flatten)            (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               200960    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 203,530\n",
      "Trainable params: 203,530\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<b>Вопрос 1:</b> Откуда все эти числа и почему такие?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "x = 28**2\n",
    "y = 256\n",
    "z = 10\n",
    "w1 = 784 * 256 + 256\n",
    "w2 = 256 * 10 + 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4Cp3vzPQzO03",
    "outputId": "32427d75-c5c4-4353-8cb9-cdba2ebd7e57",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 0.0947 - accuracy: 0.9746 - val_loss: 0.1025 - val_accuracy: 0.9700\n",
      "Epoch 2/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0913 - accuracy: 0.9756 - val_loss: 0.0994 - val_accuracy: 0.9712\n",
      "Epoch 3/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0881 - accuracy: 0.9766 - val_loss: 0.0970 - val_accuracy: 0.9715\n",
      "Epoch 4/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0850 - accuracy: 0.9775 - val_loss: 0.0960 - val_accuracy: 0.9720\n",
      "Epoch 5/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0822 - accuracy: 0.9781 - val_loss: 0.0922 - val_accuracy: 0.9731\n",
      "Epoch 6/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0796 - accuracy: 0.9789 - val_loss: 0.0916 - val_accuracy: 0.9735\n",
      "Epoch 7/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0770 - accuracy: 0.9789 - val_loss: 0.0918 - val_accuracy: 0.9726\n",
      "Epoch 8/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0748 - accuracy: 0.9801 - val_loss: 0.0885 - val_accuracy: 0.9739\n",
      "Epoch 9/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0726 - accuracy: 0.9808 - val_loss: 0.0879 - val_accuracy: 0.9734\n",
      "Epoch 10/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0703 - accuracy: 0.9814 - val_loss: 0.0855 - val_accuracy: 0.9743\n",
      "Epoch 11/100\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 0.0684 - accuracy: 0.9819 - val_loss: 0.0857 - val_accuracy: 0.9740\n",
      "Epoch 12/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0665 - accuracy: 0.9826 - val_loss: 0.0837 - val_accuracy: 0.9750\n",
      "Epoch 13/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0646 - accuracy: 0.9834 - val_loss: 0.0824 - val_accuracy: 0.9749\n",
      "Epoch 14/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0629 - accuracy: 0.9836 - val_loss: 0.0808 - val_accuracy: 0.9756\n",
      "Epoch 15/100\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 0.0612 - accuracy: 0.9840 - val_loss: 0.0806 - val_accuracy: 0.9752\n",
      "Epoch 16/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0595 - accuracy: 0.9844 - val_loss: 0.0789 - val_accuracy: 0.9765\n",
      "Epoch 17/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0580 - accuracy: 0.9846 - val_loss: 0.0783 - val_accuracy: 0.9764\n",
      "Epoch 18/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0566 - accuracy: 0.9855 - val_loss: 0.0772 - val_accuracy: 0.9769\n",
      "Epoch 19/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0551 - accuracy: 0.9860 - val_loss: 0.0762 - val_accuracy: 0.9772\n",
      "Epoch 20/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0538 - accuracy: 0.9862 - val_loss: 0.0773 - val_accuracy: 0.9764\n",
      "Epoch 21/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0525 - accuracy: 0.9866 - val_loss: 0.0756 - val_accuracy: 0.9771\n",
      "Epoch 22/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0513 - accuracy: 0.9872 - val_loss: 0.0754 - val_accuracy: 0.9773\n",
      "Epoch 23/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0501 - accuracy: 0.9872 - val_loss: 0.0744 - val_accuracy: 0.9772\n",
      "Epoch 24/100\n",
      " 340/1875 [====>.........................] - ETA: 2s - loss: 0.0476 - accuracy: 0.9881"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-b5fc1f2f077c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"float32\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;36m255\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"float32\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;36m255\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1182\u001b[0m                 _r=1):\n\u001b[0;32m   1183\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1184\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1185\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1186\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    883\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    884\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 885\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    886\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    915\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    916\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 917\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    918\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    919\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3038\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m   3039\u001b[0m     return graph_function._call_flat(\n\u001b[1;32m-> 3040\u001b[1;33m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[0;32m   3041\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3042\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1962\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1963\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1964\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1965\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1966\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    594\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    595\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 596\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    597\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    598\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[1;32m---> 60\u001b[1;33m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(x_train.astype(\"float32\") / 255, y_train, epochs=100, validation_data=(x_test.astype(\"float32\") / 255, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Gwv4-LvF1qD7",
    "outputId": "3fd84bf3-d016-4ff7-b73d-256371b8fc49",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9804"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(np.argmax(model.predict(x_test.astype(\"float32\") / 255), axis=1), y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Посмотрим ещё один датасет. \n",
    "\n",
    "Fashion-MNIST — это набор изображений статей магазина Zalando, состоящий из обучающего набора из 60 000 объектов и тестового набора из 10 000 объектов. \n",
    "\n",
    "Каждый объект — изображение в оттенках серого 28x28, связанное с меткой из 10 классов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "ZCYaJfJN7PhY",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "fashion_mnist = keras.datasets.fashion_mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 428
    },
    "id": "ypkTBgeophbv",
    "outputId": "d3f4e25d-7320-4536-9148-735a3af1d7e9",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1296x576 with 6 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, gs = plt.figure(figsize=(18, 8)), matplotlib.gridspec.GridSpec(2, 3)\n",
    "\n",
    "for i in range(6):\n",
    "    plot = fig.add_subplot(gs[i])\n",
    "    plot.imshow(x_train[i], cmap='gray')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1-B-OHL0_Mq0",
    "outputId": "f2233eb1-2fd2-490c-ad4d-e15e3921df48",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9, 0, 0], dtype=uint8)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vBRwOImQ_N27",
    "outputId": "869dd767-1b2c-4ba8-a234-2292753cc240",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 0, 2], dtype=uint8)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[3:6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Модель в точности та же."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "eiLUjwWx7Wff",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(256, activation=\"relu\"),\n",
    "    keras.layers.Dense(10, activation='sigmoid')\n",
    "])\n",
    "model.compile(optimizer='sgd', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "Fb_-9St2AVqU",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "_, x_split, _, y_split = train_test_split(x_train, y_train, test_size=0.001, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XbBY7LyO7b6K",
    "outputId": "7d4ee439-3cb0-4f0c-b14a-a24ad8d221bd",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "2/2 [==============================] - 1s 670ms/step - loss: 2.3810 - accuracy: 0.1333 - val_loss: 2.2456 - val_accuracy: 0.1621\n",
      "Epoch 2/500\n",
      "2/2 [==============================] - 1s 562ms/step - loss: 2.2086 - accuracy: 0.1667 - val_loss: 2.1723 - val_accuracy: 0.1873\n",
      "Epoch 3/500\n",
      "2/2 [==============================] - 1s 683ms/step - loss: 2.0739 - accuracy: 0.1833 - val_loss: 2.1186 - val_accuracy: 0.2339\n",
      "Epoch 4/500\n",
      "2/2 [==============================] - 1s 608ms/step - loss: 1.9699 - accuracy: 0.3000 - val_loss: 2.0737 - val_accuracy: 0.2516\n",
      "Epoch 5/500\n",
      "2/2 [==============================] - 1s 641ms/step - loss: 1.8922 - accuracy: 0.4167 - val_loss: 2.0392 - val_accuracy: 0.2820\n",
      "Epoch 6/500\n",
      "2/2 [==============================] - 1s 665ms/step - loss: 1.8219 - accuracy: 0.5000 - val_loss: 2.0074 - val_accuracy: 0.3131\n",
      "Epoch 7/500\n",
      "2/2 [==============================] - 1s 676ms/step - loss: 1.7523 - accuracy: 0.5833 - val_loss: 1.9728 - val_accuracy: 0.3405\n",
      "Epoch 8/500\n",
      "2/2 [==============================] - 1s 541ms/step - loss: 1.6920 - accuracy: 0.6333 - val_loss: 1.9367 - val_accuracy: 0.3652\n",
      "Epoch 9/500\n",
      "2/2 [==============================] - 1s 565ms/step - loss: 1.6402 - accuracy: 0.6333 - val_loss: 1.9067 - val_accuracy: 0.3742\n",
      "Epoch 10/500\n",
      "2/2 [==============================] - 1s 579ms/step - loss: 1.5917 - accuracy: 0.6333 - val_loss: 1.8781 - val_accuracy: 0.3793\n",
      "Epoch 11/500\n",
      "2/2 [==============================] - 1s 575ms/step - loss: 1.5497 - accuracy: 0.6500 - val_loss: 1.8527 - val_accuracy: 0.3838\n",
      "Epoch 12/500\n",
      "2/2 [==============================] - 1s 566ms/step - loss: 1.5119 - accuracy: 0.6500 - val_loss: 1.8258 - val_accuracy: 0.3904\n",
      "Epoch 13/500\n",
      "2/2 [==============================] - 1s 572ms/step - loss: 1.4727 - accuracy: 0.6667 - val_loss: 1.8007 - val_accuracy: 0.4011\n",
      "Epoch 14/500\n",
      "2/2 [==============================] - 1s 547ms/step - loss: 1.4344 - accuracy: 0.6500 - val_loss: 1.7765 - val_accuracy: 0.4084\n",
      "Epoch 15/500\n",
      "2/2 [==============================] - 1s 542ms/step - loss: 1.4030 - accuracy: 0.6667 - val_loss: 1.7561 - val_accuracy: 0.4133\n",
      "Epoch 16/500\n",
      "2/2 [==============================] - 1s 543ms/step - loss: 1.3756 - accuracy: 0.6833 - val_loss: 1.7397 - val_accuracy: 0.4177\n",
      "Epoch 17/500\n",
      "2/2 [==============================] - 1s 558ms/step - loss: 1.3378 - accuracy: 0.6667 - val_loss: 1.7198 - val_accuracy: 0.4270\n",
      "Epoch 18/500\n",
      "2/2 [==============================] - 1s 716ms/step - loss: 1.3125 - accuracy: 0.6833 - val_loss: 1.6986 - val_accuracy: 0.4355\n",
      "Epoch 19/500\n",
      "2/2 [==============================] - 0s 482ms/step - loss: 1.2878 - accuracy: 0.7000 - val_loss: 1.6835 - val_accuracy: 0.4410\n",
      "Epoch 20/500\n",
      "2/2 [==============================] - 1s 861ms/step - loss: 1.2618 - accuracy: 0.7167 - val_loss: 1.6646 - val_accuracy: 0.4475\n",
      "Epoch 21/500\n",
      "2/2 [==============================] - 1s 1s/step - loss: 1.2382 - accuracy: 0.7167 - val_loss: 1.6469 - val_accuracy: 0.4536\n",
      "Epoch 22/500\n",
      "2/2 [==============================] - 1s 631ms/step - loss: 1.2139 - accuracy: 0.7167 - val_loss: 1.6311 - val_accuracy: 0.4618\n",
      "Epoch 23/500\n",
      "2/2 [==============================] - 0s 477ms/step - loss: 1.1914 - accuracy: 0.7167 - val_loss: 1.6117 - val_accuracy: 0.4697\n",
      "Epoch 24/500\n",
      "2/2 [==============================] - 0s 495ms/step - loss: 1.1714 - accuracy: 0.7167 - val_loss: 1.5943 - val_accuracy: 0.4763\n",
      "Epoch 25/500\n",
      "2/2 [==============================] - 1s 516ms/step - loss: 1.1488 - accuracy: 0.7167 - val_loss: 1.5788 - val_accuracy: 0.4805\n",
      "Epoch 26/500\n",
      "2/2 [==============================] - 0s 492ms/step - loss: 1.1310 - accuracy: 0.7167 - val_loss: 1.5649 - val_accuracy: 0.4882\n",
      "Epoch 27/500\n",
      "2/2 [==============================] - 1s 560ms/step - loss: 1.1100 - accuracy: 0.7333 - val_loss: 1.5512 - val_accuracy: 0.4911\n",
      "Epoch 28/500\n",
      "2/2 [==============================] - 0s 470ms/step - loss: 1.0988 - accuracy: 0.7333 - val_loss: 1.5333 - val_accuracy: 0.4962\n",
      "Epoch 29/500\n",
      "2/2 [==============================] - 0s 452ms/step - loss: 1.0783 - accuracy: 0.7333 - val_loss: 1.5196 - val_accuracy: 0.5005\n",
      "Epoch 30/500\n",
      "2/2 [==============================] - 0s 444ms/step - loss: 1.0587 - accuracy: 0.7500 - val_loss: 1.5071 - val_accuracy: 0.5049\n",
      "Epoch 31/500\n",
      "2/2 [==============================] - 0s 473ms/step - loss: 1.0413 - accuracy: 0.7667 - val_loss: 1.4971 - val_accuracy: 0.5061\n",
      "Epoch 32/500\n",
      "2/2 [==============================] - 0s 450ms/step - loss: 1.0263 - accuracy: 0.7667 - val_loss: 1.4858 - val_accuracy: 0.5068\n",
      "Epoch 33/500\n",
      "2/2 [==============================] - 0s 458ms/step - loss: 1.0131 - accuracy: 0.7833 - val_loss: 1.4750 - val_accuracy: 0.5083\n",
      "Epoch 34/500\n",
      "2/2 [==============================] - 0s 460ms/step - loss: 1.0016 - accuracy: 0.7500 - val_loss: 1.4586 - val_accuracy: 0.5161\n",
      "Epoch 35/500\n",
      "2/2 [==============================] - 0s 452ms/step - loss: 0.9835 - accuracy: 0.7667 - val_loss: 1.4520 - val_accuracy: 0.5148\n",
      "Epoch 36/500\n",
      "2/2 [==============================] - 1s 591ms/step - loss: 0.9714 - accuracy: 0.7667 - val_loss: 1.4406 - val_accuracy: 0.5182\n",
      "Epoch 37/500\n",
      "2/2 [==============================] - 1s 507ms/step - loss: 0.9537 - accuracy: 0.7833 - val_loss: 1.4328 - val_accuracy: 0.5198\n",
      "Epoch 38/500\n",
      "2/2 [==============================] - 0s 441ms/step - loss: 0.9472 - accuracy: 0.7833 - val_loss: 1.4166 - val_accuracy: 0.5263\n",
      "Epoch 39/500\n",
      "2/2 [==============================] - 0s 450ms/step - loss: 0.9297 - accuracy: 0.7833 - val_loss: 1.4066 - val_accuracy: 0.5280\n",
      "Epoch 40/500\n",
      "2/2 [==============================] - 0s 463ms/step - loss: 0.9157 - accuracy: 0.7667 - val_loss: 1.3985 - val_accuracy: 0.5314\n",
      "Epoch 41/500\n",
      "2/2 [==============================] - 0s 445ms/step - loss: 0.9054 - accuracy: 0.8167 - val_loss: 1.3921 - val_accuracy: 0.5310\n",
      "Epoch 42/500\n",
      "2/2 [==============================] - 0s 482ms/step - loss: 0.8895 - accuracy: 0.8000 - val_loss: 1.3816 - val_accuracy: 0.5346\n",
      "Epoch 43/500\n",
      "2/2 [==============================] - 0s 480ms/step - loss: 0.8815 - accuracy: 0.8000 - val_loss: 1.3719 - val_accuracy: 0.5386\n",
      "Epoch 44/500\n",
      "2/2 [==============================] - 0s 479ms/step - loss: 0.8708 - accuracy: 0.8333 - val_loss: 1.3682 - val_accuracy: 0.5354\n",
      "Epoch 45/500\n",
      "2/2 [==============================] - 0s 434ms/step - loss: 0.8577 - accuracy: 0.8167 - val_loss: 1.3586 - val_accuracy: 0.5412\n",
      "Epoch 46/500\n",
      "2/2 [==============================] - 0s 448ms/step - loss: 0.8485 - accuracy: 0.8167 - val_loss: 1.3519 - val_accuracy: 0.5436\n",
      "Epoch 47/500\n",
      "2/2 [==============================] - 1s 516ms/step - loss: 0.8360 - accuracy: 0.8167 - val_loss: 1.3407 - val_accuracy: 0.5505\n",
      "Epoch 48/500\n",
      "2/2 [==============================] - 1s 672ms/step - loss: 0.8308 - accuracy: 0.8167 - val_loss: 1.3283 - val_accuracy: 0.5559\n",
      "Epoch 49/500\n",
      "2/2 [==============================] - 0s 463ms/step - loss: 0.8187 - accuracy: 0.8333 - val_loss: 1.3261 - val_accuracy: 0.5522\n",
      "Epoch 50/500\n",
      "2/2 [==============================] - 1s 578ms/step - loss: 0.8100 - accuracy: 0.8167 - val_loss: 1.3163 - val_accuracy: 0.5571\n",
      "Epoch 51/500\n",
      "2/2 [==============================] - 1s 746ms/step - loss: 0.8044 - accuracy: 0.8500 - val_loss: 1.3040 - val_accuracy: 0.5661\n",
      "Epoch 52/500\n",
      "2/2 [==============================] - 1s 730ms/step - loss: 0.7878 - accuracy: 0.8500 - val_loss: 1.2992 - val_accuracy: 0.5666\n",
      "Epoch 53/500\n",
      "2/2 [==============================] - 1s 866ms/step - loss: 0.7828 - accuracy: 0.8500 - val_loss: 1.2981 - val_accuracy: 0.5635\n",
      "Epoch 54/500\n",
      "2/2 [==============================] - 1s 853ms/step - loss: 0.7720 - accuracy: 0.8500 - val_loss: 1.2916 - val_accuracy: 0.5650\n",
      "Epoch 55/500\n",
      "2/2 [==============================] - 1s 920ms/step - loss: 0.7624 - accuracy: 0.8500 - val_loss: 1.2839 - val_accuracy: 0.5675\n",
      "Epoch 56/500\n",
      "2/2 [==============================] - 1s 924ms/step - loss: 0.7545 - accuracy: 0.8500 - val_loss: 1.2786 - val_accuracy: 0.5693\n",
      "Epoch 57/500\n",
      "2/2 [==============================] - 1s 898ms/step - loss: 0.7526 - accuracy: 0.8500 - val_loss: 1.2796 - val_accuracy: 0.5635\n",
      "Epoch 58/500\n",
      "2/2 [==============================] - 1s 860ms/step - loss: 0.7396 - accuracy: 0.8500 - val_loss: 1.2656 - val_accuracy: 0.5724\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/500\n",
      "2/2 [==============================] - 1s 1s/step - loss: 0.7367 - accuracy: 0.8500 - val_loss: 1.2664 - val_accuracy: 0.5686\n",
      "Epoch 60/500\n",
      "2/2 [==============================] - 1s 925ms/step - loss: 0.7263 - accuracy: 0.8500 - val_loss: 1.2610 - val_accuracy: 0.5704\n",
      "Epoch 61/500\n",
      "2/2 [==============================] - 1s 862ms/step - loss: 0.7149 - accuracy: 0.8500 - val_loss: 1.2512 - val_accuracy: 0.5742\n",
      "Epoch 62/500\n",
      "2/2 [==============================] - 1s 885ms/step - loss: 0.7097 - accuracy: 0.8500 - val_loss: 1.2405 - val_accuracy: 0.5797\n",
      "Epoch 63/500\n",
      "2/2 [==============================] - 1s 742ms/step - loss: 0.6997 - accuracy: 0.8500 - val_loss: 1.2357 - val_accuracy: 0.5823\n",
      "Epoch 64/500\n",
      "2/2 [==============================] - 1s 613ms/step - loss: 0.6947 - accuracy: 0.8500 - val_loss: 1.2332 - val_accuracy: 0.5822\n",
      "Epoch 65/500\n",
      "2/2 [==============================] - 1s 706ms/step - loss: 0.6935 - accuracy: 0.8500 - val_loss: 1.2353 - val_accuracy: 0.5777\n",
      "Epoch 66/500\n",
      "2/2 [==============================] - 1s 719ms/step - loss: 0.6797 - accuracy: 0.8500 - val_loss: 1.2286 - val_accuracy: 0.5810\n",
      "Epoch 67/500\n",
      "2/2 [==============================] - 1s 721ms/step - loss: 0.6724 - accuracy: 0.8500 - val_loss: 1.2210 - val_accuracy: 0.5845\n",
      "Epoch 68/500\n",
      "2/2 [==============================] - 1s 636ms/step - loss: 0.6714 - accuracy: 0.8500 - val_loss: 1.2099 - val_accuracy: 0.5899\n",
      "Epoch 69/500\n",
      "2/2 [==============================] - 0s 490ms/step - loss: 0.6602 - accuracy: 0.8667 - val_loss: 1.2111 - val_accuracy: 0.5865\n",
      "Epoch 70/500\n",
      "2/2 [==============================] - 0s 488ms/step - loss: 0.6570 - accuracy: 0.8500 - val_loss: 1.2002 - val_accuracy: 0.5930\n",
      "Epoch 71/500\n",
      "2/2 [==============================] - 0s 459ms/step - loss: 0.6470 - accuracy: 0.8667 - val_loss: 1.1986 - val_accuracy: 0.5910\n",
      "Epoch 72/500\n",
      "2/2 [==============================] - 0s 446ms/step - loss: 0.6399 - accuracy: 0.8667 - val_loss: 1.1968 - val_accuracy: 0.5902\n",
      "Epoch 73/500\n",
      "2/2 [==============================] - 0s 456ms/step - loss: 0.6422 - accuracy: 0.8500 - val_loss: 1.1998 - val_accuracy: 0.5845\n",
      "Epoch 74/500\n",
      "2/2 [==============================] - 1s 555ms/step - loss: 0.6296 - accuracy: 0.8667 - val_loss: 1.1897 - val_accuracy: 0.5894\n",
      "Epoch 75/500\n",
      "2/2 [==============================] - 0s 448ms/step - loss: 0.6226 - accuracy: 0.8667 - val_loss: 1.1850 - val_accuracy: 0.5911\n",
      "Epoch 76/500\n",
      "2/2 [==============================] - 0s 436ms/step - loss: 0.6208 - accuracy: 0.8667 - val_loss: 1.1839 - val_accuracy: 0.5894\n",
      "Epoch 77/500\n",
      "2/2 [==============================] - 0s 442ms/step - loss: 0.6121 - accuracy: 0.8500 - val_loss: 1.1768 - val_accuracy: 0.5943\n",
      "Epoch 78/500\n",
      "2/2 [==============================] - 0s 441ms/step - loss: 0.6074 - accuracy: 0.8833 - val_loss: 1.1759 - val_accuracy: 0.5926\n",
      "Epoch 79/500\n",
      "2/2 [==============================] - 0s 448ms/step - loss: 0.6033 - accuracy: 0.8667 - val_loss: 1.1696 - val_accuracy: 0.5948\n",
      "Epoch 80/500\n",
      "2/2 [==============================] - 0s 454ms/step - loss: 0.5950 - accuracy: 0.8667 - val_loss: 1.1664 - val_accuracy: 0.5958\n",
      "Epoch 81/500\n",
      "2/2 [==============================] - 0s 427ms/step - loss: 0.5923 - accuracy: 0.8833 - val_loss: 1.1566 - val_accuracy: 0.6028\n",
      "Epoch 82/500\n",
      "2/2 [==============================] - 0s 455ms/step - loss: 0.5891 - accuracy: 0.9000 - val_loss: 1.1530 - val_accuracy: 0.6031\n",
      "Epoch 83/500\n",
      "2/2 [==============================] - 0s 465ms/step - loss: 0.5801 - accuracy: 0.9000 - val_loss: 1.1540 - val_accuracy: 0.6010\n",
      "Epoch 84/500\n",
      "2/2 [==============================] - 0s 432ms/step - loss: 0.5806 - accuracy: 0.8833 - val_loss: 1.1469 - val_accuracy: 0.6066\n",
      "Epoch 85/500\n",
      "2/2 [==============================] - 0s 438ms/step - loss: 0.5723 - accuracy: 0.9000 - val_loss: 1.1417 - val_accuracy: 0.6080\n",
      "Epoch 86/500\n",
      "2/2 [==============================] - 0s 438ms/step - loss: 0.5689 - accuracy: 0.9000 - val_loss: 1.1437 - val_accuracy: 0.6041\n",
      "Epoch 87/500\n",
      "2/2 [==============================] - 1s 504ms/step - loss: 0.5679 - accuracy: 0.9000 - val_loss: 1.1348 - val_accuracy: 0.6123\n",
      "Epoch 88/500\n",
      "2/2 [==============================] - 0s 427ms/step - loss: 0.5607 - accuracy: 0.9167 - val_loss: 1.1395 - val_accuracy: 0.6058\n",
      "Epoch 89/500\n",
      "2/2 [==============================] - 0s 435ms/step - loss: 0.5585 - accuracy: 0.9000 - val_loss: 1.1278 - val_accuracy: 0.6161\n",
      "Epoch 90/500\n",
      "2/2 [==============================] - 0s 439ms/step - loss: 0.5496 - accuracy: 0.9167 - val_loss: 1.1289 - val_accuracy: 0.6093\n",
      "Epoch 91/500\n",
      "2/2 [==============================] - 0s 425ms/step - loss: 0.5416 - accuracy: 0.9167 - val_loss: 1.1287 - val_accuracy: 0.6088\n",
      "Epoch 92/500\n",
      "2/2 [==============================] - 1s 534ms/step - loss: 0.5392 - accuracy: 0.9167 - val_loss: 1.1276 - val_accuracy: 0.6087\n",
      "Epoch 93/500\n",
      "2/2 [==============================] - 0s 441ms/step - loss: 0.5365 - accuracy: 0.9167 - val_loss: 1.1199 - val_accuracy: 0.6138\n",
      "Epoch 94/500\n",
      "2/2 [==============================] - 0s 434ms/step - loss: 0.5317 - accuracy: 0.9167 - val_loss: 1.1230 - val_accuracy: 0.6095\n",
      "Epoch 95/500\n",
      "2/2 [==============================] - 0s 449ms/step - loss: 0.5251 - accuracy: 0.9167 - val_loss: 1.1211 - val_accuracy: 0.6096\n",
      "Epoch 96/500\n",
      "2/2 [==============================] - 0s 436ms/step - loss: 0.5208 - accuracy: 0.9167 - val_loss: 1.1156 - val_accuracy: 0.6124\n",
      "Epoch 97/500\n",
      "2/2 [==============================] - 1s 622ms/step - loss: 0.5153 - accuracy: 0.9167 - val_loss: 1.1136 - val_accuracy: 0.6128\n",
      "Epoch 98/500\n",
      "2/2 [==============================] - 1s 550ms/step - loss: 0.5149 - accuracy: 0.9167 - val_loss: 1.1085 - val_accuracy: 0.6165\n",
      "Epoch 99/500\n",
      "2/2 [==============================] - 1s 530ms/step - loss: 0.5135 - accuracy: 0.9167 - val_loss: 1.1051 - val_accuracy: 0.6205\n",
      "Epoch 100/500\n",
      "2/2 [==============================] - 1s 607ms/step - loss: 0.5047 - accuracy: 0.9167 - val_loss: 1.1033 - val_accuracy: 0.6199\n",
      "Epoch 101/500\n",
      "2/2 [==============================] - 0s 495ms/step - loss: 0.5004 - accuracy: 0.9167 - val_loss: 1.1017 - val_accuracy: 0.6198\n",
      "Epoch 102/500\n",
      "2/2 [==============================] - 1s 593ms/step - loss: 0.4992 - accuracy: 0.9167 - val_loss: 1.1044 - val_accuracy: 0.6133\n",
      "Epoch 103/500\n",
      "2/2 [==============================] - 0s 452ms/step - loss: 0.4926 - accuracy: 0.9167 - val_loss: 1.0981 - val_accuracy: 0.6170\n",
      "Epoch 104/500\n",
      "2/2 [==============================] - 0s 429ms/step - loss: 0.4919 - accuracy: 0.9167 - val_loss: 1.0983 - val_accuracy: 0.6153\n",
      "Epoch 105/500\n",
      "2/2 [==============================] - 1s 814ms/step - loss: 0.4863 - accuracy: 0.9167 - val_loss: 1.0918 - val_accuracy: 0.6200\n",
      "Epoch 106/500\n",
      "2/2 [==============================] - 1s 503ms/step - loss: 0.4824 - accuracy: 0.9167 - val_loss: 1.0926 - val_accuracy: 0.6184\n",
      "Epoch 107/500\n",
      "2/2 [==============================] - 0s 445ms/step - loss: 0.4802 - accuracy: 0.9167 - val_loss: 1.0929 - val_accuracy: 0.6169\n",
      "Epoch 108/500\n",
      "2/2 [==============================] - 0s 496ms/step - loss: 0.4760 - accuracy: 0.9333 - val_loss: 1.0916 - val_accuracy: 0.6163\n",
      "Epoch 109/500\n",
      "2/2 [==============================] - 0s 439ms/step - loss: 0.4776 - accuracy: 0.9167 - val_loss: 1.0811 - val_accuracy: 0.6265\n",
      "Epoch 110/500\n",
      "2/2 [==============================] - 0s 438ms/step - loss: 0.4683 - accuracy: 0.9333 - val_loss: 1.0818 - val_accuracy: 0.6247\n",
      "Epoch 111/500\n",
      "2/2 [==============================] - 0s 461ms/step - loss: 0.4650 - accuracy: 0.9333 - val_loss: 1.0802 - val_accuracy: 0.6241\n",
      "Epoch 112/500\n",
      "2/2 [==============================] - 1s 583ms/step - loss: 0.4622 - accuracy: 0.9333 - val_loss: 1.0758 - val_accuracy: 0.6260\n",
      "Epoch 113/500\n",
      "2/2 [==============================] - 0s 462ms/step - loss: 0.4650 - accuracy: 0.9333 - val_loss: 1.0846 - val_accuracy: 0.6167\n",
      "Epoch 114/500\n",
      "2/2 [==============================] - 0s 496ms/step - loss: 0.4569 - accuracy: 0.9167 - val_loss: 1.0825 - val_accuracy: 0.6177\n",
      "Epoch 115/500\n",
      "2/2 [==============================] - 1s 590ms/step - loss: 0.4511 - accuracy: 0.9167 - val_loss: 1.0782 - val_accuracy: 0.6202\n",
      "Epoch 116/500\n",
      "2/2 [==============================] - 1s 583ms/step - loss: 0.4513 - accuracy: 0.9167 - val_loss: 1.0797 - val_accuracy: 0.6171\n",
      "Epoch 117/500\n",
      "2/2 [==============================] - 1s 563ms/step - loss: 0.4503 - accuracy: 0.9167 - val_loss: 1.0660 - val_accuracy: 0.6310\n",
      "Epoch 118/500\n",
      "2/2 [==============================] - 0s 486ms/step - loss: 0.4422 - accuracy: 0.9333 - val_loss: 1.0679 - val_accuracy: 0.6269\n",
      "Epoch 119/500\n",
      "2/2 [==============================] - 1s 598ms/step - loss: 0.4392 - accuracy: 0.9333 - val_loss: 1.0672 - val_accuracy: 0.6276\n",
      "Epoch 120/500\n",
      "2/2 [==============================] - 0s 456ms/step - loss: 0.4353 - accuracy: 0.9333 - val_loss: 1.0665 - val_accuracy: 0.6259\n",
      "Epoch 121/500\n",
      "2/2 [==============================] - 0s 435ms/step - loss: 0.4324 - accuracy: 0.9333 - val_loss: 1.0642 - val_accuracy: 0.6284\n",
      "Epoch 122/500\n",
      "2/2 [==============================] - 0s 446ms/step - loss: 0.4310 - accuracy: 0.9333 - val_loss: 1.0653 - val_accuracy: 0.6239\n",
      "Epoch 123/500\n",
      "2/2 [==============================] - 1s 558ms/step - loss: 0.4280 - accuracy: 0.9333 - val_loss: 1.0642 - val_accuracy: 0.6247\n",
      "Epoch 124/500\n",
      "2/2 [==============================] - 0s 495ms/step - loss: 0.4245 - accuracy: 0.9333 - val_loss: 1.0608 - val_accuracy: 0.6281\n",
      "Epoch 125/500\n",
      "2/2 [==============================] - 0s 441ms/step - loss: 0.4205 - accuracy: 0.9333 - val_loss: 1.0606 - val_accuracy: 0.6267\n",
      "Epoch 126/500\n",
      "2/2 [==============================] - 1s 577ms/step - loss: 0.4199 - accuracy: 0.9167 - val_loss: 1.0546 - val_accuracy: 0.6331\n",
      "Epoch 127/500\n",
      "2/2 [==============================] - 1s 561ms/step - loss: 0.4166 - accuracy: 0.9333 - val_loss: 1.0524 - val_accuracy: 0.6337\n",
      "Epoch 128/500\n",
      "2/2 [==============================] - 0s 452ms/step - loss: 0.4133 - accuracy: 0.9333 - val_loss: 1.0506 - val_accuracy: 0.6334\n",
      "Epoch 129/500\n",
      "2/2 [==============================] - 0s 480ms/step - loss: 0.4099 - accuracy: 0.9333 - val_loss: 1.0492 - val_accuracy: 0.6345\n",
      "Epoch 130/500\n",
      "2/2 [==============================] - 1s 697ms/step - loss: 0.4058 - accuracy: 0.9333 - val_loss: 1.0485 - val_accuracy: 0.6346\n",
      "Epoch 131/500\n",
      "2/2 [==============================] - 1s 663ms/step - loss: 0.4048 - accuracy: 0.9333 - val_loss: 1.0511 - val_accuracy: 0.6303\n",
      "Epoch 132/500\n",
      "2/2 [==============================] - 1s 640ms/step - loss: 0.4008 - accuracy: 0.9333 - val_loss: 1.0467 - val_accuracy: 0.6340\n",
      "Epoch 133/500\n",
      "2/2 [==============================] - 1s 662ms/step - loss: 0.4006 - accuracy: 0.9333 - val_loss: 1.0457 - val_accuracy: 0.6349\n",
      "Epoch 134/500\n",
      "2/2 [==============================] - 1s 627ms/step - loss: 0.3972 - accuracy: 0.9333 - val_loss: 1.0466 - val_accuracy: 0.6320\n",
      "Epoch 135/500\n",
      "2/2 [==============================] - 1s 538ms/step - loss: 0.3937 - accuracy: 0.9333 - val_loss: 1.0468 - val_accuracy: 0.6302\n",
      "Epoch 136/500\n",
      "2/2 [==============================] - 0s 447ms/step - loss: 0.3917 - accuracy: 0.9333 - val_loss: 1.0408 - val_accuracy: 0.6355\n",
      "Epoch 137/500\n",
      "2/2 [==============================] - 0s 441ms/step - loss: 0.3882 - accuracy: 0.9333 - val_loss: 1.0390 - val_accuracy: 0.6360\n",
      "Epoch 138/500\n",
      "2/2 [==============================] - 0s 462ms/step - loss: 0.3869 - accuracy: 0.9333 - val_loss: 1.0347 - val_accuracy: 0.6378\n",
      "Epoch 139/500\n",
      "2/2 [==============================] - 0s 475ms/step - loss: 0.3856 - accuracy: 0.9333 - val_loss: 1.0315 - val_accuracy: 0.6403\n",
      "Epoch 140/500\n",
      "2/2 [==============================] - 0s 464ms/step - loss: 0.3825 - accuracy: 0.9333 - val_loss: 1.0297 - val_accuracy: 0.6402\n",
      "Epoch 141/500\n",
      "2/2 [==============================] - 0s 481ms/step - loss: 0.3820 - accuracy: 0.9333 - val_loss: 1.0284 - val_accuracy: 0.6394\n",
      "Epoch 142/500\n",
      "2/2 [==============================] - 0s 440ms/step - loss: 0.3820 - accuracy: 0.9333 - val_loss: 1.0236 - val_accuracy: 0.6428\n",
      "Epoch 143/500\n",
      "2/2 [==============================] - 0s 456ms/step - loss: 0.3742 - accuracy: 0.9500 - val_loss: 1.0285 - val_accuracy: 0.6387\n",
      "Epoch 144/500\n",
      "2/2 [==============================] - 0s 472ms/step - loss: 0.3725 - accuracy: 0.9333 - val_loss: 1.0323 - val_accuracy: 0.6353\n",
      "Epoch 145/500\n",
      "2/2 [==============================] - 0s 451ms/step - loss: 0.3687 - accuracy: 0.9333 - val_loss: 1.0328 - val_accuracy: 0.6348\n",
      "Epoch 146/500\n",
      "2/2 [==============================] - 0s 435ms/step - loss: 0.3667 - accuracy: 0.9333 - val_loss: 1.0303 - val_accuracy: 0.6363\n",
      "Epoch 147/500\n",
      "2/2 [==============================] - 0s 490ms/step - loss: 0.3646 - accuracy: 0.9333 - val_loss: 1.0310 - val_accuracy: 0.6344\n",
      "Epoch 148/500\n",
      "2/2 [==============================] - 1s 604ms/step - loss: 0.3678 - accuracy: 0.9333 - val_loss: 1.0348 - val_accuracy: 0.6313\n",
      "Epoch 149/500\n",
      "2/2 [==============================] - 1s 520ms/step - loss: 0.3594 - accuracy: 0.9333 - val_loss: 1.0277 - val_accuracy: 0.6361\n",
      "Epoch 150/500\n",
      "2/2 [==============================] - 1s 664ms/step - loss: 0.3576 - accuracy: 0.9333 - val_loss: 1.0281 - val_accuracy: 0.6345\n",
      "Epoch 151/500\n",
      "2/2 [==============================] - 0s 448ms/step - loss: 0.3554 - accuracy: 0.9333 - val_loss: 1.0230 - val_accuracy: 0.6381\n",
      "Epoch 152/500\n",
      "2/2 [==============================] - 1s 587ms/step - loss: 0.3528 - accuracy: 0.9333 - val_loss: 1.0211 - val_accuracy: 0.6401\n",
      "Epoch 153/500\n",
      "2/2 [==============================] - 1s 686ms/step - loss: 0.3534 - accuracy: 0.9333 - val_loss: 1.0209 - val_accuracy: 0.6410\n",
      "Epoch 154/500\n",
      "2/2 [==============================] - 0s 466ms/step - loss: 0.3496 - accuracy: 0.9333 - val_loss: 1.0196 - val_accuracy: 0.6400\n",
      "Epoch 155/500\n",
      "2/2 [==============================] - 0s 453ms/step - loss: 0.3479 - accuracy: 0.9333 - val_loss: 1.0223 - val_accuracy: 0.6381\n",
      "Epoch 156/500\n",
      "2/2 [==============================] - 0s 443ms/step - loss: 0.3481 - accuracy: 0.9333 - val_loss: 1.0138 - val_accuracy: 0.6437\n",
      "Epoch 157/500\n",
      "2/2 [==============================] - 0s 459ms/step - loss: 0.3420 - accuracy: 0.9500 - val_loss: 1.0149 - val_accuracy: 0.6426\n",
      "Epoch 158/500\n",
      "2/2 [==============================] - 0s 440ms/step - loss: 0.3407 - accuracy: 0.9333 - val_loss: 1.0144 - val_accuracy: 0.6421\n",
      "Epoch 159/500\n",
      "2/2 [==============================] - 0s 445ms/step - loss: 0.3382 - accuracy: 0.9500 - val_loss: 1.0161 - val_accuracy: 0.6407\n",
      "Epoch 160/500\n",
      "2/2 [==============================] - 1s 506ms/step - loss: 0.3369 - accuracy: 0.9500 - val_loss: 1.0142 - val_accuracy: 0.6426\n",
      "Epoch 161/500\n",
      "2/2 [==============================] - 0s 463ms/step - loss: 0.3338 - accuracy: 0.9500 - val_loss: 1.0138 - val_accuracy: 0.6421\n",
      "Epoch 162/500\n",
      "2/2 [==============================] - 1s 575ms/step - loss: 0.3332 - accuracy: 0.9500 - val_loss: 1.0157 - val_accuracy: 0.6407\n",
      "Epoch 163/500\n",
      "2/2 [==============================] - 1s 546ms/step - loss: 0.3320 - accuracy: 0.9333 - val_loss: 1.0178 - val_accuracy: 0.6397\n",
      "Epoch 164/500\n",
      "2/2 [==============================] - 1s 540ms/step - loss: 0.3322 - accuracy: 0.9333 - val_loss: 1.0091 - val_accuracy: 0.6466\n",
      "Epoch 165/500\n",
      "2/2 [==============================] - 1s 569ms/step - loss: 0.3288 - accuracy: 0.9333 - val_loss: 1.0095 - val_accuracy: 0.6431\n",
      "Epoch 166/500\n",
      "2/2 [==============================] - 0s 482ms/step - loss: 0.3238 - accuracy: 0.9500 - val_loss: 1.0105 - val_accuracy: 0.6424\n",
      "Epoch 167/500\n",
      "2/2 [==============================] - 1s 546ms/step - loss: 0.3248 - accuracy: 0.9333 - val_loss: 1.0046 - val_accuracy: 0.6466\n",
      "Epoch 168/500\n",
      "2/2 [==============================] - 0s 481ms/step - loss: 0.3203 - accuracy: 0.9500 - val_loss: 1.0067 - val_accuracy: 0.6447\n",
      "Epoch 169/500\n",
      "2/2 [==============================] - 1s 514ms/step - loss: 0.3210 - accuracy: 0.9500 - val_loss: 1.0031 - val_accuracy: 0.6486\n",
      "Epoch 170/500\n",
      "2/2 [==============================] - 1s 611ms/step - loss: 0.3177 - accuracy: 0.9500 - val_loss: 1.0025 - val_accuracy: 0.6492\n",
      "Epoch 171/500\n",
      "2/2 [==============================] - 0s 495ms/step - loss: 0.3149 - accuracy: 0.9500 - val_loss: 1.0043 - val_accuracy: 0.6456\n",
      "Epoch 172/500\n",
      "2/2 [==============================] - 0s 452ms/step - loss: 0.3147 - accuracy: 0.9500 - val_loss: 1.0045 - val_accuracy: 0.6467\n",
      "Epoch 173/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 1s 500ms/step - loss: 0.3117 - accuracy: 0.9500 - val_loss: 1.0064 - val_accuracy: 0.6447\n",
      "Epoch 174/500\n",
      "2/2 [==============================] - 1s 514ms/step - loss: 0.3094 - accuracy: 0.9500 - val_loss: 1.0063 - val_accuracy: 0.6437\n",
      "Epoch 175/500\n",
      "2/2 [==============================] - 1s 686ms/step - loss: 0.3082 - accuracy: 0.9667 - val_loss: 1.0064 - val_accuracy: 0.6432\n",
      "Epoch 176/500\n",
      "2/2 [==============================] - 1s 606ms/step - loss: 0.3077 - accuracy: 0.9667 - val_loss: 1.0025 - val_accuracy: 0.6474\n",
      "Epoch 177/500\n",
      "2/2 [==============================] - 1s 588ms/step - loss: 0.3037 - accuracy: 0.9667 - val_loss: 1.0015 - val_accuracy: 0.6460\n",
      "Epoch 178/500\n",
      "2/2 [==============================] - 1s 625ms/step - loss: 0.3020 - accuracy: 0.9667 - val_loss: 1.0004 - val_accuracy: 0.6460\n",
      "Epoch 179/500\n",
      "2/2 [==============================] - 1s 632ms/step - loss: 0.3035 - accuracy: 0.9667 - val_loss: 1.0014 - val_accuracy: 0.6443\n",
      "Epoch 180/500\n",
      "2/2 [==============================] - 0s 476ms/step - loss: 0.2999 - accuracy: 0.9667 - val_loss: 1.0021 - val_accuracy: 0.6433\n",
      "Epoch 181/500\n",
      "2/2 [==============================] - 1s 529ms/step - loss: 0.2993 - accuracy: 0.9500 - val_loss: 0.9954 - val_accuracy: 0.6480\n",
      "Epoch 182/500\n",
      "2/2 [==============================] - 1s 571ms/step - loss: 0.2984 - accuracy: 0.9667 - val_loss: 1.0004 - val_accuracy: 0.6443\n",
      "Epoch 183/500\n",
      "2/2 [==============================] - 1s 834ms/step - loss: 0.2940 - accuracy: 0.9667 - val_loss: 0.9989 - val_accuracy: 0.6455\n",
      "Epoch 184/500\n",
      "2/2 [==============================] - 1s 721ms/step - loss: 0.2928 - accuracy: 0.9667 - val_loss: 0.9996 - val_accuracy: 0.6451\n",
      "Epoch 185/500\n",
      "2/2 [==============================] - 1s 792ms/step - loss: 0.2930 - accuracy: 0.9667 - val_loss: 0.9942 - val_accuracy: 0.6491\n",
      "Epoch 186/500\n",
      "2/2 [==============================] - 1s 696ms/step - loss: 0.2899 - accuracy: 0.9667 - val_loss: 0.9982 - val_accuracy: 0.6460\n",
      "Epoch 187/500\n",
      "2/2 [==============================] - 1s 674ms/step - loss: 0.2895 - accuracy: 0.9667 - val_loss: 0.9966 - val_accuracy: 0.6461\n",
      "Epoch 188/500\n",
      "2/2 [==============================] - 1s 1s/step - loss: 0.2866 - accuracy: 0.9667 - val_loss: 0.9917 - val_accuracy: 0.6491\n",
      "Epoch 189/500\n",
      "2/2 [==============================] - 1s 1s/step - loss: 0.2871 - accuracy: 0.9667 - val_loss: 0.9878 - val_accuracy: 0.6521\n",
      "Epoch 190/500\n",
      "2/2 [==============================] - 1s 850ms/step - loss: 0.2823 - accuracy: 0.9667 - val_loss: 0.9916 - val_accuracy: 0.6492\n",
      "Epoch 191/500\n",
      "2/2 [==============================] - 1s 1s/step - loss: 0.2818 - accuracy: 0.9667 - val_loss: 0.9941 - val_accuracy: 0.6477\n",
      "Epoch 192/500\n",
      "2/2 [==============================] - 1s 1s/step - loss: 0.2807 - accuracy: 0.9667 - val_loss: 0.9924 - val_accuracy: 0.6491\n",
      "Epoch 193/500\n",
      "2/2 [==============================] - 1s 972ms/step - loss: 0.2798 - accuracy: 0.9667 - val_loss: 0.9897 - val_accuracy: 0.6499\n",
      "Epoch 194/500\n",
      "2/2 [==============================] - 1s 721ms/step - loss: 0.2760 - accuracy: 0.9667 - val_loss: 0.9916 - val_accuracy: 0.6484\n",
      "Epoch 195/500\n",
      "2/2 [==============================] - 1s 603ms/step - loss: 0.2749 - accuracy: 0.9667 - val_loss: 0.9906 - val_accuracy: 0.6489\n",
      "Epoch 196/500\n",
      "2/2 [==============================] - 0s 494ms/step - loss: 0.2771 - accuracy: 0.9667 - val_loss: 0.9961 - val_accuracy: 0.6444\n",
      "Epoch 197/500\n",
      "2/2 [==============================] - 1s 580ms/step - loss: 0.2728 - accuracy: 0.9667 - val_loss: 0.9901 - val_accuracy: 0.6490\n",
      "Epoch 198/500\n",
      "2/2 [==============================] - 1s 607ms/step - loss: 0.2708 - accuracy: 0.9667 - val_loss: 0.9912 - val_accuracy: 0.6481\n",
      "Epoch 199/500\n",
      "2/2 [==============================] - 1s 646ms/step - loss: 0.2713 - accuracy: 0.9667 - val_loss: 0.9942 - val_accuracy: 0.6451\n",
      "Epoch 200/500\n",
      "2/2 [==============================] - 1s 961ms/step - loss: 0.2686 - accuracy: 0.9667 - val_loss: 0.9883 - val_accuracy: 0.6504\n",
      "Epoch 201/500\n",
      "2/2 [==============================] - 1s 669ms/step - loss: 0.2675 - accuracy: 0.9667 - val_loss: 0.9858 - val_accuracy: 0.6516\n",
      "Epoch 202/500\n",
      "2/2 [==============================] - 1s 632ms/step - loss: 0.2660 - accuracy: 0.9667 - val_loss: 0.9869 - val_accuracy: 0.6516\n",
      "Epoch 203/500\n",
      "2/2 [==============================] - 1s 530ms/step - loss: 0.2654 - accuracy: 0.9667 - val_loss: 0.9907 - val_accuracy: 0.6492\n",
      "Epoch 204/500\n",
      "2/2 [==============================] - 1s 657ms/step - loss: 0.2646 - accuracy: 0.9667 - val_loss: 0.9869 - val_accuracy: 0.6528\n",
      "Epoch 205/500\n",
      "2/2 [==============================] - 1s 669ms/step - loss: 0.2602 - accuracy: 0.9667 - val_loss: 0.9880 - val_accuracy: 0.6504\n",
      "Epoch 206/500\n",
      "2/2 [==============================] - 1s 586ms/step - loss: 0.2592 - accuracy: 0.9667 - val_loss: 0.9882 - val_accuracy: 0.6496\n",
      "Epoch 207/500\n",
      "2/2 [==============================] - 1s 527ms/step - loss: 0.2593 - accuracy: 0.9667 - val_loss: 0.9915 - val_accuracy: 0.6471\n",
      "Epoch 208/500\n",
      "2/2 [==============================] - 1s 516ms/step - loss: 0.2586 - accuracy: 0.9667 - val_loss: 0.9880 - val_accuracy: 0.6498\n",
      "Epoch 209/500\n",
      "2/2 [==============================] - 1s 929ms/step - loss: 0.2580 - accuracy: 0.9667 - val_loss: 0.9902 - val_accuracy: 0.6484\n",
      "Epoch 210/500\n",
      "2/2 [==============================] - 1s 673ms/step - loss: 0.2538 - accuracy: 0.9667 - val_loss: 0.9887 - val_accuracy: 0.6486\n",
      "Epoch 211/500\n",
      "2/2 [==============================] - 1s 732ms/step - loss: 0.2533 - accuracy: 0.9667 - val_loss: 0.9856 - val_accuracy: 0.6518\n",
      "Epoch 212/500\n",
      "2/2 [==============================] - 0s 486ms/step - loss: 0.2510 - accuracy: 0.9667 - val_loss: 0.9841 - val_accuracy: 0.6529\n",
      "Epoch 213/500\n",
      "2/2 [==============================] - 1s 530ms/step - loss: 0.2512 - accuracy: 0.9667 - val_loss: 0.9817 - val_accuracy: 0.6530\n",
      "Epoch 214/500\n",
      "2/2 [==============================] - 0s 462ms/step - loss: 0.2499 - accuracy: 0.9833 - val_loss: 0.9823 - val_accuracy: 0.6513\n",
      "Epoch 215/500\n",
      "2/2 [==============================] - 0s 450ms/step - loss: 0.2478 - accuracy: 0.9667 - val_loss: 0.9848 - val_accuracy: 0.6493\n",
      "Epoch 216/500\n",
      "2/2 [==============================] - 0s 449ms/step - loss: 0.2489 - accuracy: 0.9667 - val_loss: 0.9876 - val_accuracy: 0.6473\n",
      "Epoch 217/500\n",
      "2/2 [==============================] - 0s 463ms/step - loss: 0.2473 - accuracy: 0.9667 - val_loss: 0.9843 - val_accuracy: 0.6492\n",
      "Epoch 218/500\n",
      "2/2 [==============================] - 1s 542ms/step - loss: 0.2433 - accuracy: 0.9667 - val_loss: 0.9831 - val_accuracy: 0.6499\n",
      "Epoch 219/500\n",
      "2/2 [==============================] - 1s 501ms/step - loss: 0.2421 - accuracy: 0.9667 - val_loss: 0.9802 - val_accuracy: 0.6525\n",
      "Epoch 220/500\n",
      "2/2 [==============================] - 1s 542ms/step - loss: 0.2413 - accuracy: 0.9667 - val_loss: 0.9786 - val_accuracy: 0.6540\n",
      "Epoch 221/500\n",
      "2/2 [==============================] - 1s 536ms/step - loss: 0.2401 - accuracy: 0.9833 - val_loss: 0.9816 - val_accuracy: 0.6516\n",
      "Epoch 222/500\n",
      "2/2 [==============================] - 1s 525ms/step - loss: 0.2384 - accuracy: 0.9833 - val_loss: 0.9806 - val_accuracy: 0.6518\n",
      "Epoch 223/500\n",
      "2/2 [==============================] - 0s 485ms/step - loss: 0.2375 - accuracy: 0.9667 - val_loss: 0.9773 - val_accuracy: 0.6549\n",
      "Epoch 224/500\n",
      "2/2 [==============================] - 1s 869ms/step - loss: 0.2357 - accuracy: 1.0000 - val_loss: 0.9778 - val_accuracy: 0.6544\n",
      "Epoch 225/500\n",
      "2/2 [==============================] - 1s 771ms/step - loss: 0.2354 - accuracy: 0.9667 - val_loss: 0.9773 - val_accuracy: 0.6550\n",
      "Epoch 226/500\n",
      "2/2 [==============================] - 1s 972ms/step - loss: 0.2350 - accuracy: 0.9667 - val_loss: 0.9745 - val_accuracy: 0.6550\n",
      "Epoch 227/500\n",
      "2/2 [==============================] - 1s 651ms/step - loss: 0.2345 - accuracy: 0.9833 - val_loss: 0.9724 - val_accuracy: 0.6561\n",
      "Epoch 228/500\n",
      "2/2 [==============================] - 1s 679ms/step - loss: 0.2338 - accuracy: 1.0000 - val_loss: 0.9786 - val_accuracy: 0.6533\n",
      "Epoch 229/500\n",
      "2/2 [==============================] - 1s 588ms/step - loss: 0.2311 - accuracy: 0.9833 - val_loss: 0.9759 - val_accuracy: 0.6556\n",
      "Epoch 230/500\n",
      "2/2 [==============================] - 1s 839ms/step - loss: 0.2293 - accuracy: 1.0000 - val_loss: 0.9769 - val_accuracy: 0.6549\n",
      "Epoch 231/500\n",
      "2/2 [==============================] - 1s 987ms/step - loss: 0.2301 - accuracy: 0.9833 - val_loss: 0.9723 - val_accuracy: 0.6564\n",
      "Epoch 232/500\n",
      "2/2 [==============================] - 2s 2s/step - loss: 0.2268 - accuracy: 1.0000 - val_loss: 0.9757 - val_accuracy: 0.6554\n",
      "Epoch 233/500\n",
      "2/2 [==============================] - 1s 582ms/step - loss: 0.2264 - accuracy: 1.0000 - val_loss: 0.9772 - val_accuracy: 0.6545\n",
      "Epoch 234/500\n",
      "2/2 [==============================] - 0s 474ms/step - loss: 0.2246 - accuracy: 0.9833 - val_loss: 0.9768 - val_accuracy: 0.6542\n",
      "Epoch 235/500\n",
      "2/2 [==============================] - 0s 444ms/step - loss: 0.2241 - accuracy: 1.0000 - val_loss: 0.9780 - val_accuracy: 0.6537\n",
      "Epoch 236/500\n",
      "2/2 [==============================] - 1s 580ms/step - loss: 0.2233 - accuracy: 0.9667 - val_loss: 0.9734 - val_accuracy: 0.6560\n",
      "Epoch 237/500\n",
      "2/2 [==============================] - 0s 458ms/step - loss: 0.2237 - accuracy: 1.0000 - val_loss: 0.9767 - val_accuracy: 0.6559\n",
      "Epoch 238/500\n",
      "2/2 [==============================] - 1s 544ms/step - loss: 0.2217 - accuracy: 0.9833 - val_loss: 0.9783 - val_accuracy: 0.6546\n",
      "Epoch 239/500\n",
      "2/2 [==============================] - 1s 527ms/step - loss: 0.2202 - accuracy: 1.0000 - val_loss: 0.9794 - val_accuracy: 0.6536\n",
      "Epoch 240/500\n",
      "2/2 [==============================] - 1s 831ms/step - loss: 0.2184 - accuracy: 1.0000 - val_loss: 0.9790 - val_accuracy: 0.6537\n",
      "Epoch 241/500\n",
      "2/2 [==============================] - 1s 1s/step - loss: 0.2185 - accuracy: 0.9833 - val_loss: 0.9774 - val_accuracy: 0.6544\n",
      "Epoch 242/500\n",
      "2/2 [==============================] - 1s 1s/step - loss: 0.2158 - accuracy: 1.0000 - val_loss: 0.9740 - val_accuracy: 0.6568\n",
      "Epoch 243/500\n",
      "2/2 [==============================] - 1s 1s/step - loss: 0.2150 - accuracy: 1.0000 - val_loss: 0.9741 - val_accuracy: 0.6563\n",
      "Epoch 244/500\n",
      "2/2 [==============================] - 1s 951ms/step - loss: 0.2138 - accuracy: 1.0000 - val_loss: 0.9747 - val_accuracy: 0.6559\n",
      "Epoch 245/500\n",
      "2/2 [==============================] - 1s 1s/step - loss: 0.2132 - accuracy: 1.0000 - val_loss: 0.9712 - val_accuracy: 0.6576\n",
      "Epoch 246/500\n",
      "2/2 [==============================] - 1s 827ms/step - loss: 0.2122 - accuracy: 1.0000 - val_loss: 0.9740 - val_accuracy: 0.6566\n",
      "Epoch 247/500\n",
      "2/2 [==============================] - 1s 820ms/step - loss: 0.2158 - accuracy: 0.9667 - val_loss: 0.9660 - val_accuracy: 0.6595\n",
      "Epoch 248/500\n",
      "2/2 [==============================] - 1s 759ms/step - loss: 0.2104 - accuracy: 1.0000 - val_loss: 0.9702 - val_accuracy: 0.6591\n",
      "Epoch 249/500\n",
      "2/2 [==============================] - 1s 888ms/step - loss: 0.2105 - accuracy: 0.9833 - val_loss: 0.9667 - val_accuracy: 0.6601\n",
      "Epoch 250/500\n",
      "2/2 [==============================] - 1s 1s/step - loss: 0.2097 - accuracy: 1.0000 - val_loss: 0.9661 - val_accuracy: 0.6596\n",
      "Epoch 251/500\n",
      "2/2 [==============================] - 1s 671ms/step - loss: 0.2075 - accuracy: 1.0000 - val_loss: 0.9686 - val_accuracy: 0.6594\n",
      "Epoch 252/500\n",
      "2/2 [==============================] - 1s 630ms/step - loss: 0.2058 - accuracy: 1.0000 - val_loss: 0.9691 - val_accuracy: 0.6587\n",
      "Epoch 253/500\n",
      "2/2 [==============================] - 1s 549ms/step - loss: 0.2046 - accuracy: 1.0000 - val_loss: 0.9696 - val_accuracy: 0.6586\n",
      "Epoch 254/500\n",
      "2/2 [==============================] - 0s 477ms/step - loss: 0.2050 - accuracy: 1.0000 - val_loss: 0.9727 - val_accuracy: 0.6573\n",
      "Epoch 255/500\n",
      "2/2 [==============================] - 0s 472ms/step - loss: 0.2044 - accuracy: 1.0000 - val_loss: 0.9696 - val_accuracy: 0.6597\n",
      "Epoch 256/500\n",
      "2/2 [==============================] - 1s 737ms/step - loss: 0.2023 - accuracy: 1.0000 - val_loss: 0.9681 - val_accuracy: 0.6600\n",
      "Epoch 257/500\n",
      "2/2 [==============================] - 1s 914ms/step - loss: 0.2023 - accuracy: 1.0000 - val_loss: 0.9679 - val_accuracy: 0.6595\n",
      "Epoch 258/500\n",
      "2/2 [==============================] - 0s 484ms/step - loss: 0.1998 - accuracy: 1.0000 - val_loss: 0.9686 - val_accuracy: 0.6588\n",
      "Epoch 259/500\n",
      "2/2 [==============================] - 0s 485ms/step - loss: 0.2002 - accuracy: 1.0000 - val_loss: 0.9710 - val_accuracy: 0.6586\n",
      "Epoch 260/500\n",
      "2/2 [==============================] - 0s 461ms/step - loss: 0.2013 - accuracy: 0.9833 - val_loss: 0.9644 - val_accuracy: 0.6608\n",
      "Epoch 261/500\n",
      "2/2 [==============================] - 1s 515ms/step - loss: 0.1988 - accuracy: 1.0000 - val_loss: 0.9700 - val_accuracy: 0.6590\n",
      "Epoch 262/500\n",
      "2/2 [==============================] - 0s 436ms/step - loss: 0.1979 - accuracy: 1.0000 - val_loss: 0.9672 - val_accuracy: 0.6596\n",
      "Epoch 263/500\n",
      "2/2 [==============================] - 0s 439ms/step - loss: 0.1956 - accuracy: 1.0000 - val_loss: 0.9671 - val_accuracy: 0.6598\n",
      "Epoch 264/500\n",
      "2/2 [==============================] - 0s 444ms/step - loss: 0.1961 - accuracy: 1.0000 - val_loss: 0.9651 - val_accuracy: 0.6601\n",
      "Epoch 265/500\n",
      "2/2 [==============================] - 0s 441ms/step - loss: 0.1937 - accuracy: 1.0000 - val_loss: 0.9664 - val_accuracy: 0.6599\n",
      "Epoch 266/500\n",
      "2/2 [==============================] - 0s 446ms/step - loss: 0.1932 - accuracy: 1.0000 - val_loss: 0.9689 - val_accuracy: 0.6596\n",
      "Epoch 267/500\n",
      "2/2 [==============================] - 0s 441ms/step - loss: 0.1947 - accuracy: 1.0000 - val_loss: 0.9746 - val_accuracy: 0.6561\n",
      "Epoch 268/500\n",
      "2/2 [==============================] - 1s 524ms/step - loss: 0.1919 - accuracy: 1.0000 - val_loss: 0.9709 - val_accuracy: 0.6587\n",
      "Epoch 269/500\n",
      "2/2 [==============================] - 1s 631ms/step - loss: 0.1904 - accuracy: 1.0000 - val_loss: 0.9705 - val_accuracy: 0.6591\n",
      "Epoch 270/500\n",
      "2/2 [==============================] - 1s 849ms/step - loss: 0.1894 - accuracy: 1.0000 - val_loss: 0.9697 - val_accuracy: 0.6591\n",
      "Epoch 271/500\n",
      "2/2 [==============================] - 1s 562ms/step - loss: 0.1882 - accuracy: 1.0000 - val_loss: 0.9673 - val_accuracy: 0.6603\n",
      "Epoch 272/500\n",
      "2/2 [==============================] - 1s 534ms/step - loss: 0.1895 - accuracy: 1.0000 - val_loss: 0.9713 - val_accuracy: 0.6589\n",
      "Epoch 273/500\n",
      "2/2 [==============================] - 0s 469ms/step - loss: 0.1868 - accuracy: 1.0000 - val_loss: 0.9685 - val_accuracy: 0.6598\n",
      "Epoch 274/500\n",
      "2/2 [==============================] - 0s 466ms/step - loss: 0.1860 - accuracy: 1.0000 - val_loss: 0.9665 - val_accuracy: 0.6601\n",
      "Epoch 275/500\n",
      "2/2 [==============================] - 0s 479ms/step - loss: 0.1856 - accuracy: 1.0000 - val_loss: 0.9681 - val_accuracy: 0.6606\n",
      "Epoch 276/500\n",
      "2/2 [==============================] - 0s 457ms/step - loss: 0.1866 - accuracy: 1.0000 - val_loss: 0.9634 - val_accuracy: 0.6607\n",
      "Epoch 277/500\n",
      "2/2 [==============================] - 0s 457ms/step - loss: 0.1832 - accuracy: 1.0000 - val_loss: 0.9654 - val_accuracy: 0.6602\n",
      "Epoch 278/500\n",
      "2/2 [==============================] - 0s 449ms/step - loss: 0.1830 - accuracy: 1.0000 - val_loss: 0.9664 - val_accuracy: 0.6603\n",
      "Epoch 279/500\n",
      "2/2 [==============================] - 0s 457ms/step - loss: 0.1821 - accuracy: 1.0000 - val_loss: 0.9643 - val_accuracy: 0.6604\n",
      "Epoch 280/500\n",
      "2/2 [==============================] - 0s 446ms/step - loss: 0.1817 - accuracy: 1.0000 - val_loss: 0.9649 - val_accuracy: 0.6603\n",
      "Epoch 281/500\n",
      "2/2 [==============================] - 0s 432ms/step - loss: 0.1803 - accuracy: 1.0000 - val_loss: 0.9638 - val_accuracy: 0.6601\n",
      "Epoch 282/500\n",
      "2/2 [==============================] - 0s 441ms/step - loss: 0.1809 - accuracy: 1.0000 - val_loss: 0.9649 - val_accuracy: 0.6600\n",
      "Epoch 283/500\n",
      "2/2 [==============================] - 0s 435ms/step - loss: 0.1788 - accuracy: 1.0000 - val_loss: 0.9655 - val_accuracy: 0.6597\n",
      "Epoch 284/500\n",
      "2/2 [==============================] - 0s 436ms/step - loss: 0.1780 - accuracy: 1.0000 - val_loss: 0.9652 - val_accuracy: 0.6602\n",
      "Epoch 285/500\n",
      "2/2 [==============================] - 1s 579ms/step - loss: 0.1773 - accuracy: 1.0000 - val_loss: 0.9637 - val_accuracy: 0.6601\n",
      "Epoch 286/500\n",
      "2/2 [==============================] - 1s 641ms/step - loss: 0.1762 - accuracy: 1.0000 - val_loss: 0.9628 - val_accuracy: 0.6603\n",
      "Epoch 287/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 1s 777ms/step - loss: 0.1755 - accuracy: 1.0000 - val_loss: 0.9650 - val_accuracy: 0.6600\n",
      "Epoch 288/500\n",
      "2/2 [==============================] - 1s 598ms/step - loss: 0.1743 - accuracy: 1.0000 - val_loss: 0.9643 - val_accuracy: 0.6604\n",
      "Epoch 289/500\n",
      "2/2 [==============================] - 1s 527ms/step - loss: 0.1740 - accuracy: 1.0000 - val_loss: 0.9652 - val_accuracy: 0.6602\n",
      "Epoch 290/500\n",
      "2/2 [==============================] - 1s 520ms/step - loss: 0.1747 - accuracy: 1.0000 - val_loss: 0.9633 - val_accuracy: 0.6605\n",
      "Epoch 291/500\n",
      "2/2 [==============================] - 0s 449ms/step - loss: 0.1725 - accuracy: 1.0000 - val_loss: 0.9652 - val_accuracy: 0.6604\n",
      "Epoch 292/500\n",
      "2/2 [==============================] - 0s 437ms/step - loss: 0.1716 - accuracy: 1.0000 - val_loss: 0.9660 - val_accuracy: 0.6600\n",
      "Epoch 293/500\n",
      "2/2 [==============================] - 0s 456ms/step - loss: 0.1710 - accuracy: 1.0000 - val_loss: 0.9651 - val_accuracy: 0.6603\n",
      "Epoch 294/500\n",
      "2/2 [==============================] - 0s 448ms/step - loss: 0.1709 - accuracy: 1.0000 - val_loss: 0.9641 - val_accuracy: 0.6602\n",
      "Epoch 295/500\n",
      "2/2 [==============================] - 0s 456ms/step - loss: 0.1692 - accuracy: 1.0000 - val_loss: 0.9639 - val_accuracy: 0.6602\n",
      "Epoch 296/500\n",
      "2/2 [==============================] - 1s 502ms/step - loss: 0.1690 - accuracy: 1.0000 - val_loss: 0.9623 - val_accuracy: 0.6605\n",
      "Epoch 297/500\n",
      "2/2 [==============================] - 0s 486ms/step - loss: 0.1681 - accuracy: 1.0000 - val_loss: 0.9637 - val_accuracy: 0.6599\n",
      "Epoch 298/500\n",
      "2/2 [==============================] - 0s 444ms/step - loss: 0.1687 - accuracy: 1.0000 - val_loss: 0.9619 - val_accuracy: 0.6613\n",
      "Epoch 299/500\n",
      "2/2 [==============================] - 0s 470ms/step - loss: 0.1701 - accuracy: 1.0000 - val_loss: 0.9685 - val_accuracy: 0.6596\n",
      "Epoch 300/500\n",
      "2/2 [==============================] - 0s 493ms/step - loss: 0.1662 - accuracy: 1.0000 - val_loss: 0.9671 - val_accuracy: 0.6602\n",
      "Epoch 301/500\n",
      "2/2 [==============================] - 1s 541ms/step - loss: 0.1656 - accuracy: 1.0000 - val_loss: 0.9639 - val_accuracy: 0.6604\n",
      "Epoch 302/500\n",
      "2/2 [==============================] - 1s 514ms/step - loss: 0.1645 - accuracy: 1.0000 - val_loss: 0.9641 - val_accuracy: 0.6604\n",
      "Epoch 303/500\n",
      "2/2 [==============================] - 0s 460ms/step - loss: 0.1643 - accuracy: 1.0000 - val_loss: 0.9622 - val_accuracy: 0.6602\n",
      "Epoch 304/500\n",
      "2/2 [==============================] - 1s 661ms/step - loss: 0.1630 - accuracy: 1.0000 - val_loss: 0.9614 - val_accuracy: 0.6606\n",
      "Epoch 305/500\n",
      "2/2 [==============================] - 1s 596ms/step - loss: 0.1630 - accuracy: 1.0000 - val_loss: 0.9653 - val_accuracy: 0.6598\n",
      "Epoch 306/500\n",
      "2/2 [==============================] - 1s 605ms/step - loss: 0.1617 - accuracy: 1.0000 - val_loss: 0.9643 - val_accuracy: 0.6594\n",
      "Epoch 307/500\n",
      "2/2 [==============================] - 1s 1s/step - loss: 0.1609 - accuracy: 1.0000 - val_loss: 0.9630 - val_accuracy: 0.6599\n",
      "Epoch 308/500\n",
      "2/2 [==============================] - 1s 931ms/step - loss: 0.1612 - accuracy: 1.0000 - val_loss: 0.9644 - val_accuracy: 0.6595\n",
      "Epoch 309/500\n",
      "2/2 [==============================] - 1s 618ms/step - loss: 0.1596 - accuracy: 1.0000 - val_loss: 0.9634 - val_accuracy: 0.6595\n",
      "Epoch 310/500\n",
      "2/2 [==============================] - 0s 488ms/step - loss: 0.1591 - accuracy: 1.0000 - val_loss: 0.9632 - val_accuracy: 0.6596\n",
      "Epoch 311/500\n",
      "2/2 [==============================] - 0s 456ms/step - loss: 0.1585 - accuracy: 1.0000 - val_loss: 0.9618 - val_accuracy: 0.6610\n",
      "Epoch 312/500\n",
      "2/2 [==============================] - 0s 454ms/step - loss: 0.1575 - accuracy: 1.0000 - val_loss: 0.9622 - val_accuracy: 0.6605\n",
      "Epoch 313/500\n",
      "2/2 [==============================] - 0s 453ms/step - loss: 0.1576 - accuracy: 1.0000 - val_loss: 0.9603 - val_accuracy: 0.6608\n",
      "Epoch 314/500\n",
      "2/2 [==============================] - 0s 455ms/step - loss: 0.1572 - accuracy: 1.0000 - val_loss: 0.9640 - val_accuracy: 0.6594\n",
      "Epoch 315/500\n",
      "2/2 [==============================] - 0s 452ms/step - loss: 0.1554 - accuracy: 1.0000 - val_loss: 0.9624 - val_accuracy: 0.6602\n",
      "Epoch 316/500\n",
      "2/2 [==============================] - 0s 445ms/step - loss: 0.1557 - accuracy: 1.0000 - val_loss: 0.9642 - val_accuracy: 0.6596\n",
      "Epoch 317/500\n",
      "2/2 [==============================] - 0s 446ms/step - loss: 0.1556 - accuracy: 1.0000 - val_loss: 0.9663 - val_accuracy: 0.6596\n",
      "Epoch 318/500\n",
      "2/2 [==============================] - 0s 448ms/step - loss: 0.1554 - accuracy: 1.0000 - val_loss: 0.9656 - val_accuracy: 0.6591\n",
      "Epoch 319/500\n",
      "2/2 [==============================] - 0s 436ms/step - loss: 0.1531 - accuracy: 1.0000 - val_loss: 0.9629 - val_accuracy: 0.6598\n",
      "Epoch 320/500\n",
      "2/2 [==============================] - 0s 444ms/step - loss: 0.1526 - accuracy: 1.0000 - val_loss: 0.9606 - val_accuracy: 0.6610\n",
      "Epoch 321/500\n",
      "2/2 [==============================] - 0s 430ms/step - loss: 0.1516 - accuracy: 1.0000 - val_loss: 0.9614 - val_accuracy: 0.6607\n",
      "Epoch 322/500\n",
      "2/2 [==============================] - 1s 503ms/step - loss: 0.1511 - accuracy: 1.0000 - val_loss: 0.9611 - val_accuracy: 0.6606\n",
      "Epoch 323/500\n",
      "2/2 [==============================] - 1s 621ms/step - loss: 0.1507 - accuracy: 1.0000 - val_loss: 0.9623 - val_accuracy: 0.6599\n",
      "Epoch 324/500\n",
      "2/2 [==============================] - 1s 514ms/step - loss: 0.1500 - accuracy: 1.0000 - val_loss: 0.9619 - val_accuracy: 0.6598\n",
      "Epoch 325/500\n",
      "2/2 [==============================] - 1s 573ms/step - loss: 0.1495 - accuracy: 1.0000 - val_loss: 0.9605 - val_accuracy: 0.6611\n",
      "Epoch 326/500\n",
      "2/2 [==============================] - 0s 489ms/step - loss: 0.1488 - accuracy: 1.0000 - val_loss: 0.9633 - val_accuracy: 0.6602\n",
      "Epoch 327/500\n",
      "2/2 [==============================] - 1s 639ms/step - loss: 0.1487 - accuracy: 1.0000 - val_loss: 0.9593 - val_accuracy: 0.6621\n",
      "Epoch 328/500\n",
      "2/2 [==============================] - 1s 746ms/step - loss: 0.1478 - accuracy: 1.0000 - val_loss: 0.9596 - val_accuracy: 0.6619\n",
      "Epoch 329/500\n",
      "2/2 [==============================] - 1s 634ms/step - loss: 0.1470 - accuracy: 1.0000 - val_loss: 0.9596 - val_accuracy: 0.6619\n",
      "Epoch 330/500\n",
      "2/2 [==============================] - 1s 822ms/step - loss: 0.1461 - accuracy: 1.0000 - val_loss: 0.9613 - val_accuracy: 0.6608\n",
      "Epoch 331/500\n",
      "2/2 [==============================] - 1s 782ms/step - loss: 0.1455 - accuracy: 1.0000 - val_loss: 0.9611 - val_accuracy: 0.6606\n",
      "Epoch 332/500\n",
      "2/2 [==============================] - 1s 737ms/step - loss: 0.1455 - accuracy: 1.0000 - val_loss: 0.9595 - val_accuracy: 0.6626\n",
      "Epoch 333/500\n",
      "2/2 [==============================] - 2s 2s/step - loss: 0.1446 - accuracy: 1.0000 - val_loss: 0.9596 - val_accuracy: 0.6623\n",
      "Epoch 334/500\n",
      "2/2 [==============================] - 1s 962ms/step - loss: 0.1444 - accuracy: 1.0000 - val_loss: 0.9586 - val_accuracy: 0.6633\n",
      "Epoch 335/500\n",
      "2/2 [==============================] - 1s 975ms/step - loss: 0.1444 - accuracy: 1.0000 - val_loss: 0.9606 - val_accuracy: 0.6624\n",
      "Epoch 336/500\n",
      "2/2 [==============================] - 1s 1s/step - loss: 0.1447 - accuracy: 1.0000 - val_loss: 0.9582 - val_accuracy: 0.6634\n",
      "Epoch 337/500\n",
      "2/2 [==============================] - 1s 1s/step - loss: 0.1429 - accuracy: 1.0000 - val_loss: 0.9608 - val_accuracy: 0.6627\n",
      "Epoch 338/500\n",
      "2/2 [==============================] - 1s 884ms/step - loss: 0.1418 - accuracy: 1.0000 - val_loss: 0.9597 - val_accuracy: 0.6632\n",
      "Epoch 339/500\n",
      "2/2 [==============================] - 1s 872ms/step - loss: 0.1421 - accuracy: 1.0000 - val_loss: 0.9623 - val_accuracy: 0.6621\n",
      "Epoch 340/500\n",
      "2/2 [==============================] - 1s 791ms/step - loss: 0.1426 - accuracy: 1.0000 - val_loss: 0.9657 - val_accuracy: 0.6606\n",
      "Epoch 341/500\n",
      "2/2 [==============================] - 1s 859ms/step - loss: 0.1400 - accuracy: 1.0000 - val_loss: 0.9625 - val_accuracy: 0.6614\n",
      "Epoch 342/500\n",
      "2/2 [==============================] - 1s 780ms/step - loss: 0.1410 - accuracy: 1.0000 - val_loss: 0.9652 - val_accuracy: 0.6603\n",
      "Epoch 343/500\n",
      "2/2 [==============================] - 1s 1s/step - loss: 0.1393 - accuracy: 1.0000 - val_loss: 0.9616 - val_accuracy: 0.6615\n",
      "Epoch 344/500\n",
      "2/2 [==============================] - 1s 806ms/step - loss: 0.1394 - accuracy: 1.0000 - val_loss: 0.9579 - val_accuracy: 0.6633\n",
      "Epoch 345/500\n",
      "2/2 [==============================] - 1s 731ms/step - loss: 0.1402 - accuracy: 1.0000 - val_loss: 0.9554 - val_accuracy: 0.6636\n",
      "Epoch 346/500\n",
      "2/2 [==============================] - 1s 686ms/step - loss: 0.1373 - accuracy: 1.0000 - val_loss: 0.9584 - val_accuracy: 0.6624\n",
      "Epoch 347/500\n",
      "2/2 [==============================] - 1s 655ms/step - loss: 0.1367 - accuracy: 1.0000 - val_loss: 0.9606 - val_accuracy: 0.6620\n",
      "Epoch 348/500\n",
      "2/2 [==============================] - 1s 689ms/step - loss: 0.1372 - accuracy: 1.0000 - val_loss: 0.9631 - val_accuracy: 0.6605\n",
      "Epoch 349/500\n",
      "2/2 [==============================] - 1s 645ms/step - loss: 0.1356 - accuracy: 1.0000 - val_loss: 0.9634 - val_accuracy: 0.6606\n",
      "Epoch 350/500\n",
      "2/2 [==============================] - 1s 724ms/step - loss: 0.1370 - accuracy: 1.0000 - val_loss: 0.9659 - val_accuracy: 0.6604\n",
      "Epoch 351/500\n",
      "2/2 [==============================] - 1s 749ms/step - loss: 0.1348 - accuracy: 1.0000 - val_loss: 0.9626 - val_accuracy: 0.6616\n",
      "Epoch 352/500\n",
      "2/2 [==============================] - 0s 474ms/step - loss: 0.1341 - accuracy: 1.0000 - val_loss: 0.9637 - val_accuracy: 0.6607\n",
      "Epoch 353/500\n",
      "2/2 [==============================] - 0s 458ms/step - loss: 0.1336 - accuracy: 1.0000 - val_loss: 0.9631 - val_accuracy: 0.6612\n",
      "Epoch 354/500\n",
      "2/2 [==============================] - 0s 444ms/step - loss: 0.1331 - accuracy: 1.0000 - val_loss: 0.9624 - val_accuracy: 0.6615\n",
      "Epoch 355/500\n",
      "2/2 [==============================] - 0s 483ms/step - loss: 0.1329 - accuracy: 1.0000 - val_loss: 0.9627 - val_accuracy: 0.6615\n",
      "Epoch 356/500\n",
      "2/2 [==============================] - 1s 530ms/step - loss: 0.1329 - accuracy: 1.0000 - val_loss: 0.9593 - val_accuracy: 0.6630\n",
      "Epoch 357/500\n",
      "2/2 [==============================] - 1s 661ms/step - loss: 0.1315 - accuracy: 1.0000 - val_loss: 0.9595 - val_accuracy: 0.6628\n",
      "Epoch 358/500\n",
      "2/2 [==============================] - 0s 459ms/step - loss: 0.1311 - accuracy: 1.0000 - val_loss: 0.9593 - val_accuracy: 0.6633\n",
      "Epoch 359/500\n",
      "2/2 [==============================] - 0s 453ms/step - loss: 0.1309 - accuracy: 1.0000 - val_loss: 0.9619 - val_accuracy: 0.6621\n",
      "Epoch 360/500\n",
      "2/2 [==============================] - 1s 519ms/step - loss: 0.1299 - accuracy: 1.0000 - val_loss: 0.9623 - val_accuracy: 0.6613\n",
      "Epoch 361/500\n",
      "2/2 [==============================] - 0s 459ms/step - loss: 0.1312 - accuracy: 1.0000 - val_loss: 0.9652 - val_accuracy: 0.6606\n",
      "Epoch 362/500\n",
      "2/2 [==============================] - 0s 461ms/step - loss: 0.1295 - accuracy: 1.0000 - val_loss: 0.9664 - val_accuracy: 0.6607\n",
      "Epoch 363/500\n",
      "2/2 [==============================] - 1s 665ms/step - loss: 0.1289 - accuracy: 1.0000 - val_loss: 0.9662 - val_accuracy: 0.6609\n",
      "Epoch 364/500\n",
      "2/2 [==============================] - 1s 559ms/step - loss: 0.1277 - accuracy: 1.0000 - val_loss: 0.9627 - val_accuracy: 0.6622\n",
      "Epoch 365/500\n",
      "2/2 [==============================] - 0s 451ms/step - loss: 0.1275 - accuracy: 1.0000 - val_loss: 0.9634 - val_accuracy: 0.6613\n",
      "Epoch 366/500\n",
      "2/2 [==============================] - 0s 491ms/step - loss: 0.1267 - accuracy: 1.0000 - val_loss: 0.9624 - val_accuracy: 0.6618\n",
      "Epoch 367/500\n",
      "2/2 [==============================] - 0s 453ms/step - loss: 0.1267 - accuracy: 1.0000 - val_loss: 0.9590 - val_accuracy: 0.6629\n",
      "Epoch 368/500\n",
      "2/2 [==============================] - 0s 453ms/step - loss: 0.1256 - accuracy: 1.0000 - val_loss: 0.9606 - val_accuracy: 0.6625\n",
      "Epoch 369/500\n",
      "2/2 [==============================] - 0s 452ms/step - loss: 0.1251 - accuracy: 1.0000 - val_loss: 0.9596 - val_accuracy: 0.6628\n",
      "Epoch 370/500\n",
      "2/2 [==============================] - 1s 574ms/step - loss: 0.1247 - accuracy: 1.0000 - val_loss: 0.9596 - val_accuracy: 0.6632\n",
      "Epoch 371/500\n",
      "2/2 [==============================] - 0s 459ms/step - loss: 0.1244 - accuracy: 1.0000 - val_loss: 0.9607 - val_accuracy: 0.6626\n",
      "Epoch 372/500\n",
      "2/2 [==============================] - 1s 574ms/step - loss: 0.1239 - accuracy: 1.0000 - val_loss: 0.9600 - val_accuracy: 0.6632\n",
      "Epoch 373/500\n",
      "2/2 [==============================] - 1s 551ms/step - loss: 0.1234 - accuracy: 1.0000 - val_loss: 0.9593 - val_accuracy: 0.6629\n",
      "Epoch 374/500\n",
      "2/2 [==============================] - 1s 578ms/step - loss: 0.1240 - accuracy: 1.0000 - val_loss: 0.9621 - val_accuracy: 0.6624\n",
      "Epoch 375/500\n",
      "2/2 [==============================] - 0s 449ms/step - loss: 0.1223 - accuracy: 1.0000 - val_loss: 0.9602 - val_accuracy: 0.6627\n",
      "Epoch 376/500\n",
      "2/2 [==============================] - 0s 448ms/step - loss: 0.1232 - accuracy: 1.0000 - val_loss: 0.9636 - val_accuracy: 0.6619\n",
      "Epoch 377/500\n",
      "2/2 [==============================] - 1s 550ms/step - loss: 0.1217 - accuracy: 1.0000 - val_loss: 0.9620 - val_accuracy: 0.6629\n",
      "Epoch 378/500\n",
      "2/2 [==============================] - 1s 518ms/step - loss: 0.1219 - accuracy: 1.0000 - val_loss: 0.9618 - val_accuracy: 0.6628\n",
      "Epoch 379/500\n",
      "2/2 [==============================] - 0s 445ms/step - loss: 0.1214 - accuracy: 1.0000 - val_loss: 0.9638 - val_accuracy: 0.6620\n",
      "Epoch 380/500\n",
      "2/2 [==============================] - 1s 536ms/step - loss: 0.1201 - accuracy: 1.0000 - val_loss: 0.9613 - val_accuracy: 0.6631\n",
      "Epoch 381/500\n",
      "2/2 [==============================] - 1s 499ms/step - loss: 0.1207 - accuracy: 1.0000 - val_loss: 0.9586 - val_accuracy: 0.6637\n",
      "Epoch 382/500\n",
      "2/2 [==============================] - 1s 576ms/step - loss: 0.1190 - accuracy: 1.0000 - val_loss: 0.9601 - val_accuracy: 0.6633\n",
      "Epoch 383/500\n",
      "2/2 [==============================] - 0s 461ms/step - loss: 0.1194 - accuracy: 1.0000 - val_loss: 0.9586 - val_accuracy: 0.6637\n",
      "Epoch 384/500\n",
      "2/2 [==============================] - 0s 442ms/step - loss: 0.1183 - accuracy: 1.0000 - val_loss: 0.9598 - val_accuracy: 0.6637\n",
      "Epoch 385/500\n",
      "2/2 [==============================] - 0s 483ms/step - loss: 0.1178 - accuracy: 1.0000 - val_loss: 0.9597 - val_accuracy: 0.6636\n",
      "Epoch 386/500\n",
      "2/2 [==============================] - 0s 449ms/step - loss: 0.1176 - accuracy: 1.0000 - val_loss: 0.9615 - val_accuracy: 0.6638\n",
      "Epoch 387/500\n",
      "2/2 [==============================] - 0s 441ms/step - loss: 0.1173 - accuracy: 1.0000 - val_loss: 0.9624 - val_accuracy: 0.6629\n",
      "Epoch 388/500\n",
      "2/2 [==============================] - 0s 432ms/step - loss: 0.1165 - accuracy: 1.0000 - val_loss: 0.9615 - val_accuracy: 0.6631\n",
      "Epoch 389/500\n",
      "2/2 [==============================] - 0s 450ms/step - loss: 0.1165 - accuracy: 1.0000 - val_loss: 0.9623 - val_accuracy: 0.6632\n",
      "Epoch 390/500\n",
      "2/2 [==============================] - 0s 445ms/step - loss: 0.1157 - accuracy: 1.0000 - val_loss: 0.9629 - val_accuracy: 0.6632\n",
      "Epoch 391/500\n",
      "2/2 [==============================] - 0s 442ms/step - loss: 0.1154 - accuracy: 1.0000 - val_loss: 0.9614 - val_accuracy: 0.6632\n",
      "Epoch 392/500\n",
      "2/2 [==============================] - 0s 439ms/step - loss: 0.1150 - accuracy: 1.0000 - val_loss: 0.9622 - val_accuracy: 0.6631\n",
      "Epoch 393/500\n",
      "2/2 [==============================] - 0s 444ms/step - loss: 0.1151 - accuracy: 1.0000 - val_loss: 0.9630 - val_accuracy: 0.6632\n",
      "Epoch 394/500\n",
      "2/2 [==============================] - 0s 449ms/step - loss: 0.1145 - accuracy: 1.0000 - val_loss: 0.9605 - val_accuracy: 0.6643\n",
      "Epoch 395/500\n",
      "2/2 [==============================] - 0s 469ms/step - loss: 0.1152 - accuracy: 1.0000 - val_loss: 0.9575 - val_accuracy: 0.6652\n",
      "Epoch 396/500\n",
      "2/2 [==============================] - 0s 446ms/step - loss: 0.1141 - accuracy: 1.0000 - val_loss: 0.9572 - val_accuracy: 0.6646\n",
      "Epoch 397/500\n",
      "2/2 [==============================] - 1s 521ms/step - loss: 0.1131 - accuracy: 1.0000 - val_loss: 0.9584 - val_accuracy: 0.6644\n",
      "Epoch 398/500\n",
      "2/2 [==============================] - 0s 480ms/step - loss: 0.1133 - accuracy: 1.0000 - val_loss: 0.9618 - val_accuracy: 0.6634\n",
      "Epoch 399/500\n",
      "2/2 [==============================] - 0s 451ms/step - loss: 0.1127 - accuracy: 1.0000 - val_loss: 0.9626 - val_accuracy: 0.6634\n",
      "Epoch 400/500\n",
      "2/2 [==============================] - 0s 442ms/step - loss: 0.1115 - accuracy: 1.0000 - val_loss: 0.9623 - val_accuracy: 0.6636\n",
      "Epoch 401/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 447ms/step - loss: 0.1112 - accuracy: 1.0000 - val_loss: 0.9610 - val_accuracy: 0.6637\n",
      "Epoch 402/500\n",
      "2/2 [==============================] - 0s 454ms/step - loss: 0.1119 - accuracy: 1.0000 - val_loss: 0.9643 - val_accuracy: 0.6630\n",
      "Epoch 403/500\n",
      "2/2 [==============================] - 0s 444ms/step - loss: 0.1105 - accuracy: 1.0000 - val_loss: 0.9631 - val_accuracy: 0.6629\n",
      "Epoch 404/500\n",
      "2/2 [==============================] - 0s 452ms/step - loss: 0.1099 - accuracy: 1.0000 - val_loss: 0.9618 - val_accuracy: 0.6633\n",
      "Epoch 405/500\n",
      "2/2 [==============================] - 0s 441ms/step - loss: 0.1098 - accuracy: 1.0000 - val_loss: 0.9609 - val_accuracy: 0.6636\n",
      "Epoch 406/500\n",
      "2/2 [==============================] - 0s 440ms/step - loss: 0.1103 - accuracy: 1.0000 - val_loss: 0.9596 - val_accuracy: 0.6645\n",
      "Epoch 407/500\n",
      "2/2 [==============================] - 0s 445ms/step - loss: 0.1090 - accuracy: 1.0000 - val_loss: 0.9609 - val_accuracy: 0.6640\n",
      "Epoch 408/500\n",
      "2/2 [==============================] - 0s 451ms/step - loss: 0.1085 - accuracy: 1.0000 - val_loss: 0.9624 - val_accuracy: 0.6637\n",
      "Epoch 409/500\n",
      "2/2 [==============================] - 0s 474ms/step - loss: 0.1083 - accuracy: 1.0000 - val_loss: 0.9605 - val_accuracy: 0.6638\n",
      "Epoch 410/500\n",
      "2/2 [==============================] - 0s 462ms/step - loss: 0.1078 - accuracy: 1.0000 - val_loss: 0.9607 - val_accuracy: 0.6640\n",
      "Epoch 411/500\n",
      "2/2 [==============================] - 0s 460ms/step - loss: 0.1074 - accuracy: 1.0000 - val_loss: 0.9611 - val_accuracy: 0.6639\n",
      "Epoch 412/500\n",
      "2/2 [==============================] - 1s 621ms/step - loss: 0.1083 - accuracy: 1.0000 - val_loss: 0.9587 - val_accuracy: 0.6653\n",
      "Epoch 413/500\n",
      "2/2 [==============================] - 1s 791ms/step - loss: 0.1066 - accuracy: 1.0000 - val_loss: 0.9597 - val_accuracy: 0.6648\n",
      "Epoch 414/500\n",
      "2/2 [==============================] - 0s 457ms/step - loss: 0.1065 - accuracy: 1.0000 - val_loss: 0.9617 - val_accuracy: 0.6639\n",
      "Epoch 415/500\n",
      "2/2 [==============================] - 0s 443ms/step - loss: 0.1064 - accuracy: 1.0000 - val_loss: 0.9628 - val_accuracy: 0.6635\n",
      "Epoch 416/500\n",
      "2/2 [==============================] - 0s 446ms/step - loss: 0.1060 - accuracy: 1.0000 - val_loss: 0.9635 - val_accuracy: 0.6634\n",
      "Epoch 417/500\n",
      "2/2 [==============================] - 0s 446ms/step - loss: 0.1053 - accuracy: 1.0000 - val_loss: 0.9620 - val_accuracy: 0.6641\n",
      "Epoch 418/500\n",
      "2/2 [==============================] - 0s 443ms/step - loss: 0.1053 - accuracy: 1.0000 - val_loss: 0.9634 - val_accuracy: 0.6636\n",
      "Epoch 419/500\n",
      "2/2 [==============================] - 0s 460ms/step - loss: 0.1047 - accuracy: 1.0000 - val_loss: 0.9636 - val_accuracy: 0.6634\n",
      "Epoch 420/500\n",
      "2/2 [==============================] - 1s 504ms/step - loss: 0.1042 - accuracy: 1.0000 - val_loss: 0.9618 - val_accuracy: 0.6642\n",
      "Epoch 421/500\n",
      "2/2 [==============================] - 0s 490ms/step - loss: 0.1041 - accuracy: 1.0000 - val_loss: 0.9607 - val_accuracy: 0.6644\n",
      "Epoch 422/500\n",
      "2/2 [==============================] - 0s 448ms/step - loss: 0.1038 - accuracy: 1.0000 - val_loss: 0.9628 - val_accuracy: 0.6640\n",
      "Epoch 423/500\n",
      "2/2 [==============================] - 1s 680ms/step - loss: 0.1034 - accuracy: 1.0000 - val_loss: 0.9609 - val_accuracy: 0.6651\n",
      "Epoch 424/500\n",
      "2/2 [==============================] - 1s 1s/step - loss: 0.1036 - accuracy: 1.0000 - val_loss: 0.9638 - val_accuracy: 0.6640\n",
      "Epoch 425/500\n",
      "2/2 [==============================] - 1s 663ms/step - loss: 0.1031 - accuracy: 1.0000 - val_loss: 0.9621 - val_accuracy: 0.6641\n",
      "Epoch 426/500\n",
      "2/2 [==============================] - 1s 785ms/step - loss: 0.1024 - accuracy: 1.0000 - val_loss: 0.9623 - val_accuracy: 0.6640\n",
      "Epoch 427/500\n",
      "2/2 [==============================] - 1s 698ms/step - loss: 0.1017 - accuracy: 1.0000 - val_loss: 0.9629 - val_accuracy: 0.6639\n",
      "Epoch 428/500\n",
      "2/2 [==============================] - 1s 738ms/step - loss: 0.1014 - accuracy: 1.0000 - val_loss: 0.9619 - val_accuracy: 0.6640\n",
      "Epoch 429/500\n",
      "2/2 [==============================] - 1s 778ms/step - loss: 0.1009 - accuracy: 1.0000 - val_loss: 0.9626 - val_accuracy: 0.6639\n",
      "Epoch 430/500\n",
      "2/2 [==============================] - 1s 830ms/step - loss: 0.1008 - accuracy: 1.0000 - val_loss: 0.9619 - val_accuracy: 0.6642\n",
      "Epoch 431/500\n",
      "2/2 [==============================] - 1s 871ms/step - loss: 0.1006 - accuracy: 1.0000 - val_loss: 0.9639 - val_accuracy: 0.6638\n",
      "Epoch 432/500\n",
      "2/2 [==============================] - 1s 741ms/step - loss: 0.1000 - accuracy: 1.0000 - val_loss: 0.9635 - val_accuracy: 0.6640\n",
      "Epoch 433/500\n",
      "2/2 [==============================] - 1s 677ms/step - loss: 0.1005 - accuracy: 1.0000 - val_loss: 0.9630 - val_accuracy: 0.6634\n",
      "Epoch 434/500\n",
      "2/2 [==============================] - 1s 559ms/step - loss: 0.0992 - accuracy: 1.0000 - val_loss: 0.9635 - val_accuracy: 0.6641\n",
      "Epoch 435/500\n",
      "2/2 [==============================] - 1s 748ms/step - loss: 0.0998 - accuracy: 1.0000 - val_loss: 0.9619 - val_accuracy: 0.6637\n",
      "Epoch 436/500\n",
      "2/2 [==============================] - 2s 2s/step - loss: 0.0997 - accuracy: 1.0000 - val_loss: 0.9591 - val_accuracy: 0.6645\n",
      "Epoch 437/500\n",
      "2/2 [==============================] - 1s 764ms/step - loss: 0.0985 - accuracy: 1.0000 - val_loss: 0.9598 - val_accuracy: 0.6642\n",
      "Epoch 438/500\n",
      "2/2 [==============================] - 1s 728ms/step - loss: 0.0983 - accuracy: 1.0000 - val_loss: 0.9596 - val_accuracy: 0.6655\n",
      "Epoch 439/500\n",
      "2/2 [==============================] - 1s 710ms/step - loss: 0.0978 - accuracy: 1.0000 - val_loss: 0.9596 - val_accuracy: 0.6651\n",
      "Epoch 440/500\n",
      "2/2 [==============================] - 1s 661ms/step - loss: 0.0973 - accuracy: 1.0000 - val_loss: 0.9611 - val_accuracy: 0.6643\n",
      "Epoch 441/500\n",
      "2/2 [==============================] - 0s 493ms/step - loss: 0.0979 - accuracy: 1.0000 - val_loss: 0.9605 - val_accuracy: 0.6649\n",
      "Epoch 442/500\n",
      "2/2 [==============================] - 1s 719ms/step - loss: 0.0977 - accuracy: 1.0000 - val_loss: 0.9641 - val_accuracy: 0.6638\n",
      "Epoch 443/500\n",
      "2/2 [==============================] - 1s 717ms/step - loss: 0.0963 - accuracy: 1.0000 - val_loss: 0.9633 - val_accuracy: 0.6637\n",
      "Epoch 444/500\n",
      "2/2 [==============================] - 1s 591ms/step - loss: 0.0961 - accuracy: 1.0000 - val_loss: 0.9638 - val_accuracy: 0.6639\n",
      "Epoch 445/500\n",
      "2/2 [==============================] - 1s 544ms/step - loss: 0.0958 - accuracy: 1.0000 - val_loss: 0.9629 - val_accuracy: 0.6638\n",
      "Epoch 446/500\n",
      "2/2 [==============================] - 1s 550ms/step - loss: 0.0959 - accuracy: 1.0000 - val_loss: 0.9614 - val_accuracy: 0.6650\n",
      "Epoch 447/500\n",
      "2/2 [==============================] - 1s 524ms/step - loss: 0.0952 - accuracy: 1.0000 - val_loss: 0.9633 - val_accuracy: 0.6640\n",
      "Epoch 448/500\n",
      "2/2 [==============================] - 1s 500ms/step - loss: 0.0952 - accuracy: 1.0000 - val_loss: 0.9643 - val_accuracy: 0.6640\n",
      "Epoch 449/500\n",
      "2/2 [==============================] - 1s 514ms/step - loss: 0.0947 - accuracy: 1.0000 - val_loss: 0.9652 - val_accuracy: 0.6638\n",
      "Epoch 450/500\n",
      "2/2 [==============================] - 1s 1s/step - loss: 0.0949 - accuracy: 1.0000 - val_loss: 0.9622 - val_accuracy: 0.6650\n",
      "Epoch 451/500\n",
      "2/2 [==============================] - 1s 968ms/step - loss: 0.0940 - accuracy: 1.0000 - val_loss: 0.9627 - val_accuracy: 0.6642\n",
      "Epoch 452/500\n",
      "2/2 [==============================] - 1s 645ms/step - loss: 0.0940 - accuracy: 1.0000 - val_loss: 0.9626 - val_accuracy: 0.6648\n",
      "Epoch 453/500\n",
      "2/2 [==============================] - 1s 503ms/step - loss: 0.0954 - accuracy: 1.0000 - val_loss: 0.9668 - val_accuracy: 0.6634\n",
      "Epoch 454/500\n",
      "2/2 [==============================] - 1s 643ms/step - loss: 0.0932 - accuracy: 1.0000 - val_loss: 0.9644 - val_accuracy: 0.6639\n",
      "Epoch 455/500\n",
      "2/2 [==============================] - 1s 601ms/step - loss: 0.0927 - accuracy: 1.0000 - val_loss: 0.9637 - val_accuracy: 0.6637\n",
      "Epoch 456/500\n",
      "2/2 [==============================] - 1s 510ms/step - loss: 0.0924 - accuracy: 1.0000 - val_loss: 0.9643 - val_accuracy: 0.6637\n",
      "Epoch 457/500\n",
      "2/2 [==============================] - 1s 529ms/step - loss: 0.0922 - accuracy: 1.0000 - val_loss: 0.9653 - val_accuracy: 0.6637\n",
      "Epoch 458/500\n",
      "2/2 [==============================] - 1s 539ms/step - loss: 0.0918 - accuracy: 1.0000 - val_loss: 0.9643 - val_accuracy: 0.6642\n",
      "Epoch 459/500\n",
      "2/2 [==============================] - 0s 468ms/step - loss: 0.0917 - accuracy: 1.0000 - val_loss: 0.9634 - val_accuracy: 0.6650\n",
      "Epoch 460/500\n",
      "2/2 [==============================] - 0s 459ms/step - loss: 0.0929 - accuracy: 1.0000 - val_loss: 0.9607 - val_accuracy: 0.6664\n",
      "Epoch 461/500\n",
      "2/2 [==============================] - 0s 459ms/step - loss: 0.0909 - accuracy: 1.0000 - val_loss: 0.9621 - val_accuracy: 0.6655\n",
      "Epoch 462/500\n",
      "2/2 [==============================] - 0s 474ms/step - loss: 0.0911 - accuracy: 1.0000 - val_loss: 0.9642 - val_accuracy: 0.6644\n",
      "Epoch 463/500\n",
      "2/2 [==============================] - 0s 448ms/step - loss: 0.0909 - accuracy: 1.0000 - val_loss: 0.9626 - val_accuracy: 0.6654\n",
      "Epoch 464/500\n",
      "2/2 [==============================] - 0s 468ms/step - loss: 0.0904 - accuracy: 1.0000 - val_loss: 0.9632 - val_accuracy: 0.6654\n",
      "Epoch 465/500\n",
      "2/2 [==============================] - 0s 464ms/step - loss: 0.0901 - accuracy: 1.0000 - val_loss: 0.9641 - val_accuracy: 0.6648\n",
      "Epoch 466/500\n",
      "2/2 [==============================] - 0s 447ms/step - loss: 0.0905 - accuracy: 1.0000 - val_loss: 0.9620 - val_accuracy: 0.6659\n",
      "Epoch 467/500\n",
      "2/2 [==============================] - 1s 533ms/step - loss: 0.0896 - accuracy: 1.0000 - val_loss: 0.9646 - val_accuracy: 0.6646\n",
      "Epoch 468/500\n",
      "2/2 [==============================] - 0s 449ms/step - loss: 0.0889 - accuracy: 1.0000 - val_loss: 0.9644 - val_accuracy: 0.6646\n",
      "Epoch 469/500\n",
      "2/2 [==============================] - 0s 455ms/step - loss: 0.0891 - accuracy: 1.0000 - val_loss: 0.9657 - val_accuracy: 0.6633\n",
      "Epoch 470/500\n",
      "2/2 [==============================] - 0s 451ms/step - loss: 0.0884 - accuracy: 1.0000 - val_loss: 0.9653 - val_accuracy: 0.6641\n",
      "Epoch 471/500\n",
      "2/2 [==============================] - 0s 439ms/step - loss: 0.0886 - accuracy: 1.0000 - val_loss: 0.9663 - val_accuracy: 0.6639\n",
      "Epoch 472/500\n",
      "2/2 [==============================] - 0s 450ms/step - loss: 0.0881 - accuracy: 1.0000 - val_loss: 0.9644 - val_accuracy: 0.6653\n",
      "Epoch 473/500\n",
      "2/2 [==============================] - 0s 471ms/step - loss: 0.0876 - accuracy: 1.0000 - val_loss: 0.9657 - val_accuracy: 0.6641\n",
      "Epoch 474/500\n",
      "2/2 [==============================] - 0s 441ms/step - loss: 0.0874 - accuracy: 1.0000 - val_loss: 0.9664 - val_accuracy: 0.6633\n",
      "Epoch 475/500\n",
      "2/2 [==============================] - 1s 514ms/step - loss: 0.0872 - accuracy: 1.0000 - val_loss: 0.9663 - val_accuracy: 0.6636\n",
      "Epoch 476/500\n",
      "2/2 [==============================] - 1s 565ms/step - loss: 0.0869 - accuracy: 1.0000 - val_loss: 0.9648 - val_accuracy: 0.6648\n",
      "Epoch 477/500\n",
      "2/2 [==============================] - 1s 1s/step - loss: 0.0865 - accuracy: 1.0000 - val_loss: 0.9645 - val_accuracy: 0.6649\n",
      "Epoch 478/500\n",
      "2/2 [==============================] - 1s 715ms/step - loss: 0.0864 - accuracy: 1.0000 - val_loss: 0.9655 - val_accuracy: 0.6645\n",
      "Epoch 479/500\n",
      "2/2 [==============================] - 1s 832ms/step - loss: 0.0864 - accuracy: 1.0000 - val_loss: 0.9647 - val_accuracy: 0.6645\n",
      "Epoch 480/500\n",
      "2/2 [==============================] - 2s 2s/step - loss: 0.0857 - accuracy: 1.0000 - val_loss: 0.9648 - val_accuracy: 0.6646\n",
      "Epoch 481/500\n",
      "2/2 [==============================] - 2s 2s/step - loss: 0.0856 - accuracy: 1.0000 - val_loss: 0.9656 - val_accuracy: 0.6648\n",
      "Epoch 482/500\n",
      "2/2 [==============================] - 1s 1s/step - loss: 0.0853 - accuracy: 1.0000 - val_loss: 0.9657 - val_accuracy: 0.6646\n",
      "Epoch 483/500\n",
      "2/2 [==============================] - 1s 1s/step - loss: 0.0850 - accuracy: 1.0000 - val_loss: 0.9653 - val_accuracy: 0.6647\n",
      "Epoch 484/500\n",
      "2/2 [==============================] - 1s 899ms/step - loss: 0.0847 - accuracy: 1.0000 - val_loss: 0.9652 - val_accuracy: 0.6645\n",
      "Epoch 485/500\n",
      "2/2 [==============================] - 1s 823ms/step - loss: 0.0851 - accuracy: 1.0000 - val_loss: 0.9660 - val_accuracy: 0.6639\n",
      "Epoch 486/500\n",
      "2/2 [==============================] - 1s 638ms/step - loss: 0.0846 - accuracy: 1.0000 - val_loss: 0.9648 - val_accuracy: 0.6648\n",
      "Epoch 487/500\n",
      "2/2 [==============================] - 1s 647ms/step - loss: 0.0839 - accuracy: 1.0000 - val_loss: 0.9652 - val_accuracy: 0.6645\n",
      "Epoch 488/500\n",
      "2/2 [==============================] - 1s 660ms/step - loss: 0.0838 - accuracy: 1.0000 - val_loss: 0.9643 - val_accuracy: 0.6645\n",
      "Epoch 489/500\n",
      "2/2 [==============================] - 1s 688ms/step - loss: 0.0836 - accuracy: 1.0000 - val_loss: 0.9641 - val_accuracy: 0.6645\n",
      "Epoch 490/500\n",
      "2/2 [==============================] - 1s 594ms/step - loss: 0.0834 - accuracy: 1.0000 - val_loss: 0.9642 - val_accuracy: 0.6645\n",
      "Epoch 491/500\n",
      "2/2 [==============================] - 0s 463ms/step - loss: 0.0833 - accuracy: 1.0000 - val_loss: 0.9656 - val_accuracy: 0.6643\n",
      "Epoch 492/500\n",
      "2/2 [==============================] - 0s 469ms/step - loss: 0.0828 - accuracy: 1.0000 - val_loss: 0.9656 - val_accuracy: 0.6643\n",
      "Epoch 493/500\n",
      "2/2 [==============================] - 0s 445ms/step - loss: 0.0830 - accuracy: 1.0000 - val_loss: 0.9638 - val_accuracy: 0.6646\n",
      "Epoch 494/500\n",
      "2/2 [==============================] - 0s 470ms/step - loss: 0.0822 - accuracy: 1.0000 - val_loss: 0.9647 - val_accuracy: 0.6646\n",
      "Epoch 495/500\n",
      "2/2 [==============================] - 0s 447ms/step - loss: 0.0820 - accuracy: 1.0000 - val_loss: 0.9644 - val_accuracy: 0.6648\n",
      "Epoch 496/500\n",
      "2/2 [==============================] - 0s 477ms/step - loss: 0.0821 - accuracy: 1.0000 - val_loss: 0.9668 - val_accuracy: 0.6647\n",
      "Epoch 497/500\n",
      "2/2 [==============================] - 0s 475ms/step - loss: 0.0814 - accuracy: 1.0000 - val_loss: 0.9671 - val_accuracy: 0.6647\n",
      "Epoch 498/500\n",
      "2/2 [==============================] - 0s 446ms/step - loss: 0.0813 - accuracy: 1.0000 - val_loss: 0.9662 - val_accuracy: 0.6649\n",
      "Epoch 499/500\n",
      "2/2 [==============================] - 0s 465ms/step - loss: 0.0812 - accuracy: 1.0000 - val_loss: 0.9664 - val_accuracy: 0.6646\n",
      "Epoch 500/500\n",
      "2/2 [==============================] - 0s 491ms/step - loss: 0.0814 - accuracy: 1.0000 - val_loss: 0.9650 - val_accuracy: 0.6648\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1bf4377ec08>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_split.astype(\"float32\") / 255, y_split, epochs=500, validation_data=(x_test.astype(\"float32\") / 255, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CVf7fA1mE92D",
    "outputId": "847e1c55-9763-486a-9215-43eb51e61ca5",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "2/2 [==============================] - 1s 635ms/step - loss: 0.0806 - accuracy: 1.0000 - val_loss: 0.9663 - val_accuracy: 0.6648\n",
      "Epoch 2/500\n",
      "2/2 [==============================] - 1s 856ms/step - loss: 0.0807 - accuracy: 1.0000 - val_loss: 0.9651 - val_accuracy: 0.6646\n",
      "Epoch 3/500\n",
      "2/2 [==============================] - 1s 805ms/step - loss: 0.0801 - accuracy: 1.0000 - val_loss: 0.9668 - val_accuracy: 0.6648\n",
      "Epoch 4/500\n",
      "2/2 [==============================] - 1s 886ms/step - loss: 0.0798 - accuracy: 1.0000 - val_loss: 0.9665 - val_accuracy: 0.6644\n",
      "Epoch 5/500\n",
      "2/2 [==============================] - 1s 967ms/step - loss: 0.0796 - accuracy: 1.0000 - val_loss: 0.9672 - val_accuracy: 0.6649\n",
      "Epoch 6/500\n",
      "2/2 [==============================] - 1s 981ms/step - loss: 0.0797 - accuracy: 1.0000 - val_loss: 0.9657 - val_accuracy: 0.6648\n",
      "Epoch 7/500\n",
      "2/2 [==============================] - 1s 635ms/step - loss: 0.0796 - accuracy: 1.0000 - val_loss: 0.9655 - val_accuracy: 0.6645\n",
      "Epoch 8/500\n",
      "2/2 [==============================] - 1s 592ms/step - loss: 0.0789 - accuracy: 1.0000 - val_loss: 0.9669 - val_accuracy: 0.6646\n",
      "Epoch 9/500\n",
      "2/2 [==============================] - 1s 586ms/step - loss: 0.0787 - accuracy: 1.0000 - val_loss: 0.9671 - val_accuracy: 0.6644\n",
      "Epoch 10/500\n",
      "2/2 [==============================] - 1s 610ms/step - loss: 0.0787 - accuracy: 1.0000 - val_loss: 0.9663 - val_accuracy: 0.6645\n",
      "Epoch 11/500\n",
      "2/2 [==============================] - 1s 586ms/step - loss: 0.0785 - accuracy: 1.0000 - val_loss: 0.9658 - val_accuracy: 0.6645\n",
      "Epoch 12/500\n",
      "2/2 [==============================] - 2s 2s/step - loss: 0.0781 - accuracy: 1.0000 - val_loss: 0.9674 - val_accuracy: 0.6645\n",
      "Epoch 13/500\n",
      "2/2 [==============================] - 1s 1s/step - loss: 0.0780 - accuracy: 1.0000 - val_loss: 0.9668 - val_accuracy: 0.6644\n",
      "Epoch 14/500\n",
      "2/2 [==============================] - 1s 1s/step - loss: 0.0781 - accuracy: 1.0000 - val_loss: 0.9695 - val_accuracy: 0.6643\n",
      "Epoch 15/500\n",
      "2/2 [==============================] - 1s 1s/step - loss: 0.0774 - accuracy: 1.0000 - val_loss: 0.9701 - val_accuracy: 0.6640\n",
      "Epoch 16/500\n",
      "2/2 [==============================] - 2s 2s/step - loss: 0.0773 - accuracy: 1.0000 - val_loss: 0.9684 - val_accuracy: 0.6648\n",
      "Epoch 17/500\n",
      "2/2 [==============================] - 2s 2s/step - loss: 0.0769 - accuracy: 1.0000 - val_loss: 0.9680 - val_accuracy: 0.6647\n",
      "Epoch 18/500\n",
      "2/2 [==============================] - 1s 947ms/step - loss: 0.0767 - accuracy: 1.0000 - val_loss: 0.9682 - val_accuracy: 0.6648\n",
      "Epoch 19/500\n",
      "2/2 [==============================] - 1s 847ms/step - loss: 0.0764 - accuracy: 1.0000 - val_loss: 0.9682 - val_accuracy: 0.6650\n",
      "Epoch 20/500\n",
      "2/2 [==============================] - 1s 854ms/step - loss: 0.0762 - accuracy: 1.0000 - val_loss: 0.9685 - val_accuracy: 0.6648\n",
      "Epoch 21/500\n",
      "2/2 [==============================] - 1s 815ms/step - loss: 0.0762 - accuracy: 1.0000 - val_loss: 0.9678 - val_accuracy: 0.6651\n",
      "Epoch 22/500\n",
      "2/2 [==============================] - 1s 801ms/step - loss: 0.0757 - accuracy: 1.0000 - val_loss: 0.9687 - val_accuracy: 0.6646\n",
      "Epoch 23/500\n",
      "2/2 [==============================] - 1s 631ms/step - loss: 0.0766 - accuracy: 1.0000 - val_loss: 0.9712 - val_accuracy: 0.6644\n",
      "Epoch 24/500\n",
      "2/2 [==============================] - 1s 652ms/step - loss: 0.0753 - accuracy: 1.0000 - val_loss: 0.9705 - val_accuracy: 0.6646\n",
      "Epoch 25/500\n",
      "2/2 [==============================] - 1s 523ms/step - loss: 0.0752 - accuracy: 1.0000 - val_loss: 0.9694 - val_accuracy: 0.6648\n",
      "Epoch 26/500\n",
      "2/2 [==============================] - 0s 483ms/step - loss: 0.0749 - accuracy: 1.0000 - val_loss: 0.9701 - val_accuracy: 0.6647\n",
      "Epoch 27/500\n",
      "2/2 [==============================] - 0s 484ms/step - loss: 0.0748 - accuracy: 1.0000 - val_loss: 0.9694 - val_accuracy: 0.6648\n",
      "Epoch 28/500\n",
      "2/2 [==============================] - 0s 471ms/step - loss: 0.0748 - accuracy: 1.0000 - val_loss: 0.9689 - val_accuracy: 0.6652\n",
      "Epoch 29/500\n",
      "2/2 [==============================] - 0s 472ms/step - loss: 0.0750 - accuracy: 1.0000 - val_loss: 0.9717 - val_accuracy: 0.6645\n",
      "Epoch 30/500\n",
      "2/2 [==============================] - 0s 461ms/step - loss: 0.0745 - accuracy: 1.0000 - val_loss: 0.9726 - val_accuracy: 0.6645\n",
      "Epoch 31/500\n",
      "2/2 [==============================] - 0s 463ms/step - loss: 0.0740 - accuracy: 1.0000 - val_loss: 0.9716 - val_accuracy: 0.6646\n",
      "Epoch 32/500\n",
      "2/2 [==============================] - 0s 472ms/step - loss: 0.0751 - accuracy: 1.0000 - val_loss: 0.9745 - val_accuracy: 0.6640\n",
      "Epoch 33/500\n",
      "2/2 [==============================] - 0s 457ms/step - loss: 0.0735 - accuracy: 1.0000 - val_loss: 0.9732 - val_accuracy: 0.6644\n",
      "Epoch 34/500\n",
      "2/2 [==============================] - 1s 511ms/step - loss: 0.0735 - accuracy: 1.0000 - val_loss: 0.9713 - val_accuracy: 0.6652\n",
      "Epoch 35/500\n",
      "2/2 [==============================] - 1s 500ms/step - loss: 0.0731 - accuracy: 1.0000 - val_loss: 0.9721 - val_accuracy: 0.6645\n",
      "Epoch 36/500\n",
      "2/2 [==============================] - 1s 854ms/step - loss: 0.0731 - accuracy: 1.0000 - val_loss: 0.9705 - val_accuracy: 0.6653\n",
      "Epoch 37/500\n",
      "2/2 [==============================] - 2s 2s/step - loss: 0.0734 - accuracy: 1.0000 - val_loss: 0.9684 - val_accuracy: 0.6661\n",
      "Epoch 38/500\n",
      "2/2 [==============================] - 2s 2s/step - loss: 0.0725 - accuracy: 1.0000 - val_loss: 0.9695 - val_accuracy: 0.6655\n",
      "Epoch 39/500\n",
      "2/2 [==============================] - 2s 2s/step - loss: 0.0723 - accuracy: 1.0000 - val_loss: 0.9705 - val_accuracy: 0.6652\n",
      "Epoch 40/500\n",
      "2/2 [==============================] - 1s 1s/step - loss: 0.0721 - accuracy: 1.0000 - val_loss: 0.9704 - val_accuracy: 0.6650\n",
      "Epoch 41/500\n",
      "2/2 [==============================] - 1s 1s/step - loss: 0.0721 - accuracy: 1.0000 - val_loss: 0.9707 - val_accuracy: 0.6657\n",
      "Epoch 42/500\n",
      "2/2 [==============================] - 1s 1s/step - loss: 0.0716 - accuracy: 1.0000 - val_loss: 0.9708 - val_accuracy: 0.6655\n",
      "Epoch 43/500\n",
      "2/2 [==============================] - 1s 1s/step - loss: 0.0717 - accuracy: 1.0000 - val_loss: 0.9695 - val_accuracy: 0.6655\n",
      "Epoch 44/500\n",
      "2/2 [==============================] - 1s 945ms/step - loss: 0.0714 - accuracy: 1.0000 - val_loss: 0.9694 - val_accuracy: 0.6658\n",
      "Epoch 45/500\n",
      "2/2 [==============================] - 1s 830ms/step - loss: 0.0711 - accuracy: 1.0000 - val_loss: 0.9697 - val_accuracy: 0.6658\n",
      "Epoch 46/500\n",
      "2/2 [==============================] - 1s 670ms/step - loss: 0.0711 - accuracy: 1.0000 - val_loss: 0.9713 - val_accuracy: 0.6652\n",
      "Epoch 47/500\n",
      "2/2 [==============================] - 0s 459ms/step - loss: 0.0708 - accuracy: 1.0000 - val_loss: 0.9716 - val_accuracy: 0.6653\n",
      "Epoch 48/500\n",
      "2/2 [==============================] - 0s 480ms/step - loss: 0.0710 - accuracy: 1.0000 - val_loss: 0.9702 - val_accuracy: 0.6656\n",
      "Epoch 49/500\n",
      "2/2 [==============================] - 0s 451ms/step - loss: 0.0708 - accuracy: 1.0000 - val_loss: 0.9726 - val_accuracy: 0.6647\n",
      "Epoch 50/500\n",
      "2/2 [==============================] - 0s 481ms/step - loss: 0.0702 - accuracy: 1.0000 - val_loss: 0.9716 - val_accuracy: 0.6650\n",
      "Epoch 51/500\n",
      "2/2 [==============================] - 0s 496ms/step - loss: 0.0700 - accuracy: 1.0000 - val_loss: 0.9721 - val_accuracy: 0.6650\n",
      "Epoch 52/500\n",
      "2/2 [==============================] - 0s 444ms/step - loss: 0.0698 - accuracy: 1.0000 - val_loss: 0.9724 - val_accuracy: 0.6653\n",
      "Epoch 53/500\n",
      "2/2 [==============================] - 1s 557ms/step - loss: 0.0703 - accuracy: 1.0000 - val_loss: 0.9744 - val_accuracy: 0.6645\n",
      "Epoch 54/500\n",
      "2/2 [==============================] - 0s 469ms/step - loss: 0.0696 - accuracy: 1.0000 - val_loss: 0.9737 - val_accuracy: 0.6648\n",
      "Epoch 55/500\n",
      "2/2 [==============================] - 1s 529ms/step - loss: 0.0692 - accuracy: 1.0000 - val_loss: 0.9730 - val_accuracy: 0.6649\n",
      "Epoch 56/500\n",
      "2/2 [==============================] - 1s 525ms/step - loss: 0.0690 - accuracy: 1.0000 - val_loss: 0.9729 - val_accuracy: 0.6650\n",
      "Epoch 57/500\n",
      "2/2 [==============================] - 0s 470ms/step - loss: 0.0690 - accuracy: 1.0000 - val_loss: 0.9718 - val_accuracy: 0.6656\n",
      "Epoch 58/500\n",
      "2/2 [==============================] - 0s 476ms/step - loss: 0.0688 - accuracy: 1.0000 - val_loss: 0.9716 - val_accuracy: 0.6659\n",
      "Epoch 59/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 463ms/step - loss: 0.0685 - accuracy: 1.0000 - val_loss: 0.9721 - val_accuracy: 0.6657\n",
      "Epoch 60/500\n",
      "2/2 [==============================] - 0s 478ms/step - loss: 0.0686 - accuracy: 1.0000 - val_loss: 0.9735 - val_accuracy: 0.6653\n",
      "Epoch 61/500\n",
      "2/2 [==============================] - 1s 884ms/step - loss: 0.0682 - accuracy: 1.0000 - val_loss: 0.9730 - val_accuracy: 0.6647\n",
      "Epoch 62/500\n",
      "2/2 [==============================] - 1s 703ms/step - loss: 0.0681 - accuracy: 1.0000 - val_loss: 0.9734 - val_accuracy: 0.6650\n",
      "Epoch 63/500\n",
      "2/2 [==============================] - 1s 683ms/step - loss: 0.0678 - accuracy: 1.0000 - val_loss: 0.9735 - val_accuracy: 0.6650\n",
      "Epoch 64/500\n",
      "2/2 [==============================] - 1s 673ms/step - loss: 0.0679 - accuracy: 1.0000 - val_loss: 0.9722 - val_accuracy: 0.6657\n",
      "Epoch 65/500\n",
      "2/2 [==============================] - 1s 667ms/step - loss: 0.0679 - accuracy: 1.0000 - val_loss: 0.9742 - val_accuracy: 0.6645\n",
      "Epoch 66/500\n",
      "2/2 [==============================] - 1s 856ms/step - loss: 0.0672 - accuracy: 1.0000 - val_loss: 0.9745 - val_accuracy: 0.6645\n",
      "Epoch 67/500\n",
      "2/2 [==============================] - 1s 879ms/step - loss: 0.0673 - accuracy: 1.0000 - val_loss: 0.9744 - val_accuracy: 0.6648\n",
      "Epoch 68/500\n",
      "2/2 [==============================] - 1s 978ms/step - loss: 0.0669 - accuracy: 1.0000 - val_loss: 0.9736 - val_accuracy: 0.6652\n",
      "Epoch 69/500\n",
      "2/2 [==============================] - 1s 1s/step - loss: 0.0668 - accuracy: 1.0000 - val_loss: 0.9731 - val_accuracy: 0.6659\n",
      "Epoch 70/500\n",
      "2/2 [==============================] - 1s 930ms/step - loss: 0.0666 - accuracy: 1.0000 - val_loss: 0.9732 - val_accuracy: 0.6657\n",
      "Epoch 71/500\n",
      "2/2 [==============================] - 1s 856ms/step - loss: 0.0664 - accuracy: 1.0000 - val_loss: 0.9737 - val_accuracy: 0.6653\n",
      "Epoch 72/500\n",
      "2/2 [==============================] - 1s 815ms/step - loss: 0.0665 - accuracy: 1.0000 - val_loss: 0.9726 - val_accuracy: 0.6661\n",
      "Epoch 73/500\n",
      "2/2 [==============================] - 1s 765ms/step - loss: 0.0661 - accuracy: 1.0000 - val_loss: 0.9724 - val_accuracy: 0.6664\n",
      "Epoch 74/500\n",
      "2/2 [==============================] - 1s 798ms/step - loss: 0.0661 - accuracy: 1.0000 - val_loss: 0.9739 - val_accuracy: 0.6659\n",
      "Epoch 75/500\n",
      "2/2 [==============================] - 1s 795ms/step - loss: 0.0656 - accuracy: 1.0000 - val_loss: 0.9738 - val_accuracy: 0.6659\n",
      "Epoch 76/500\n",
      "2/2 [==============================] - 1s 826ms/step - loss: 0.0656 - accuracy: 1.0000 - val_loss: 0.9739 - val_accuracy: 0.6658\n",
      "Epoch 77/500\n",
      "2/2 [==============================] - 1s 1s/step - loss: 0.0653 - accuracy: 1.0000 - val_loss: 0.9741 - val_accuracy: 0.6659\n",
      "Epoch 78/500\n",
      "2/2 [==============================] - 1s 955ms/step - loss: 0.0653 - accuracy: 1.0000 - val_loss: 0.9741 - val_accuracy: 0.6663\n",
      "Epoch 79/500\n",
      "2/2 [==============================] - 1s 635ms/step - loss: 0.0651 - accuracy: 1.0000 - val_loss: 0.9751 - val_accuracy: 0.6652\n",
      "Epoch 80/500\n",
      "2/2 [==============================] - 0s 455ms/step - loss: 0.0651 - accuracy: 1.0000 - val_loss: 0.9760 - val_accuracy: 0.6652\n",
      "Epoch 81/500\n",
      "2/2 [==============================] - 1s 954ms/step - loss: 0.0650 - accuracy: 1.0000 - val_loss: 0.9742 - val_accuracy: 0.6662\n",
      "Epoch 82/500\n",
      "2/2 [==============================] - 1s 600ms/step - loss: 0.0645 - accuracy: 1.0000 - val_loss: 0.9752 - val_accuracy: 0.6656\n",
      "Epoch 83/500\n",
      "2/2 [==============================] - 1s 519ms/step - loss: 0.0645 - accuracy: 1.0000 - val_loss: 0.9759 - val_accuracy: 0.6654\n",
      "Epoch 84/500\n",
      "2/2 [==============================] - 1s 537ms/step - loss: 0.0642 - accuracy: 1.0000 - val_loss: 0.9751 - val_accuracy: 0.6659\n",
      "Epoch 85/500\n",
      "2/2 [==============================] - 1s 910ms/step - loss: 0.0643 - accuracy: 1.0000 - val_loss: 0.9765 - val_accuracy: 0.6654\n",
      "Epoch 86/500\n",
      "2/2 [==============================] - 1s 699ms/step - loss: 0.0638 - accuracy: 1.0000 - val_loss: 0.9758 - val_accuracy: 0.6656\n",
      "Epoch 87/500\n",
      "2/2 [==============================] - 1s 628ms/step - loss: 0.0636 - accuracy: 1.0000 - val_loss: 0.9758 - val_accuracy: 0.6659\n",
      "Epoch 88/500\n",
      "2/2 [==============================] - 1s 914ms/step - loss: 0.0635 - accuracy: 1.0000 - val_loss: 0.9752 - val_accuracy: 0.6663\n",
      "Epoch 89/500\n",
      "2/2 [==============================] - 1s 1s/step - loss: 0.0637 - accuracy: 1.0000 - val_loss: 0.9751 - val_accuracy: 0.6664\n",
      "Epoch 90/500\n",
      "2/2 [==============================] - 1s 1s/step - loss: 0.0636 - accuracy: 1.0000 - val_loss: 0.9771 - val_accuracy: 0.6653\n",
      "Epoch 91/500\n",
      "2/2 [==============================] - 2s 2s/step - loss: 0.0631 - accuracy: 1.0000 - val_loss: 0.9768 - val_accuracy: 0.6653\n",
      "Epoch 92/500\n",
      "2/2 [==============================] - 1s 914ms/step - loss: 0.0634 - accuracy: 1.0000 - val_loss: 0.9750 - val_accuracy: 0.6663\n",
      "Epoch 93/500\n",
      "2/2 [==============================] - 1s 848ms/step - loss: 0.0629 - accuracy: 1.0000 - val_loss: 0.9751 - val_accuracy: 0.6663\n",
      "Epoch 94/500\n",
      "2/2 [==============================] - 1s 551ms/step - loss: 0.0625 - accuracy: 1.0000 - val_loss: 0.9756 - val_accuracy: 0.6663\n",
      "Epoch 95/500\n",
      "2/2 [==============================] - 0s 470ms/step - loss: 0.0624 - accuracy: 1.0000 - val_loss: 0.9760 - val_accuracy: 0.6660\n",
      "Epoch 96/500\n",
      "2/2 [==============================] - 1s 498ms/step - loss: 0.0625 - accuracy: 1.0000 - val_loss: 0.9772 - val_accuracy: 0.6658\n",
      "Epoch 97/500\n",
      "2/2 [==============================] - 0s 474ms/step - loss: 0.0623 - accuracy: 1.0000 - val_loss: 0.9780 - val_accuracy: 0.6653\n",
      "Epoch 98/500\n",
      "2/2 [==============================] - 1s 529ms/step - loss: 0.0620 - accuracy: 1.0000 - val_loss: 0.9773 - val_accuracy: 0.6659\n",
      "Epoch 99/500\n",
      "2/2 [==============================] - 1s 568ms/step - loss: 0.0619 - accuracy: 1.0000 - val_loss: 0.9766 - val_accuracy: 0.6660\n",
      "Epoch 100/500\n",
      "2/2 [==============================] - 1s 673ms/step - loss: 0.0620 - accuracy: 1.0000 - val_loss: 0.9748 - val_accuracy: 0.6663\n",
      "Epoch 101/500\n",
      "2/2 [==============================] - 1s 583ms/step - loss: 0.0616 - accuracy: 1.0000 - val_loss: 0.9759 - val_accuracy: 0.6664\n",
      "Epoch 102/500\n",
      "2/2 [==============================] - 0s 488ms/step - loss: 0.0614 - accuracy: 1.0000 - val_loss: 0.9755 - val_accuracy: 0.6664\n",
      "Epoch 103/500\n",
      "2/2 [==============================] - 0s 475ms/step - loss: 0.0612 - accuracy: 1.0000 - val_loss: 0.9764 - val_accuracy: 0.6661\n",
      "Epoch 104/500\n",
      "2/2 [==============================] - 0s 457ms/step - loss: 0.0610 - accuracy: 1.0000 - val_loss: 0.9762 - val_accuracy: 0.6662\n",
      "Epoch 105/500\n",
      "2/2 [==============================] - 0s 456ms/step - loss: 0.0611 - accuracy: 1.0000 - val_loss: 0.9776 - val_accuracy: 0.6661\n",
      "Epoch 106/500\n",
      "2/2 [==============================] - 0s 451ms/step - loss: 0.0608 - accuracy: 1.0000 - val_loss: 0.9769 - val_accuracy: 0.6661\n",
      "Epoch 107/500\n",
      "2/2 [==============================] - 0s 446ms/step - loss: 0.0613 - accuracy: 1.0000 - val_loss: 0.9760 - val_accuracy: 0.6665\n",
      "Epoch 108/500\n",
      "2/2 [==============================] - 0s 446ms/step - loss: 0.0609 - accuracy: 1.0000 - val_loss: 0.9783 - val_accuracy: 0.6661\n",
      "Epoch 109/500\n",
      "2/2 [==============================] - 0s 487ms/step - loss: 0.0605 - accuracy: 1.0000 - val_loss: 0.9768 - val_accuracy: 0.6662\n",
      "Epoch 110/500\n",
      "2/2 [==============================] - 0s 458ms/step - loss: 0.0607 - accuracy: 1.0000 - val_loss: 0.9789 - val_accuracy: 0.6658\n",
      "Epoch 111/500\n",
      "2/2 [==============================] - 1s 537ms/step - loss: 0.0601 - accuracy: 1.0000 - val_loss: 0.9785 - val_accuracy: 0.6664\n",
      "Epoch 112/500\n",
      "2/2 [==============================] - 0s 452ms/step - loss: 0.0600 - accuracy: 1.0000 - val_loss: 0.9773 - val_accuracy: 0.6661\n",
      "Epoch 113/500\n",
      "2/2 [==============================] - 0s 437ms/step - loss: 0.0598 - accuracy: 1.0000 - val_loss: 0.9778 - val_accuracy: 0.6659\n",
      "Epoch 114/500\n",
      "2/2 [==============================] - 0s 482ms/step - loss: 0.0596 - accuracy: 1.0000 - val_loss: 0.9778 - val_accuracy: 0.6659\n",
      "Epoch 115/500\n",
      "2/2 [==============================] - 0s 497ms/step - loss: 0.0593 - accuracy: 1.0000 - val_loss: 0.9780 - val_accuracy: 0.6658\n",
      "Epoch 116/500\n",
      "2/2 [==============================] - 0s 454ms/step - loss: 0.0595 - accuracy: 1.0000 - val_loss: 0.9773 - val_accuracy: 0.6662\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 117/500\n",
      "2/2 [==============================] - 0s 464ms/step - loss: 0.0592 - accuracy: 1.0000 - val_loss: 0.9772 - val_accuracy: 0.6664\n",
      "Epoch 118/500\n",
      "2/2 [==============================] - 0s 438ms/step - loss: 0.0590 - accuracy: 1.0000 - val_loss: 0.9768 - val_accuracy: 0.6661\n",
      "Epoch 119/500\n",
      "2/2 [==============================] - 0s 446ms/step - loss: 0.0589 - accuracy: 1.0000 - val_loss: 0.9776 - val_accuracy: 0.6659\n",
      "Epoch 120/500\n",
      "2/2 [==============================] - 0s 495ms/step - loss: 0.0586 - accuracy: 1.0000 - val_loss: 0.9780 - val_accuracy: 0.6665\n",
      "Epoch 121/500\n",
      "2/2 [==============================] - 0s 470ms/step - loss: 0.0586 - accuracy: 1.0000 - val_loss: 0.9788 - val_accuracy: 0.6659\n",
      "Epoch 122/500\n",
      "2/2 [==============================] - 0s 467ms/step - loss: 0.0585 - accuracy: 1.0000 - val_loss: 0.9790 - val_accuracy: 0.6659\n",
      "Epoch 123/500\n",
      "2/2 [==============================] - 1s 542ms/step - loss: 0.0583 - accuracy: 1.0000 - val_loss: 0.9782 - val_accuracy: 0.6664\n",
      "Epoch 124/500\n",
      "2/2 [==============================] - 1s 686ms/step - loss: 0.0581 - accuracy: 1.0000 - val_loss: 0.9785 - val_accuracy: 0.6663\n",
      "Epoch 125/500\n",
      "2/2 [==============================] - 1s 727ms/step - loss: 0.0581 - accuracy: 1.0000 - val_loss: 0.9782 - val_accuracy: 0.6661\n",
      "Epoch 126/500\n",
      "2/2 [==============================] - 1s 662ms/step - loss: 0.0583 - accuracy: 1.0000 - val_loss: 0.9782 - val_accuracy: 0.6662\n",
      "Epoch 127/500\n",
      "2/2 [==============================] - 1s 700ms/step - loss: 0.0581 - accuracy: 1.0000 - val_loss: 0.9802 - val_accuracy: 0.6660\n",
      "Epoch 128/500\n",
      "2/2 [==============================] - 1s 647ms/step - loss: 0.0576 - accuracy: 1.0000 - val_loss: 0.9805 - val_accuracy: 0.6661\n",
      "Epoch 129/500\n",
      "2/2 [==============================] - 1s 736ms/step - loss: 0.0577 - accuracy: 1.0000 - val_loss: 0.9791 - val_accuracy: 0.6660\n",
      "Epoch 130/500\n",
      "2/2 [==============================] - 1s 976ms/step - loss: 0.0574 - accuracy: 1.0000 - val_loss: 0.9790 - val_accuracy: 0.6657\n",
      "Epoch 131/500\n",
      "2/2 [==============================] - 1s 864ms/step - loss: 0.0571 - accuracy: 1.0000 - val_loss: 0.9792 - val_accuracy: 0.6657\n",
      "Epoch 132/500\n",
      "2/2 [==============================] - 1s 922ms/step - loss: 0.0572 - accuracy: 1.0000 - val_loss: 0.9785 - val_accuracy: 0.6661\n",
      "Epoch 133/500\n",
      "2/2 [==============================] - 1s 1s/step - loss: 0.0569 - accuracy: 1.0000 - val_loss: 0.9799 - val_accuracy: 0.6656\n",
      "Epoch 134/500\n",
      "2/2 [==============================] - 1s 600ms/step - loss: 0.0569 - accuracy: 1.0000 - val_loss: 0.9803 - val_accuracy: 0.6657\n",
      "Epoch 135/500\n",
      "2/2 [==============================] - 0s 481ms/step - loss: 0.0566 - accuracy: 1.0000 - val_loss: 0.9803 - val_accuracy: 0.6660\n",
      "Epoch 136/500\n",
      "2/2 [==============================] - 0s 463ms/step - loss: 0.0564 - accuracy: 1.0000 - val_loss: 0.9804 - val_accuracy: 0.6660\n",
      "Epoch 137/500\n",
      "2/2 [==============================] - 1s 727ms/step - loss: 0.0564 - accuracy: 1.0000 - val_loss: 0.9799 - val_accuracy: 0.6666\n",
      "Epoch 138/500\n",
      "2/2 [==============================] - 1s 700ms/step - loss: 0.0564 - accuracy: 1.0000 - val_loss: 0.9811 - val_accuracy: 0.6663\n",
      "Epoch 139/500\n",
      "2/2 [==============================] - 1s 847ms/step - loss: 0.0561 - accuracy: 1.0000 - val_loss: 0.9814 - val_accuracy: 0.6664\n",
      "Epoch 140/500\n",
      "2/2 [==============================] - 1s 756ms/step - loss: 0.0561 - accuracy: 1.0000 - val_loss: 0.9820 - val_accuracy: 0.6657\n",
      "Epoch 141/500\n",
      "2/2 [==============================] - 1s 818ms/step - loss: 0.0559 - accuracy: 1.0000 - val_loss: 0.9809 - val_accuracy: 0.6661\n",
      "Epoch 142/500\n",
      "2/2 [==============================] - 1s 764ms/step - loss: 0.0557 - accuracy: 1.0000 - val_loss: 0.9808 - val_accuracy: 0.6664\n",
      "Epoch 143/500\n",
      "2/2 [==============================] - 1s 713ms/step - loss: 0.0556 - accuracy: 1.0000 - val_loss: 0.9813 - val_accuracy: 0.6661\n",
      "Epoch 144/500\n",
      "2/2 [==============================] - 1s 726ms/step - loss: 0.0555 - accuracy: 1.0000 - val_loss: 0.9820 - val_accuracy: 0.6656\n",
      "Epoch 145/500\n",
      "2/2 [==============================] - 1s 725ms/step - loss: 0.0554 - accuracy: 1.0000 - val_loss: 0.9826 - val_accuracy: 0.6656\n",
      "Epoch 146/500\n",
      "2/2 [==============================] - 1s 709ms/step - loss: 0.0555 - accuracy: 1.0000 - val_loss: 0.9806 - val_accuracy: 0.6664\n",
      "Epoch 147/500\n",
      "2/2 [==============================] - 1s 581ms/step - loss: 0.0555 - accuracy: 1.0000 - val_loss: 0.9799 - val_accuracy: 0.6665\n",
      "Epoch 148/500\n",
      "2/2 [==============================] - 1s 513ms/step - loss: 0.0549 - accuracy: 1.0000 - val_loss: 0.9811 - val_accuracy: 0.6664\n",
      "Epoch 149/500\n",
      "2/2 [==============================] - 0s 488ms/step - loss: 0.0553 - accuracy: 1.0000 - val_loss: 0.9832 - val_accuracy: 0.6659\n",
      "Epoch 150/500\n",
      "2/2 [==============================] - 0s 495ms/step - loss: 0.0548 - accuracy: 1.0000 - val_loss: 0.9837 - val_accuracy: 0.6661\n",
      "Epoch 151/500\n",
      "2/2 [==============================] - 0s 453ms/step - loss: 0.0547 - accuracy: 1.0000 - val_loss: 0.9840 - val_accuracy: 0.6664\n",
      "Epoch 152/500\n",
      "2/2 [==============================] - 0s 455ms/step - loss: 0.0544 - accuracy: 1.0000 - val_loss: 0.9832 - val_accuracy: 0.6660\n",
      "Epoch 153/500\n",
      "2/2 [==============================] - 0s 444ms/step - loss: 0.0545 - accuracy: 1.0000 - val_loss: 0.9820 - val_accuracy: 0.6666\n",
      "Epoch 154/500\n",
      "2/2 [==============================] - 0s 454ms/step - loss: 0.0543 - accuracy: 1.0000 - val_loss: 0.9819 - val_accuracy: 0.6666\n",
      "Epoch 155/500\n",
      "2/2 [==============================] - 1s 501ms/step - loss: 0.0543 - accuracy: 1.0000 - val_loss: 0.9811 - val_accuracy: 0.6662\n",
      "Epoch 156/500\n",
      "2/2 [==============================] - 0s 460ms/step - loss: 0.0540 - accuracy: 1.0000 - val_loss: 0.9823 - val_accuracy: 0.6663\n",
      "Epoch 157/500\n",
      "2/2 [==============================] - 0s 468ms/step - loss: 0.0538 - accuracy: 1.0000 - val_loss: 0.9825 - val_accuracy: 0.6661\n",
      "Epoch 158/500\n",
      "2/2 [==============================] - 1s 504ms/step - loss: 0.0537 - accuracy: 1.0000 - val_loss: 0.9825 - val_accuracy: 0.6662\n",
      "Epoch 159/500\n",
      "2/2 [==============================] - 1s 511ms/step - loss: 0.0536 - accuracy: 1.0000 - val_loss: 0.9828 - val_accuracy: 0.6664\n",
      "Epoch 160/500\n",
      "2/2 [==============================] - 0s 465ms/step - loss: 0.0536 - accuracy: 1.0000 - val_loss: 0.9821 - val_accuracy: 0.6661\n",
      "Epoch 161/500\n",
      "2/2 [==============================] - 0s 475ms/step - loss: 0.0535 - accuracy: 1.0000 - val_loss: 0.9823 - val_accuracy: 0.6668\n",
      "Epoch 162/500\n",
      "2/2 [==============================] - 0s 443ms/step - loss: 0.0538 - accuracy: 1.0000 - val_loss: 0.9811 - val_accuracy: 0.6665\n",
      "Epoch 163/500\n",
      "2/2 [==============================] - 0s 430ms/step - loss: 0.0534 - accuracy: 1.0000 - val_loss: 0.9833 - val_accuracy: 0.6660\n",
      "Epoch 164/500\n",
      "2/2 [==============================] - 0s 457ms/step - loss: 0.0530 - accuracy: 1.0000 - val_loss: 0.9833 - val_accuracy: 0.6661\n",
      "Epoch 165/500\n",
      "2/2 [==============================] - 0s 480ms/step - loss: 0.0530 - accuracy: 1.0000 - val_loss: 0.9841 - val_accuracy: 0.6660\n",
      "Epoch 166/500\n",
      "2/2 [==============================] - 1s 510ms/step - loss: 0.0529 - accuracy: 1.0000 - val_loss: 0.9845 - val_accuracy: 0.6661\n",
      "Epoch 167/500\n",
      "2/2 [==============================] - 1s 524ms/step - loss: 0.0528 - accuracy: 1.0000 - val_loss: 0.9852 - val_accuracy: 0.6662\n",
      "Epoch 168/500\n",
      "2/2 [==============================] - 1s 525ms/step - loss: 0.0525 - accuracy: 1.0000 - val_loss: 0.9848 - val_accuracy: 0.6662\n",
      "Epoch 169/500\n",
      "2/2 [==============================] - 1s 688ms/step - loss: 0.0525 - accuracy: 1.0000 - val_loss: 0.9855 - val_accuracy: 0.6661\n",
      "Epoch 170/500\n",
      "2/2 [==============================] - 1s 532ms/step - loss: 0.0524 - accuracy: 1.0000 - val_loss: 0.9850 - val_accuracy: 0.6661\n",
      "Epoch 171/500\n",
      "2/2 [==============================] - 0s 494ms/step - loss: 0.0523 - accuracy: 1.0000 - val_loss: 0.9840 - val_accuracy: 0.6663\n",
      "Epoch 172/500\n",
      "2/2 [==============================] - 0s 451ms/step - loss: 0.0521 - accuracy: 1.0000 - val_loss: 0.9850 - val_accuracy: 0.6661\n",
      "Epoch 173/500\n",
      "2/2 [==============================] - 1s 564ms/step - loss: 0.0521 - accuracy: 1.0000 - val_loss: 0.9840 - val_accuracy: 0.6667\n",
      "Epoch 174/500\n",
      "2/2 [==============================] - 1s 513ms/step - loss: 0.0518 - accuracy: 1.0000 - val_loss: 0.9840 - val_accuracy: 0.6664\n",
      "Epoch 175/500\n",
      "2/2 [==============================] - 0s 454ms/step - loss: 0.0517 - accuracy: 1.0000 - val_loss: 0.9844 - val_accuracy: 0.6665\n",
      "Epoch 176/500\n",
      "2/2 [==============================] - 1s 590ms/step - loss: 0.0516 - accuracy: 1.0000 - val_loss: 0.9840 - val_accuracy: 0.6664\n",
      "Epoch 177/500\n",
      "2/2 [==============================] - 1s 498ms/step - loss: 0.0515 - accuracy: 1.0000 - val_loss: 0.9843 - val_accuracy: 0.6662\n",
      "Epoch 178/500\n",
      "2/2 [==============================] - 0s 489ms/step - loss: 0.0514 - accuracy: 1.0000 - val_loss: 0.9840 - val_accuracy: 0.6661\n",
      "Epoch 179/500\n",
      "2/2 [==============================] - 0s 485ms/step - loss: 0.0515 - accuracy: 1.0000 - val_loss: 0.9852 - val_accuracy: 0.6660\n",
      "Epoch 180/500\n",
      "2/2 [==============================] - 1s 506ms/step - loss: 0.0512 - accuracy: 1.0000 - val_loss: 0.9845 - val_accuracy: 0.6659\n",
      "Epoch 181/500\n",
      "2/2 [==============================] - 1s 609ms/step - loss: 0.0510 - accuracy: 1.0000 - val_loss: 0.9849 - val_accuracy: 0.6663\n",
      "Epoch 182/500\n",
      "2/2 [==============================] - 1s 798ms/step - loss: 0.0510 - accuracy: 1.0000 - val_loss: 0.9844 - val_accuracy: 0.6663\n",
      "Epoch 183/500\n",
      "2/2 [==============================] - 0s 467ms/step - loss: 0.0508 - accuracy: 1.0000 - val_loss: 0.9854 - val_accuracy: 0.6667\n",
      "Epoch 184/500\n",
      "2/2 [==============================] - 1s 501ms/step - loss: 0.0507 - accuracy: 1.0000 - val_loss: 0.9860 - val_accuracy: 0.6668\n",
      "Epoch 185/500\n",
      "2/2 [==============================] - 0s 464ms/step - loss: 0.0506 - accuracy: 1.0000 - val_loss: 0.9862 - val_accuracy: 0.6667\n",
      "Epoch 186/500\n",
      "2/2 [==============================] - 0s 455ms/step - loss: 0.0506 - accuracy: 1.0000 - val_loss: 0.9867 - val_accuracy: 0.6668\n",
      "Epoch 187/500\n",
      "2/2 [==============================] - 1s 535ms/step - loss: 0.0508 - accuracy: 1.0000 - val_loss: 0.9881 - val_accuracy: 0.6664\n",
      "Epoch 188/500\n",
      "2/2 [==============================] - 0s 476ms/step - loss: 0.0504 - accuracy: 1.0000 - val_loss: 0.9881 - val_accuracy: 0.6664\n",
      "Epoch 189/500\n",
      "2/2 [==============================] - 0s 458ms/step - loss: 0.0501 - accuracy: 1.0000 - val_loss: 0.9875 - val_accuracy: 0.6663\n",
      "Epoch 190/500\n",
      "2/2 [==============================] - 0s 463ms/step - loss: 0.0500 - accuracy: 1.0000 - val_loss: 0.9874 - val_accuracy: 0.6665\n",
      "Epoch 191/500\n",
      "2/2 [==============================] - 0s 451ms/step - loss: 0.0501 - accuracy: 1.0000 - val_loss: 0.9867 - val_accuracy: 0.6666\n",
      "Epoch 192/500\n",
      "2/2 [==============================] - 0s 482ms/step - loss: 0.0499 - accuracy: 1.0000 - val_loss: 0.9860 - val_accuracy: 0.6666\n",
      "Epoch 193/500\n",
      "2/2 [==============================] - 1s 517ms/step - loss: 0.0500 - accuracy: 1.0000 - val_loss: 0.9876 - val_accuracy: 0.6667\n",
      "Epoch 194/500\n",
      "2/2 [==============================] - 1s 557ms/step - loss: 0.0496 - accuracy: 1.0000 - val_loss: 0.9873 - val_accuracy: 0.6669\n",
      "Epoch 195/500\n",
      "2/2 [==============================] - 0s 476ms/step - loss: 0.0500 - accuracy: 1.0000 - val_loss: 0.9888 - val_accuracy: 0.6664\n",
      "Epoch 196/500\n",
      "2/2 [==============================] - 0s 493ms/step - loss: 0.0495 - accuracy: 1.0000 - val_loss: 0.9886 - val_accuracy: 0.6665\n",
      "Epoch 197/500\n",
      "2/2 [==============================] - 1s 510ms/step - loss: 0.0494 - accuracy: 1.0000 - val_loss: 0.9872 - val_accuracy: 0.6669\n",
      "Epoch 198/500\n",
      "2/2 [==============================] - 0s 453ms/step - loss: 0.0493 - accuracy: 1.0000 - val_loss: 0.9866 - val_accuracy: 0.6666\n",
      "Epoch 199/500\n",
      "2/2 [==============================] - 0s 453ms/step - loss: 0.0492 - accuracy: 1.0000 - val_loss: 0.9864 - val_accuracy: 0.6664\n",
      "Epoch 200/500\n",
      "2/2 [==============================] - 0s 461ms/step - loss: 0.0492 - accuracy: 1.0000 - val_loss: 0.9857 - val_accuracy: 0.6669\n",
      "Epoch 201/500\n",
      "2/2 [==============================] - 0s 459ms/step - loss: 0.0489 - accuracy: 1.0000 - val_loss: 0.9863 - val_accuracy: 0.6669\n",
      "Epoch 202/500\n",
      "2/2 [==============================] - 1s 571ms/step - loss: 0.0488 - accuracy: 1.0000 - val_loss: 0.9862 - val_accuracy: 0.6668\n",
      "Epoch 203/500\n",
      "2/2 [==============================] - 0s 472ms/step - loss: 0.0488 - accuracy: 1.0000 - val_loss: 0.9876 - val_accuracy: 0.6669\n",
      "Epoch 204/500\n",
      "2/2 [==============================] - 0s 463ms/step - loss: 0.0487 - accuracy: 1.0000 - val_loss: 0.9881 - val_accuracy: 0.6666\n",
      "Epoch 205/500\n",
      "2/2 [==============================] - 0s 453ms/step - loss: 0.0486 - accuracy: 1.0000 - val_loss: 0.9889 - val_accuracy: 0.6667\n",
      "Epoch 206/500\n",
      "2/2 [==============================] - 0s 452ms/step - loss: 0.0485 - accuracy: 1.0000 - val_loss: 0.9892 - val_accuracy: 0.6666\n",
      "Epoch 207/500\n",
      "2/2 [==============================] - 0s 458ms/step - loss: 0.0484 - accuracy: 1.0000 - val_loss: 0.9897 - val_accuracy: 0.6664\n",
      "Epoch 208/500\n",
      "2/2 [==============================] - 0s 457ms/step - loss: 0.0482 - accuracy: 1.0000 - val_loss: 0.9896 - val_accuracy: 0.6663\n",
      "Epoch 209/500\n",
      "2/2 [==============================] - 1s 537ms/step - loss: 0.0483 - accuracy: 1.0000 - val_loss: 0.9883 - val_accuracy: 0.6666\n",
      "Epoch 210/500\n",
      "2/2 [==============================] - 0s 465ms/step - loss: 0.0480 - accuracy: 1.0000 - val_loss: 0.9887 - val_accuracy: 0.6666\n",
      "Epoch 211/500\n",
      "2/2 [==============================] - 0s 441ms/step - loss: 0.0478 - accuracy: 1.0000 - val_loss: 0.9887 - val_accuracy: 0.6667\n",
      "Epoch 212/500\n",
      "2/2 [==============================] - 0s 455ms/step - loss: 0.0480 - accuracy: 1.0000 - val_loss: 0.9885 - val_accuracy: 0.6661\n",
      "Epoch 213/500\n",
      "2/2 [==============================] - 0s 456ms/step - loss: 0.0480 - accuracy: 1.0000 - val_loss: 0.9875 - val_accuracy: 0.6670\n",
      "Epoch 214/500\n",
      "2/2 [==============================] - 0s 465ms/step - loss: 0.0477 - accuracy: 1.0000 - val_loss: 0.9882 - val_accuracy: 0.6671\n",
      "Epoch 215/500\n",
      "2/2 [==============================] - 0s 456ms/step - loss: 0.0474 - accuracy: 1.0000 - val_loss: 0.9886 - val_accuracy: 0.6668\n",
      "Epoch 216/500\n",
      "2/2 [==============================] - 0s 461ms/step - loss: 0.0474 - accuracy: 1.0000 - val_loss: 0.9890 - val_accuracy: 0.6666\n",
      "Epoch 217/500\n",
      "2/2 [==============================] - 0s 471ms/step - loss: 0.0474 - accuracy: 1.0000 - val_loss: 0.9899 - val_accuracy: 0.6667\n",
      "Epoch 218/500\n",
      "2/2 [==============================] - 0s 477ms/step - loss: 0.0472 - accuracy: 1.0000 - val_loss: 0.9897 - val_accuracy: 0.6668\n",
      "Epoch 219/500\n",
      "2/2 [==============================] - 0s 492ms/step - loss: 0.0473 - accuracy: 1.0000 - val_loss: 0.9905 - val_accuracy: 0.6665\n",
      "Epoch 220/500\n",
      "2/2 [==============================] - 0s 438ms/step - loss: 0.0470 - accuracy: 1.0000 - val_loss: 0.9897 - val_accuracy: 0.6667\n",
      "Epoch 221/500\n",
      "2/2 [==============================] - 0s 450ms/step - loss: 0.0472 - accuracy: 1.0000 - val_loss: 0.9906 - val_accuracy: 0.6664\n",
      "Epoch 222/500\n",
      "2/2 [==============================] - 0s 444ms/step - loss: 0.0469 - accuracy: 1.0000 - val_loss: 0.9904 - val_accuracy: 0.6667\n",
      "Epoch 223/500\n",
      "2/2 [==============================] - 0s 454ms/step - loss: 0.0470 - accuracy: 1.0000 - val_loss: 0.9897 - val_accuracy: 0.6672\n",
      "Epoch 224/500\n",
      "2/2 [==============================] - 0s 493ms/step - loss: 0.0466 - accuracy: 1.0000 - val_loss: 0.9898 - val_accuracy: 0.6668\n",
      "Epoch 225/500\n",
      "2/2 [==============================] - 0s 444ms/step - loss: 0.0467 - accuracy: 1.0000 - val_loss: 0.9893 - val_accuracy: 0.6673\n",
      "Epoch 226/500\n",
      "2/2 [==============================] - 0s 451ms/step - loss: 0.0464 - accuracy: 1.0000 - val_loss: 0.9898 - val_accuracy: 0.6671\n",
      "Epoch 227/500\n",
      "2/2 [==============================] - 0s 471ms/step - loss: 0.0463 - accuracy: 1.0000 - val_loss: 0.9903 - val_accuracy: 0.6673\n",
      "Epoch 228/500\n",
      "2/2 [==============================] - 0s 462ms/step - loss: 0.0465 - accuracy: 1.0000 - val_loss: 0.9893 - val_accuracy: 0.6671\n",
      "Epoch 229/500\n",
      "2/2 [==============================] - 0s 434ms/step - loss: 0.0463 - accuracy: 1.0000 - val_loss: 0.9904 - val_accuracy: 0.6674\n",
      "Epoch 230/500\n",
      "2/2 [==============================] - 0s 442ms/step - loss: 0.0462 - accuracy: 1.0000 - val_loss: 0.9907 - val_accuracy: 0.6668\n",
      "Epoch 231/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 466ms/step - loss: 0.0461 - accuracy: 1.0000 - val_loss: 0.9902 - val_accuracy: 0.6664\n",
      "Epoch 232/500\n",
      "2/2 [==============================] - 0s 490ms/step - loss: 0.0458 - accuracy: 1.0000 - val_loss: 0.9898 - val_accuracy: 0.6671\n",
      "Epoch 233/500\n",
      "2/2 [==============================] - 0s 447ms/step - loss: 0.0460 - accuracy: 1.0000 - val_loss: 0.9889 - val_accuracy: 0.6671\n",
      "Epoch 234/500\n",
      "2/2 [==============================] - 0s 448ms/step - loss: 0.0457 - accuracy: 1.0000 - val_loss: 0.9901 - val_accuracy: 0.6666\n",
      "Epoch 235/500\n",
      "2/2 [==============================] - 0s 463ms/step - loss: 0.0457 - accuracy: 1.0000 - val_loss: 0.9897 - val_accuracy: 0.6669\n",
      "Epoch 236/500\n",
      "2/2 [==============================] - 0s 468ms/step - loss: 0.0456 - accuracy: 1.0000 - val_loss: 0.9909 - val_accuracy: 0.6670\n",
      "Epoch 237/500\n",
      "2/2 [==============================] - 0s 457ms/step - loss: 0.0455 - accuracy: 1.0000 - val_loss: 0.9907 - val_accuracy: 0.6670\n",
      "Epoch 238/500\n",
      "2/2 [==============================] - 0s 447ms/step - loss: 0.0453 - accuracy: 1.0000 - val_loss: 0.9911 - val_accuracy: 0.6669\n",
      "Epoch 239/500\n",
      "2/2 [==============================] - 0s 440ms/step - loss: 0.0454 - accuracy: 1.0000 - val_loss: 0.9925 - val_accuracy: 0.6667\n",
      "Epoch 240/500\n",
      "2/2 [==============================] - 0s 473ms/step - loss: 0.0453 - accuracy: 1.0000 - val_loss: 0.9918 - val_accuracy: 0.6662\n",
      "Epoch 241/500\n",
      "2/2 [==============================] - 0s 459ms/step - loss: 0.0451 - accuracy: 1.0000 - val_loss: 0.9919 - val_accuracy: 0.6664\n",
      "Epoch 242/500\n",
      "2/2 [==============================] - 0s 448ms/step - loss: 0.0449 - accuracy: 1.0000 - val_loss: 0.9921 - val_accuracy: 0.6663\n",
      "Epoch 243/500\n",
      "2/2 [==============================] - 0s 434ms/step - loss: 0.0449 - accuracy: 1.0000 - val_loss: 0.9913 - val_accuracy: 0.6669\n",
      "Epoch 244/500\n",
      "2/2 [==============================] - 0s 474ms/step - loss: 0.0453 - accuracy: 1.0000 - val_loss: 0.9897 - val_accuracy: 0.6671\n",
      "Epoch 245/500\n",
      "2/2 [==============================] - 1s 544ms/step - loss: 0.0448 - accuracy: 1.0000 - val_loss: 0.9898 - val_accuracy: 0.6672\n",
      "Epoch 246/500\n",
      "2/2 [==============================] - 1s 503ms/step - loss: 0.0446 - accuracy: 1.0000 - val_loss: 0.9902 - val_accuracy: 0.6670\n",
      "Epoch 247/500\n",
      "2/2 [==============================] - 1s 528ms/step - loss: 0.0447 - accuracy: 1.0000 - val_loss: 0.9897 - val_accuracy: 0.6676\n",
      "Epoch 248/500\n",
      "2/2 [==============================] - 0s 467ms/step - loss: 0.0445 - accuracy: 1.0000 - val_loss: 0.9909 - val_accuracy: 0.6675\n",
      "Epoch 249/500\n",
      "2/2 [==============================] - 0s 446ms/step - loss: 0.0445 - accuracy: 1.0000 - val_loss: 0.9920 - val_accuracy: 0.6668\n",
      "Epoch 250/500\n",
      "2/2 [==============================] - 0s 443ms/step - loss: 0.0442 - accuracy: 1.0000 - val_loss: 0.9915 - val_accuracy: 0.6667\n",
      "Epoch 251/500\n",
      "2/2 [==============================] - 0s 445ms/step - loss: 0.0442 - accuracy: 1.0000 - val_loss: 0.9921 - val_accuracy: 0.6672\n",
      "Epoch 252/500\n",
      "2/2 [==============================] - 0s 447ms/step - loss: 0.0442 - accuracy: 1.0000 - val_loss: 0.9928 - val_accuracy: 0.6672\n",
      "Epoch 253/500\n",
      "2/2 [==============================] - 1s 564ms/step - loss: 0.0441 - accuracy: 1.0000 - val_loss: 0.9929 - val_accuracy: 0.6673\n",
      "Epoch 254/500\n",
      "2/2 [==============================] - 1s 507ms/step - loss: 0.0438 - accuracy: 1.0000 - val_loss: 0.9929 - val_accuracy: 0.6673\n",
      "Epoch 255/500\n",
      "2/2 [==============================] - 0s 449ms/step - loss: 0.0440 - accuracy: 1.0000 - val_loss: 0.9934 - val_accuracy: 0.6673\n",
      "Epoch 256/500\n",
      "2/2 [==============================] - 0s 482ms/step - loss: 0.0438 - accuracy: 1.0000 - val_loss: 0.9929 - val_accuracy: 0.6673\n",
      "Epoch 257/500\n",
      "2/2 [==============================] - 1s 732ms/step - loss: 0.0436 - accuracy: 1.0000 - val_loss: 0.9929 - val_accuracy: 0.6673\n",
      "Epoch 258/500\n",
      "2/2 [==============================] - 0s 493ms/step - loss: 0.0438 - accuracy: 1.0000 - val_loss: 0.9920 - val_accuracy: 0.6672\n",
      "Epoch 259/500\n",
      "2/2 [==============================] - 0s 439ms/step - loss: 0.0435 - accuracy: 1.0000 - val_loss: 0.9923 - val_accuracy: 0.6674\n",
      "Epoch 260/500\n",
      "2/2 [==============================] - 0s 471ms/step - loss: 0.0433 - accuracy: 1.0000 - val_loss: 0.9929 - val_accuracy: 0.6675\n",
      "Epoch 261/500\n",
      "2/2 [==============================] - 1s 588ms/step - loss: 0.0433 - accuracy: 1.0000 - val_loss: 0.9928 - val_accuracy: 0.6675\n",
      "Epoch 262/500\n",
      "2/2 [==============================] - 1s 589ms/step - loss: 0.0432 - accuracy: 1.0000 - val_loss: 0.9932 - val_accuracy: 0.6675\n",
      "Epoch 263/500\n",
      "2/2 [==============================] - 1s 566ms/step - loss: 0.0433 - accuracy: 1.0000 - val_loss: 0.9944 - val_accuracy: 0.6671\n",
      "Epoch 264/500\n",
      "2/2 [==============================] - 1s 498ms/step - loss: 0.0431 - accuracy: 1.0000 - val_loss: 0.9943 - val_accuracy: 0.6670\n",
      "Epoch 265/500\n",
      "2/2 [==============================] - 1s 496ms/step - loss: 0.0430 - accuracy: 1.0000 - val_loss: 0.9943 - val_accuracy: 0.6673\n",
      "Epoch 266/500\n",
      "2/2 [==============================] - 1s 730ms/step - loss: 0.0430 - accuracy: 1.0000 - val_loss: 0.9935 - val_accuracy: 0.6676\n",
      "Epoch 267/500\n",
      "2/2 [==============================] - 1s 796ms/step - loss: 0.0428 - accuracy: 1.0000 - val_loss: 0.9940 - val_accuracy: 0.6668\n",
      "Epoch 268/500\n",
      "2/2 [==============================] - 1s 575ms/step - loss: 0.0427 - accuracy: 1.0000 - val_loss: 0.9937 - val_accuracy: 0.6670\n",
      "Epoch 269/500\n",
      "2/2 [==============================] - 0s 466ms/step - loss: 0.0428 - accuracy: 1.0000 - val_loss: 0.9934 - val_accuracy: 0.6672\n",
      "Epoch 270/500\n",
      "2/2 [==============================] - 0s 443ms/step - loss: 0.0426 - accuracy: 1.0000 - val_loss: 0.9933 - val_accuracy: 0.6673\n",
      "Epoch 271/500\n",
      "2/2 [==============================] - 0s 460ms/step - loss: 0.0425 - accuracy: 1.0000 - val_loss: 0.9944 - val_accuracy: 0.6667\n",
      "Epoch 272/500\n",
      "2/2 [==============================] - 1s 625ms/step - loss: 0.0425 - accuracy: 1.0000 - val_loss: 0.9941 - val_accuracy: 0.6676\n",
      "Epoch 273/500\n",
      "2/2 [==============================] - 1s 602ms/step - loss: 0.0423 - accuracy: 1.0000 - val_loss: 0.9948 - val_accuracy: 0.6669\n",
      "Epoch 274/500\n",
      "2/2 [==============================] - 1s 576ms/step - loss: 0.0425 - accuracy: 1.0000 - val_loss: 0.9938 - val_accuracy: 0.6673\n",
      "Epoch 275/500\n",
      "2/2 [==============================] - 1s 590ms/step - loss: 0.0421 - accuracy: 1.0000 - val_loss: 0.9947 - val_accuracy: 0.6673\n",
      "Epoch 276/500\n",
      "2/2 [==============================] - 1s 572ms/step - loss: 0.0422 - accuracy: 1.0000 - val_loss: 0.9955 - val_accuracy: 0.6670\n",
      "Epoch 277/500\n",
      "2/2 [==============================] - 0s 495ms/step - loss: 0.0420 - accuracy: 1.0000 - val_loss: 0.9962 - val_accuracy: 0.6669\n",
      "Epoch 278/500\n",
      "2/2 [==============================] - 1s 546ms/step - loss: 0.0419 - accuracy: 1.0000 - val_loss: 0.9964 - val_accuracy: 0.6669\n",
      "Epoch 279/500\n",
      "2/2 [==============================] - 1s 507ms/step - loss: 0.0420 - accuracy: 1.0000 - val_loss: 0.9958 - val_accuracy: 0.6671\n",
      "Epoch 280/500\n",
      "2/2 [==============================] - 1s 561ms/step - loss: 0.0418 - accuracy: 1.0000 - val_loss: 0.9962 - val_accuracy: 0.6672\n",
      "Epoch 281/500\n",
      "2/2 [==============================] - 1s 613ms/step - loss: 0.0416 - accuracy: 1.0000 - val_loss: 0.9963 - val_accuracy: 0.6673\n",
      "Epoch 282/500\n",
      "2/2 [==============================] - 1s 602ms/step - loss: 0.0416 - accuracy: 1.0000 - val_loss: 0.9957 - val_accuracy: 0.6670\n",
      "Epoch 283/500\n",
      "2/2 [==============================] - 1s 618ms/step - loss: 0.0416 - accuracy: 1.0000 - val_loss: 0.9958 - val_accuracy: 0.6673\n",
      "Epoch 284/500\n",
      "2/2 [==============================] - 1s 590ms/step - loss: 0.0416 - accuracy: 1.0000 - val_loss: 0.9952 - val_accuracy: 0.6672\n",
      "Epoch 285/500\n",
      "2/2 [==============================] - 1s 623ms/step - loss: 0.0415 - accuracy: 1.0000 - val_loss: 0.9960 - val_accuracy: 0.6669\n",
      "Epoch 286/500\n",
      "2/2 [==============================] - 1s 528ms/step - loss: 0.0413 - accuracy: 1.0000 - val_loss: 0.9955 - val_accuracy: 0.6671\n",
      "Epoch 287/500\n",
      "2/2 [==============================] - 1s 564ms/step - loss: 0.0412 - accuracy: 1.0000 - val_loss: 0.9958 - val_accuracy: 0.6670\n",
      "Epoch 288/500\n",
      "2/2 [==============================] - 1s 645ms/step - loss: 0.0411 - accuracy: 1.0000 - val_loss: 0.9960 - val_accuracy: 0.6671\n",
      "Epoch 289/500\n",
      "2/2 [==============================] - 1s 822ms/step - loss: 0.0412 - accuracy: 1.0000 - val_loss: 0.9969 - val_accuracy: 0.6669\n",
      "Epoch 290/500\n",
      "2/2 [==============================] - 1s 617ms/step - loss: 0.0410 - accuracy: 1.0000 - val_loss: 0.9974 - val_accuracy: 0.6668\n",
      "Epoch 291/500\n",
      "2/2 [==============================] - 1s 694ms/step - loss: 0.0408 - accuracy: 1.0000 - val_loss: 0.9969 - val_accuracy: 0.6671\n",
      "Epoch 292/500\n",
      "2/2 [==============================] - 1s 941ms/step - loss: 0.0408 - accuracy: 1.0000 - val_loss: 0.9973 - val_accuracy: 0.6671\n",
      "Epoch 293/500\n",
      "2/2 [==============================] - 1s 851ms/step - loss: 0.0407 - accuracy: 1.0000 - val_loss: 0.9978 - val_accuracy: 0.6668\n",
      "Epoch 294/500\n",
      "2/2 [==============================] - 1s 702ms/step - loss: 0.0408 - accuracy: 1.0000 - val_loss: 0.9968 - val_accuracy: 0.6672\n",
      "Epoch 295/500\n",
      "2/2 [==============================] - 1s 695ms/step - loss: 0.0405 - accuracy: 1.0000 - val_loss: 0.9974 - val_accuracy: 0.6669\n",
      "Epoch 296/500\n",
      "2/2 [==============================] - 1s 747ms/step - loss: 0.0405 - accuracy: 1.0000 - val_loss: 0.9968 - val_accuracy: 0.6674\n",
      "Epoch 297/500\n",
      "2/2 [==============================] - 1s 1s/step - loss: 0.0406 - accuracy: 1.0000 - val_loss: 0.9966 - val_accuracy: 0.6672\n",
      "Epoch 298/500\n",
      "2/2 [==============================] - 2s 2s/step - loss: 0.0403 - accuracy: 1.0000 - val_loss: 0.9968 - val_accuracy: 0.6674\n",
      "Epoch 299/500\n",
      "2/2 [==============================] - 1s 1s/step - loss: 0.0403 - accuracy: 1.0000 - val_loss: 0.9974 - val_accuracy: 0.6671\n",
      "Epoch 300/500\n",
      "2/2 [==============================] - 1s 1s/step - loss: 0.0402 - accuracy: 1.0000 - val_loss: 0.9968 - val_accuracy: 0.6673\n",
      "Epoch 301/500\n",
      "2/2 [==============================] - 1s 945ms/step - loss: 0.0401 - accuracy: 1.0000 - val_loss: 0.9973 - val_accuracy: 0.6671\n",
      "Epoch 302/500\n",
      "2/2 [==============================] - 1s 662ms/step - loss: 0.0401 - accuracy: 1.0000 - val_loss: 0.9976 - val_accuracy: 0.6669\n",
      "Epoch 303/500\n",
      "2/2 [==============================] - 0s 464ms/step - loss: 0.0400 - accuracy: 1.0000 - val_loss: 0.9973 - val_accuracy: 0.6674\n",
      "Epoch 304/500\n",
      "2/2 [==============================] - 0s 445ms/step - loss: 0.0398 - accuracy: 1.0000 - val_loss: 0.9977 - val_accuracy: 0.6672\n",
      "Epoch 305/500\n",
      "2/2 [==============================] - 0s 472ms/step - loss: 0.0398 - accuracy: 1.0000 - val_loss: 0.9973 - val_accuracy: 0.6673\n",
      "Epoch 306/500\n",
      "2/2 [==============================] - 0s 473ms/step - loss: 0.0398 - accuracy: 1.0000 - val_loss: 0.9974 - val_accuracy: 0.6671\n",
      "Epoch 307/500\n",
      "2/2 [==============================] - 0s 474ms/step - loss: 0.0398 - accuracy: 1.0000 - val_loss: 0.9968 - val_accuracy: 0.6671\n",
      "Epoch 308/500\n",
      "2/2 [==============================] - 0s 449ms/step - loss: 0.0396 - accuracy: 1.0000 - val_loss: 0.9970 - val_accuracy: 0.6669\n",
      "Epoch 309/500\n",
      "2/2 [==============================] - 0s 455ms/step - loss: 0.0395 - accuracy: 1.0000 - val_loss: 0.9975 - val_accuracy: 0.6670\n",
      "Epoch 310/500\n",
      "2/2 [==============================] - 0s 441ms/step - loss: 0.0394 - accuracy: 1.0000 - val_loss: 0.9982 - val_accuracy: 0.6675\n",
      "Epoch 311/500\n",
      "2/2 [==============================] - 0s 448ms/step - loss: 0.0394 - accuracy: 1.0000 - val_loss: 0.9979 - val_accuracy: 0.6675\n",
      "Epoch 312/500\n",
      "2/2 [==============================] - 0s 451ms/step - loss: 0.0393 - accuracy: 1.0000 - val_loss: 0.9987 - val_accuracy: 0.6673\n",
      "Epoch 313/500\n",
      "2/2 [==============================] - 0s 452ms/step - loss: 0.0392 - accuracy: 1.0000 - val_loss: 0.9991 - val_accuracy: 0.6673\n",
      "Epoch 314/500\n",
      "2/2 [==============================] - 0s 459ms/step - loss: 0.0392 - accuracy: 1.0000 - val_loss: 0.9986 - val_accuracy: 0.6674\n",
      "Epoch 315/500\n",
      "2/2 [==============================] - 0s 455ms/step - loss: 0.0392 - accuracy: 1.0000 - val_loss: 0.9986 - val_accuracy: 0.6671\n",
      "Epoch 316/500\n",
      "2/2 [==============================] - 0s 448ms/step - loss: 0.0391 - accuracy: 1.0000 - val_loss: 0.9988 - val_accuracy: 0.6673\n",
      "Epoch 317/500\n",
      "2/2 [==============================] - 0s 433ms/step - loss: 0.0389 - accuracy: 1.0000 - val_loss: 0.9994 - val_accuracy: 0.6674\n",
      "Epoch 318/500\n",
      "2/2 [==============================] - 0s 497ms/step - loss: 0.0389 - accuracy: 1.0000 - val_loss: 0.9998 - val_accuracy: 0.6673\n",
      "Epoch 319/500\n",
      "2/2 [==============================] - 1s 732ms/step - loss: 0.0388 - accuracy: 1.0000 - val_loss: 0.9998 - val_accuracy: 0.6672\n",
      "Epoch 320/500\n",
      "2/2 [==============================] - 1s 704ms/step - loss: 0.0387 - accuracy: 1.0000 - val_loss: 0.9995 - val_accuracy: 0.6673\n",
      "Epoch 321/500\n",
      "2/2 [==============================] - 1s 763ms/step - loss: 0.0387 - accuracy: 1.0000 - val_loss: 0.9995 - val_accuracy: 0.6671\n",
      "Epoch 322/500\n",
      "2/2 [==============================] - 1s 738ms/step - loss: 0.0386 - accuracy: 1.0000 - val_loss: 1.0003 - val_accuracy: 0.6671\n",
      "Epoch 323/500\n",
      "2/2 [==============================] - 1s 772ms/step - loss: 0.0386 - accuracy: 1.0000 - val_loss: 0.9999 - val_accuracy: 0.6674\n",
      "Epoch 324/500\n",
      "2/2 [==============================] - 1s 559ms/step - loss: 0.0386 - accuracy: 1.0000 - val_loss: 0.9991 - val_accuracy: 0.6675\n",
      "Epoch 325/500\n",
      "2/2 [==============================] - 1s 668ms/step - loss: 0.0385 - accuracy: 1.0000 - val_loss: 0.9984 - val_accuracy: 0.6673\n",
      "Epoch 326/500\n",
      "2/2 [==============================] - 1s 697ms/step - loss: 0.0383 - accuracy: 1.0000 - val_loss: 0.9991 - val_accuracy: 0.6672\n",
      "Epoch 327/500\n",
      "2/2 [==============================] - 1s 675ms/step - loss: 0.0382 - accuracy: 1.0000 - val_loss: 0.9992 - val_accuracy: 0.6672\n",
      "Epoch 328/500\n",
      "2/2 [==============================] - 1s 661ms/step - loss: 0.0383 - accuracy: 1.0000 - val_loss: 0.9991 - val_accuracy: 0.6675\n",
      "Epoch 329/500\n",
      "2/2 [==============================] - 1s 536ms/step - loss: 0.0382 - accuracy: 1.0000 - val_loss: 1.0003 - val_accuracy: 0.6674\n",
      "Epoch 330/500\n",
      "2/2 [==============================] - 0s 494ms/step - loss: 0.0382 - accuracy: 1.0000 - val_loss: 0.9998 - val_accuracy: 0.6671\n",
      "Epoch 331/500\n",
      "2/2 [==============================] - 1s 504ms/step - loss: 0.0380 - accuracy: 1.0000 - val_loss: 1.0002 - val_accuracy: 0.6675\n",
      "Epoch 332/500\n",
      "2/2 [==============================] - 0s 483ms/step - loss: 0.0380 - accuracy: 1.0000 - val_loss: 1.0006 - val_accuracy: 0.6676\n",
      "Epoch 333/500\n",
      "2/2 [==============================] - 1s 510ms/step - loss: 0.0378 - accuracy: 1.0000 - val_loss: 1.0004 - val_accuracy: 0.6676\n",
      "Epoch 334/500\n",
      "2/2 [==============================] - 1s 554ms/step - loss: 0.0379 - accuracy: 1.0000 - val_loss: 1.0001 - val_accuracy: 0.6675\n",
      "Epoch 335/500\n",
      "2/2 [==============================] - 0s 475ms/step - loss: 0.0378 - accuracy: 1.0000 - val_loss: 1.0001 - val_accuracy: 0.6675\n",
      "Epoch 336/500\n",
      "2/2 [==============================] - 0s 475ms/step - loss: 0.0378 - accuracy: 1.0000 - val_loss: 0.9998 - val_accuracy: 0.6671\n",
      "Epoch 337/500\n",
      "2/2 [==============================] - 0s 446ms/step - loss: 0.0376 - accuracy: 1.0000 - val_loss: 1.0002 - val_accuracy: 0.6671\n",
      "Epoch 338/500\n",
      "2/2 [==============================] - 0s 478ms/step - loss: 0.0376 - accuracy: 1.0000 - val_loss: 1.0012 - val_accuracy: 0.6672\n",
      "Epoch 339/500\n",
      "2/2 [==============================] - 0s 475ms/step - loss: 0.0374 - accuracy: 1.0000 - val_loss: 1.0015 - val_accuracy: 0.6674\n",
      "Epoch 340/500\n",
      "2/2 [==============================] - 1s 500ms/step - loss: 0.0375 - accuracy: 1.0000 - val_loss: 1.0026 - val_accuracy: 0.6672\n",
      "Epoch 341/500\n",
      "2/2 [==============================] - 0s 494ms/step - loss: 0.0374 - accuracy: 1.0000 - val_loss: 1.0017 - val_accuracy: 0.6675\n",
      "Epoch 342/500\n",
      "2/2 [==============================] - 1s 503ms/step - loss: 0.0372 - accuracy: 1.0000 - val_loss: 1.0017 - val_accuracy: 0.6674\n",
      "Epoch 343/500\n",
      "2/2 [==============================] - 0s 444ms/step - loss: 0.0372 - accuracy: 1.0000 - val_loss: 1.0015 - val_accuracy: 0.6674\n",
      "Epoch 344/500\n",
      "2/2 [==============================] - 0s 485ms/step - loss: 0.0372 - accuracy: 1.0000 - val_loss: 1.0023 - val_accuracy: 0.6673\n",
      "Epoch 345/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 451ms/step - loss: 0.0372 - accuracy: 1.0000 - val_loss: 1.0027 - val_accuracy: 0.6674\n",
      "Epoch 346/500\n",
      "2/2 [==============================] - 0s 483ms/step - loss: 0.0370 - accuracy: 1.0000 - val_loss: 1.0025 - val_accuracy: 0.6674\n",
      "Epoch 347/500\n",
      "2/2 [==============================] - 1s 499ms/step - loss: 0.0369 - accuracy: 1.0000 - val_loss: 1.0024 - val_accuracy: 0.6673\n",
      "Epoch 348/500\n",
      "2/2 [==============================] - 1s 543ms/step - loss: 0.0369 - accuracy: 1.0000 - val_loss: 1.0024 - val_accuracy: 0.6673\n",
      "Epoch 349/500\n",
      "2/2 [==============================] - 0s 456ms/step - loss: 0.0370 - accuracy: 1.0000 - val_loss: 1.0016 - val_accuracy: 0.6672\n",
      "Epoch 350/500\n",
      "2/2 [==============================] - 0s 476ms/step - loss: 0.0367 - accuracy: 1.0000 - val_loss: 1.0018 - val_accuracy: 0.6677\n",
      "Epoch 351/500\n",
      "2/2 [==============================] - 1s 575ms/step - loss: 0.0367 - accuracy: 1.0000 - val_loss: 1.0026 - val_accuracy: 0.6675\n",
      "Epoch 352/500\n",
      "2/2 [==============================] - 1s 576ms/step - loss: 0.0368 - accuracy: 1.0000 - val_loss: 1.0018 - val_accuracy: 0.6677\n",
      "Epoch 353/500\n",
      "2/2 [==============================] - 1s 606ms/step - loss: 0.0366 - accuracy: 1.0000 - val_loss: 1.0028 - val_accuracy: 0.6676\n",
      "Epoch 354/500\n",
      "2/2 [==============================] - 1s 586ms/step - loss: 0.0365 - accuracy: 1.0000 - val_loss: 1.0029 - val_accuracy: 0.6673\n",
      "Epoch 355/500\n",
      "2/2 [==============================] - 1s 543ms/step - loss: 0.0364 - accuracy: 1.0000 - val_loss: 1.0034 - val_accuracy: 0.6674\n",
      "Epoch 356/500\n",
      "2/2 [==============================] - 1s 567ms/step - loss: 0.0365 - accuracy: 1.0000 - val_loss: 1.0043 - val_accuracy: 0.6673\n",
      "Epoch 357/500\n",
      "2/2 [==============================] - 1s 618ms/step - loss: 0.0363 - accuracy: 1.0000 - val_loss: 1.0042 - val_accuracy: 0.6674\n",
      "Epoch 358/500\n",
      "2/2 [==============================] - 1s 682ms/step - loss: 0.0363 - accuracy: 1.0000 - val_loss: 1.0048 - val_accuracy: 0.6672\n",
      "Epoch 359/500\n",
      "2/2 [==============================] - 1s 575ms/step - loss: 0.0362 - accuracy: 1.0000 - val_loss: 1.0048 - val_accuracy: 0.6673\n",
      "Epoch 360/500\n",
      "2/2 [==============================] - 1s 782ms/step - loss: 0.0361 - accuracy: 1.0000 - val_loss: 1.0051 - val_accuracy: 0.6672\n",
      "Epoch 361/500\n",
      "2/2 [==============================] - 1s 733ms/step - loss: 0.0361 - accuracy: 1.0000 - val_loss: 1.0050 - val_accuracy: 0.6673\n",
      "Epoch 362/500\n",
      "2/2 [==============================] - 1s 961ms/step - loss: 0.0362 - accuracy: 1.0000 - val_loss: 1.0059 - val_accuracy: 0.6670\n",
      "Epoch 363/500\n",
      "2/2 [==============================] - 1s 906ms/step - loss: 0.0359 - accuracy: 1.0000 - val_loss: 1.0056 - val_accuracy: 0.6670\n",
      "Epoch 364/500\n",
      "2/2 [==============================] - 1s 595ms/step - loss: 0.0362 - accuracy: 1.0000 - val_loss: 1.0041 - val_accuracy: 0.6674\n",
      "Epoch 365/500\n",
      "2/2 [==============================] - 1s 508ms/step - loss: 0.0360 - accuracy: 1.0000 - val_loss: 1.0033 - val_accuracy: 0.6674\n",
      "Epoch 366/500\n",
      "2/2 [==============================] - 0s 471ms/step - loss: 0.0357 - accuracy: 1.0000 - val_loss: 1.0042 - val_accuracy: 0.6671\n",
      "Epoch 367/500\n",
      "2/2 [==============================] - 0s 446ms/step - loss: 0.0358 - accuracy: 1.0000 - val_loss: 1.0037 - val_accuracy: 0.6672\n",
      "Epoch 368/500\n",
      "2/2 [==============================] - 0s 482ms/step - loss: 0.0357 - accuracy: 1.0000 - val_loss: 1.0050 - val_accuracy: 0.6671\n",
      "Epoch 369/500\n",
      "2/2 [==============================] - 0s 480ms/step - loss: 0.0356 - accuracy: 1.0000 - val_loss: 1.0050 - val_accuracy: 0.6670\n",
      "Epoch 370/500\n",
      "2/2 [==============================] - 0s 477ms/step - loss: 0.0355 - accuracy: 1.0000 - val_loss: 1.0049 - val_accuracy: 0.6673\n",
      "Epoch 371/500\n",
      "2/2 [==============================] - 0s 445ms/step - loss: 0.0356 - accuracy: 1.0000 - val_loss: 1.0058 - val_accuracy: 0.6675\n",
      "Epoch 372/500\n",
      "2/2 [==============================] - 1s 502ms/step - loss: 0.0354 - accuracy: 1.0000 - val_loss: 1.0054 - val_accuracy: 0.6672\n",
      "Epoch 373/500\n",
      "2/2 [==============================] - 0s 471ms/step - loss: 0.0353 - accuracy: 1.0000 - val_loss: 1.0051 - val_accuracy: 0.6672\n",
      "Epoch 374/500\n",
      "2/2 [==============================] - 1s 533ms/step - loss: 0.0353 - accuracy: 1.0000 - val_loss: 1.0058 - val_accuracy: 0.6674\n",
      "Epoch 375/500\n",
      "2/2 [==============================] - 1s 598ms/step - loss: 0.0352 - accuracy: 1.0000 - val_loss: 1.0053 - val_accuracy: 0.6672\n",
      "Epoch 376/500\n",
      "2/2 [==============================] - 1s 993ms/step - loss: 0.0352 - accuracy: 1.0000 - val_loss: 1.0061 - val_accuracy: 0.6673\n",
      "Epoch 377/500\n",
      "2/2 [==============================] - 1s 1s/step - loss: 0.0351 - accuracy: 1.0000 - val_loss: 1.0067 - val_accuracy: 0.6675\n",
      "Epoch 378/500\n",
      "2/2 [==============================] - 1s 1s/step - loss: 0.0352 - accuracy: 1.0000 - val_loss: 1.0077 - val_accuracy: 0.6669\n",
      "Epoch 379/500\n",
      "2/2 [==============================] - 1s 959ms/step - loss: 0.0350 - accuracy: 1.0000 - val_loss: 1.0065 - val_accuracy: 0.6674\n",
      "Epoch 380/500\n",
      "2/2 [==============================] - 1s 762ms/step - loss: 0.0351 - accuracy: 1.0000 - val_loss: 1.0076 - val_accuracy: 0.6670\n",
      "Epoch 381/500\n",
      "2/2 [==============================] - 1s 543ms/step - loss: 0.0349 - accuracy: 1.0000 - val_loss: 1.0079 - val_accuracy: 0.6670\n",
      "Epoch 382/500\n",
      "2/2 [==============================] - 0s 464ms/step - loss: 0.0348 - accuracy: 1.0000 - val_loss: 1.0080 - val_accuracy: 0.6670\n",
      "Epoch 383/500\n",
      "2/2 [==============================] - 0s 433ms/step - loss: 0.0348 - accuracy: 1.0000 - val_loss: 1.0076 - val_accuracy: 0.6673\n",
      "Epoch 384/500\n",
      "2/2 [==============================] - 1s 506ms/step - loss: 0.0347 - accuracy: 1.0000 - val_loss: 1.0075 - val_accuracy: 0.6678\n",
      "Epoch 385/500\n",
      "2/2 [==============================] - 0s 462ms/step - loss: 0.0346 - accuracy: 1.0000 - val_loss: 1.0076 - val_accuracy: 0.6677\n",
      "Epoch 386/500\n",
      "2/2 [==============================] - 0s 480ms/step - loss: 0.0346 - accuracy: 1.0000 - val_loss: 1.0077 - val_accuracy: 0.6677\n",
      "Epoch 387/500\n",
      "2/2 [==============================] - 0s 481ms/step - loss: 0.0345 - accuracy: 1.0000 - val_loss: 1.0076 - val_accuracy: 0.6674\n",
      "Epoch 388/500\n",
      "2/2 [==============================] - 1s 538ms/step - loss: 0.0344 - accuracy: 1.0000 - val_loss: 1.0079 - val_accuracy: 0.6675\n",
      "Epoch 389/500\n",
      "2/2 [==============================] - 1s 514ms/step - loss: 0.0344 - accuracy: 1.0000 - val_loss: 1.0071 - val_accuracy: 0.6675\n",
      "Epoch 390/500\n",
      "2/2 [==============================] - 1s 544ms/step - loss: 0.0343 - accuracy: 1.0000 - val_loss: 1.0071 - val_accuracy: 0.6674\n",
      "Epoch 391/500\n",
      "2/2 [==============================] - 0s 477ms/step - loss: 0.0342 - accuracy: 1.0000 - val_loss: 1.0072 - val_accuracy: 0.6673\n",
      "Epoch 392/500\n",
      "2/2 [==============================] - 0s 449ms/step - loss: 0.0342 - accuracy: 1.0000 - val_loss: 1.0075 - val_accuracy: 0.6674\n",
      "Epoch 393/500\n",
      "2/2 [==============================] - 1s 502ms/step - loss: 0.0342 - accuracy: 1.0000 - val_loss: 1.0083 - val_accuracy: 0.6675\n",
      "Epoch 394/500\n",
      "2/2 [==============================] - 1s 594ms/step - loss: 0.0341 - accuracy: 1.0000 - val_loss: 1.0083 - val_accuracy: 0.6675\n",
      "Epoch 395/500\n",
      "2/2 [==============================] - 0s 485ms/step - loss: 0.0340 - accuracy: 1.0000 - val_loss: 1.0083 - val_accuracy: 0.6675\n",
      "Epoch 396/500\n",
      "2/2 [==============================] - 1s 608ms/step - loss: 0.0341 - accuracy: 1.0000 - val_loss: 1.0078 - val_accuracy: 0.6675\n",
      "Epoch 397/500\n",
      "2/2 [==============================] - 0s 453ms/step - loss: 0.0339 - accuracy: 1.0000 - val_loss: 1.0076 - val_accuracy: 0.6674\n",
      "Epoch 398/500\n",
      "2/2 [==============================] - 1s 616ms/step - loss: 0.0339 - accuracy: 1.0000 - val_loss: 1.0082 - val_accuracy: 0.6675\n",
      "Epoch 399/500\n",
      "2/2 [==============================] - 1s 685ms/step - loss: 0.0338 - accuracy: 1.0000 - val_loss: 1.0082 - val_accuracy: 0.6675\n",
      "Epoch 400/500\n",
      "2/2 [==============================] - 1s 1s/step - loss: 0.0337 - accuracy: 1.0000 - val_loss: 1.0081 - val_accuracy: 0.6675\n",
      "Epoch 401/500\n",
      "2/2 [==============================] - 1s 779ms/step - loss: 0.0337 - accuracy: 1.0000 - val_loss: 1.0083 - val_accuracy: 0.6674\n",
      "Epoch 402/500\n",
      "2/2 [==============================] - 1s 590ms/step - loss: 0.0337 - accuracy: 1.0000 - val_loss: 1.0087 - val_accuracy: 0.6673\n",
      "Epoch 403/500\n",
      "2/2 [==============================] - 1s 643ms/step - loss: 0.0336 - accuracy: 1.0000 - val_loss: 1.0081 - val_accuracy: 0.6677\n",
      "Epoch 404/500\n",
      "2/2 [==============================] - 1s 508ms/step - loss: 0.0335 - accuracy: 1.0000 - val_loss: 1.0084 - val_accuracy: 0.6675\n",
      "Epoch 405/500\n",
      "2/2 [==============================] - 0s 470ms/step - loss: 0.0335 - accuracy: 1.0000 - val_loss: 1.0083 - val_accuracy: 0.6676\n",
      "Epoch 406/500\n",
      "2/2 [==============================] - 1s 530ms/step - loss: 0.0335 - accuracy: 1.0000 - val_loss: 1.0078 - val_accuracy: 0.6674\n",
      "Epoch 407/500\n",
      "2/2 [==============================] - 1s 518ms/step - loss: 0.0334 - accuracy: 1.0000 - val_loss: 1.0083 - val_accuracy: 0.6676\n",
      "Epoch 408/500\n",
      "2/2 [==============================] - 1s 511ms/step - loss: 0.0334 - accuracy: 1.0000 - val_loss: 1.0081 - val_accuracy: 0.6675\n",
      "Epoch 409/500\n",
      "2/2 [==============================] - 0s 454ms/step - loss: 0.0333 - accuracy: 1.0000 - val_loss: 1.0087 - val_accuracy: 0.6677\n",
      "Epoch 410/500\n",
      "2/2 [==============================] - 1s 515ms/step - loss: 0.0332 - accuracy: 1.0000 - val_loss: 1.0090 - val_accuracy: 0.6679\n",
      "Epoch 411/500\n",
      "2/2 [==============================] - 0s 459ms/step - loss: 0.0332 - accuracy: 1.0000 - val_loss: 1.0090 - val_accuracy: 0.6678\n",
      "Epoch 412/500\n",
      "2/2 [==============================] - 0s 460ms/step - loss: 0.0331 - accuracy: 1.0000 - val_loss: 1.0095 - val_accuracy: 0.6678\n",
      "Epoch 413/500\n",
      "2/2 [==============================] - 1s 518ms/step - loss: 0.0330 - accuracy: 1.0000 - val_loss: 1.0092 - val_accuracy: 0.6680\n",
      "Epoch 414/500\n",
      "2/2 [==============================] - 0s 440ms/step - loss: 0.0331 - accuracy: 1.0000 - val_loss: 1.0092 - val_accuracy: 0.6676\n",
      "Epoch 415/500\n",
      "2/2 [==============================] - 0s 438ms/step - loss: 0.0329 - accuracy: 1.0000 - val_loss: 1.0095 - val_accuracy: 0.6675\n",
      "Epoch 416/500\n",
      "2/2 [==============================] - 0s 489ms/step - loss: 0.0330 - accuracy: 1.0000 - val_loss: 1.0087 - val_accuracy: 0.6678\n",
      "Epoch 417/500\n",
      "2/2 [==============================] - 0s 473ms/step - loss: 0.0328 - accuracy: 1.0000 - val_loss: 1.0095 - val_accuracy: 0.6677\n",
      "Epoch 418/500\n",
      "2/2 [==============================] - 1s 573ms/step - loss: 0.0329 - accuracy: 1.0000 - val_loss: 1.0090 - val_accuracy: 0.6676\n",
      "Epoch 419/500\n",
      "2/2 [==============================] - 0s 446ms/step - loss: 0.0327 - accuracy: 1.0000 - val_loss: 1.0093 - val_accuracy: 0.6676\n",
      "Epoch 420/500\n",
      "2/2 [==============================] - 0s 442ms/step - loss: 0.0327 - accuracy: 1.0000 - val_loss: 1.0100 - val_accuracy: 0.6676\n",
      "Epoch 421/500\n",
      "2/2 [==============================] - 1s 561ms/step - loss: 0.0327 - accuracy: 1.0000 - val_loss: 1.0098 - val_accuracy: 0.6677\n",
      "Epoch 422/500\n",
      "2/2 [==============================] - 0s 457ms/step - loss: 0.0328 - accuracy: 1.0000 - val_loss: 1.0091 - val_accuracy: 0.6675\n",
      "Epoch 423/500\n",
      "2/2 [==============================] - 1s 721ms/step - loss: 0.0325 - accuracy: 1.0000 - val_loss: 1.0100 - val_accuracy: 0.6674\n",
      "Epoch 424/500\n",
      "2/2 [==============================] - 0s 452ms/step - loss: 0.0325 - accuracy: 1.0000 - val_loss: 1.0100 - val_accuracy: 0.6677\n",
      "Epoch 425/500\n",
      "2/2 [==============================] - 0s 457ms/step - loss: 0.0324 - accuracy: 1.0000 - val_loss: 1.0102 - val_accuracy: 0.6676\n",
      "Epoch 426/500\n",
      "2/2 [==============================] - 0s 460ms/step - loss: 0.0324 - accuracy: 1.0000 - val_loss: 1.0107 - val_accuracy: 0.6677\n",
      "Epoch 427/500\n",
      "2/2 [==============================] - 0s 448ms/step - loss: 0.0323 - accuracy: 1.0000 - val_loss: 1.0109 - val_accuracy: 0.6678\n",
      "Epoch 428/500\n",
      "2/2 [==============================] - 0s 459ms/step - loss: 0.0323 - accuracy: 1.0000 - val_loss: 1.0107 - val_accuracy: 0.6676\n",
      "Epoch 429/500\n",
      "2/2 [==============================] - 0s 440ms/step - loss: 0.0322 - accuracy: 1.0000 - val_loss: 1.0108 - val_accuracy: 0.6676\n",
      "Epoch 430/500\n",
      "2/2 [==============================] - 0s 446ms/step - loss: 0.0322 - accuracy: 1.0000 - val_loss: 1.0111 - val_accuracy: 0.6677\n",
      "Epoch 431/500\n",
      "2/2 [==============================] - 0s 451ms/step - loss: 0.0321 - accuracy: 1.0000 - val_loss: 1.0108 - val_accuracy: 0.6677\n",
      "Epoch 432/500\n",
      "2/2 [==============================] - 1s 629ms/step - loss: 0.0320 - accuracy: 1.0000 - val_loss: 1.0111 - val_accuracy: 0.6677\n",
      "Epoch 433/500\n",
      "2/2 [==============================] - 1s 857ms/step - loss: 0.0321 - accuracy: 1.0000 - val_loss: 1.0120 - val_accuracy: 0.6675\n",
      "Epoch 434/500\n",
      "2/2 [==============================] - 1s 1s/step - loss: 0.0319 - accuracy: 1.0000 - val_loss: 1.0115 - val_accuracy: 0.6677\n",
      "Epoch 435/500\n",
      "2/2 [==============================] - 1s 532ms/step - loss: 0.0320 - accuracy: 1.0000 - val_loss: 1.0109 - val_accuracy: 0.6678\n",
      "Epoch 436/500\n",
      "2/2 [==============================] - 1s 552ms/step - loss: 0.0319 - accuracy: 1.0000 - val_loss: 1.0108 - val_accuracy: 0.6677\n",
      "Epoch 437/500\n",
      "2/2 [==============================] - 1s 941ms/step - loss: 0.0318 - accuracy: 1.0000 - val_loss: 1.0105 - val_accuracy: 0.6679\n",
      "Epoch 438/500\n",
      "2/2 [==============================] - 1s 637ms/step - loss: 0.0318 - accuracy: 1.0000 - val_loss: 1.0111 - val_accuracy: 0.6678\n",
      "Epoch 439/500\n",
      "2/2 [==============================] - 0s 477ms/step - loss: 0.0318 - accuracy: 1.0000 - val_loss: 1.0121 - val_accuracy: 0.6679\n",
      "Epoch 440/500\n",
      "2/2 [==============================] - 0s 451ms/step - loss: 0.0317 - accuracy: 1.0000 - val_loss: 1.0120 - val_accuracy: 0.6679\n",
      "Epoch 441/500\n",
      "2/2 [==============================] - 1s 561ms/step - loss: 0.0316 - accuracy: 1.0000 - val_loss: 1.0119 - val_accuracy: 0.6677\n",
      "Epoch 442/500\n",
      "2/2 [==============================] - 1s 676ms/step - loss: 0.0315 - accuracy: 1.0000 - val_loss: 1.0122 - val_accuracy: 0.6677\n",
      "Epoch 443/500\n",
      "2/2 [==============================] - 1s 661ms/step - loss: 0.0315 - accuracy: 1.0000 - val_loss: 1.0123 - val_accuracy: 0.6677\n",
      "Epoch 444/500\n",
      "2/2 [==============================] - 1s 617ms/step - loss: 0.0314 - accuracy: 1.0000 - val_loss: 1.0126 - val_accuracy: 0.6678\n",
      "Epoch 445/500\n",
      "2/2 [==============================] - 1s 496ms/step - loss: 0.0314 - accuracy: 1.0000 - val_loss: 1.0125 - val_accuracy: 0.6679\n",
      "Epoch 446/500\n",
      "2/2 [==============================] - 0s 470ms/step - loss: 0.0314 - accuracy: 1.0000 - val_loss: 1.0125 - val_accuracy: 0.6679\n",
      "Epoch 447/500\n",
      "2/2 [==============================] - 0s 466ms/step - loss: 0.0314 - accuracy: 1.0000 - val_loss: 1.0121 - val_accuracy: 0.6678\n",
      "Epoch 448/500\n",
      "2/2 [==============================] - 0s 452ms/step - loss: 0.0313 - accuracy: 1.0000 - val_loss: 1.0118 - val_accuracy: 0.6679\n",
      "Epoch 449/500\n",
      "2/2 [==============================] - 0s 461ms/step - loss: 0.0312 - accuracy: 1.0000 - val_loss: 1.0125 - val_accuracy: 0.6678\n",
      "Epoch 450/500\n",
      "2/2 [==============================] - 0s 457ms/step - loss: 0.0313 - accuracy: 1.0000 - val_loss: 1.0124 - val_accuracy: 0.6680\n",
      "Epoch 451/500\n",
      "2/2 [==============================] - 1s 535ms/step - loss: 0.0311 - accuracy: 1.0000 - val_loss: 1.0128 - val_accuracy: 0.6678\n",
      "Epoch 452/500\n",
      "2/2 [==============================] - 1s 582ms/step - loss: 0.0311 - accuracy: 1.0000 - val_loss: 1.0135 - val_accuracy: 0.6679\n",
      "Epoch 453/500\n",
      "2/2 [==============================] - 1s 566ms/step - loss: 0.0311 - accuracy: 1.0000 - val_loss: 1.0131 - val_accuracy: 0.6679\n",
      "Epoch 454/500\n",
      "2/2 [==============================] - 0s 492ms/step - loss: 0.0310 - accuracy: 1.0000 - val_loss: 1.0129 - val_accuracy: 0.6679\n",
      "Epoch 455/500\n",
      "2/2 [==============================] - 1s 511ms/step - loss: 0.0309 - accuracy: 1.0000 - val_loss: 1.0135 - val_accuracy: 0.6678\n",
      "Epoch 456/500\n",
      "2/2 [==============================] - 0s 460ms/step - loss: 0.0310 - accuracy: 1.0000 - val_loss: 1.0142 - val_accuracy: 0.6680\n",
      "Epoch 457/500\n",
      "2/2 [==============================] - 0s 464ms/step - loss: 0.0310 - accuracy: 1.0000 - val_loss: 1.0151 - val_accuracy: 0.6677\n",
      "Epoch 458/500\n",
      "2/2 [==============================] - 1s 505ms/step - loss: 0.0309 - accuracy: 1.0000 - val_loss: 1.0155 - val_accuracy: 0.6674\n",
      "Epoch 459/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 1s 542ms/step - loss: 0.0307 - accuracy: 1.0000 - val_loss: 1.0150 - val_accuracy: 0.6680\n",
      "Epoch 460/500\n",
      "2/2 [==============================] - 0s 460ms/step - loss: 0.0308 - accuracy: 1.0000 - val_loss: 1.0157 - val_accuracy: 0.6676\n",
      "Epoch 461/500\n",
      "2/2 [==============================] - 0s 462ms/step - loss: 0.0308 - accuracy: 1.0000 - val_loss: 1.0160 - val_accuracy: 0.6677\n",
      "Epoch 462/500\n",
      "2/2 [==============================] - 1s 498ms/step - loss: 0.0306 - accuracy: 1.0000 - val_loss: 1.0157 - val_accuracy: 0.6678\n",
      "Epoch 463/500\n",
      "2/2 [==============================] - 0s 465ms/step - loss: 0.0306 - accuracy: 1.0000 - val_loss: 1.0158 - val_accuracy: 0.6677\n",
      "Epoch 464/500\n",
      "2/2 [==============================] - 0s 482ms/step - loss: 0.0305 - accuracy: 1.0000 - val_loss: 1.0159 - val_accuracy: 0.6678\n",
      "Epoch 465/500\n",
      "2/2 [==============================] - 0s 457ms/step - loss: 0.0305 - accuracy: 1.0000 - val_loss: 1.0156 - val_accuracy: 0.6680\n",
      "Epoch 466/500\n",
      "2/2 [==============================] - 1s 508ms/step - loss: 0.0304 - accuracy: 1.0000 - val_loss: 1.0157 - val_accuracy: 0.6678\n",
      "Epoch 467/500\n",
      "2/2 [==============================] - 1s 560ms/step - loss: 0.0304 - accuracy: 1.0000 - val_loss: 1.0150 - val_accuracy: 0.6681\n",
      "Epoch 468/500\n",
      "2/2 [==============================] - 1s 505ms/step - loss: 0.0305 - accuracy: 1.0000 - val_loss: 1.0143 - val_accuracy: 0.6681\n",
      "Epoch 469/500\n",
      "2/2 [==============================] - 0s 443ms/step - loss: 0.0303 - accuracy: 1.0000 - val_loss: 1.0146 - val_accuracy: 0.6682\n",
      "Epoch 470/500\n",
      "2/2 [==============================] - 0s 442ms/step - loss: 0.0302 - accuracy: 1.0000 - val_loss: 1.0146 - val_accuracy: 0.6682\n",
      "Epoch 471/500\n",
      "2/2 [==============================] - 0s 473ms/step - loss: 0.0303 - accuracy: 1.0000 - val_loss: 1.0145 - val_accuracy: 0.6681\n",
      "Epoch 472/500\n",
      "2/2 [==============================] - 0s 465ms/step - loss: 0.0301 - accuracy: 1.0000 - val_loss: 1.0150 - val_accuracy: 0.6679\n",
      "Epoch 473/500\n",
      "2/2 [==============================] - 0s 476ms/step - loss: 0.0302 - accuracy: 1.0000 - val_loss: 1.0151 - val_accuracy: 0.6678\n",
      "Epoch 474/500\n",
      "2/2 [==============================] - 0s 447ms/step - loss: 0.0300 - accuracy: 1.0000 - val_loss: 1.0152 - val_accuracy: 0.6678\n",
      "Epoch 475/500\n",
      "2/2 [==============================] - 0s 441ms/step - loss: 0.0300 - accuracy: 1.0000 - val_loss: 1.0155 - val_accuracy: 0.6678\n",
      "Epoch 476/500\n",
      "2/2 [==============================] - 0s 465ms/step - loss: 0.0300 - accuracy: 1.0000 - val_loss: 1.0154 - val_accuracy: 0.6679\n",
      "Epoch 477/500\n",
      "2/2 [==============================] - 0s 451ms/step - loss: 0.0300 - accuracy: 1.0000 - val_loss: 1.0155 - val_accuracy: 0.6677\n",
      "Epoch 478/500\n",
      "2/2 [==============================] - 0s 431ms/step - loss: 0.0299 - accuracy: 1.0000 - val_loss: 1.0156 - val_accuracy: 0.6677\n",
      "Epoch 479/500\n",
      "2/2 [==============================] - 0s 440ms/step - loss: 0.0299 - accuracy: 1.0000 - val_loss: 1.0152 - val_accuracy: 0.6677\n",
      "Epoch 480/500\n",
      "2/2 [==============================] - 0s 473ms/step - loss: 0.0299 - accuracy: 1.0000 - val_loss: 1.0148 - val_accuracy: 0.6678\n",
      "Epoch 481/500\n",
      "2/2 [==============================] - 0s 495ms/step - loss: 0.0298 - accuracy: 1.0000 - val_loss: 1.0158 - val_accuracy: 0.6677\n",
      "Epoch 482/500\n",
      "2/2 [==============================] - 0s 447ms/step - loss: 0.0298 - accuracy: 1.0000 - val_loss: 1.0166 - val_accuracy: 0.6678\n",
      "Epoch 483/500\n",
      "2/2 [==============================] - 0s 438ms/step - loss: 0.0297 - accuracy: 1.0000 - val_loss: 1.0168 - val_accuracy: 0.6679\n",
      "Epoch 484/500\n",
      "2/2 [==============================] - 0s 442ms/step - loss: 0.0297 - accuracy: 1.0000 - val_loss: 1.0170 - val_accuracy: 0.6678\n",
      "Epoch 485/500\n",
      "2/2 [==============================] - 0s 489ms/step - loss: 0.0296 - accuracy: 1.0000 - val_loss: 1.0169 - val_accuracy: 0.6681\n",
      "Epoch 486/500\n",
      "2/2 [==============================] - 0s 496ms/step - loss: 0.0295 - accuracy: 1.0000 - val_loss: 1.0169 - val_accuracy: 0.6677\n",
      "Epoch 487/500\n",
      "2/2 [==============================] - 0s 461ms/step - loss: 0.0295 - accuracy: 1.0000 - val_loss: 1.0165 - val_accuracy: 0.6678\n",
      "Epoch 488/500\n",
      "2/2 [==============================] - 1s 553ms/step - loss: 0.0296 - accuracy: 1.0000 - val_loss: 1.0156 - val_accuracy: 0.6680\n",
      "Epoch 489/500\n",
      "2/2 [==============================] - 1s 631ms/step - loss: 0.0294 - accuracy: 1.0000 - val_loss: 1.0164 - val_accuracy: 0.6682\n",
      "Epoch 490/500\n",
      "2/2 [==============================] - 0s 449ms/step - loss: 0.0294 - accuracy: 1.0000 - val_loss: 1.0165 - val_accuracy: 0.6679\n",
      "Epoch 491/500\n",
      "2/2 [==============================] - 0s 471ms/step - loss: 0.0293 - accuracy: 1.0000 - val_loss: 1.0168 - val_accuracy: 0.6679\n",
      "Epoch 492/500\n",
      "2/2 [==============================] - 1s 578ms/step - loss: 0.0293 - accuracy: 1.0000 - val_loss: 1.0167 - val_accuracy: 0.6681\n",
      "Epoch 493/500\n",
      "2/2 [==============================] - 1s 595ms/step - loss: 0.0293 - accuracy: 1.0000 - val_loss: 1.0162 - val_accuracy: 0.6682\n",
      "Epoch 494/500\n",
      "2/2 [==============================] - 1s 661ms/step - loss: 0.0292 - accuracy: 1.0000 - val_loss: 1.0163 - val_accuracy: 0.6682\n",
      "Epoch 495/500\n",
      "2/2 [==============================] - 1s 639ms/step - loss: 0.0292 - accuracy: 1.0000 - val_loss: 1.0163 - val_accuracy: 0.6681\n",
      "Epoch 496/500\n",
      "2/2 [==============================] - 0s 449ms/step - loss: 0.0291 - accuracy: 1.0000 - val_loss: 1.0168 - val_accuracy: 0.6682\n",
      "Epoch 497/500\n",
      "2/2 [==============================] - 1s 520ms/step - loss: 0.0290 - accuracy: 1.0000 - val_loss: 1.0171 - val_accuracy: 0.6682\n",
      "Epoch 498/500\n",
      "2/2 [==============================] - 1s 916ms/step - loss: 0.0292 - accuracy: 1.0000 - val_loss: 1.0165 - val_accuracy: 0.6684\n",
      "Epoch 499/500\n",
      "2/2 [==============================] - 1s 758ms/step - loss: 0.0290 - accuracy: 1.0000 - val_loss: 1.0168 - val_accuracy: 0.6685\n",
      "Epoch 500/500\n",
      "2/2 [==============================] - 1s 772ms/step - loss: 0.0289 - accuracy: 1.0000 - val_loss: 1.0169 - val_accuracy: 0.6684\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1bf438e16c8>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_split.astype(\"float32\") / 255, y_split, epochs=500, validation_data=(x_test.astype(\"float32\") / 255, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3Nv-CoMpwg5l",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Сравнение фреймворков для глубокого обучения"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UBMfjH5XwpIu",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "**Tensorflow**\n",
    "\n",
    "Плюсы:\n",
    " * Поддерживает много устройств (GPU, TPU, мобильные устройства)\n",
    " * Простой deploy\n",
    " * Поглотил в себя Keras — высокоуровневую абстракцию\n",
    " * Есть методы для эффективного написания модулей на Питоне, достаточно просто писать модули на C\n",
    " * Самое большое коммьюнити\n",
    " * Дружественен к типизированию функций (свои механизмы, не mypy)\n",
    "\n",
    "Минусы:\n",
    " * Начинал со статических графов, перешел к динамическим в 2.0. Очень много устаревших примеров, путаницы в документации\n",
    " * Есть три способа сделать что-то (динамические/статические графы, керас)\n",
    " * Свой дебаггер и неудобочитаемые сообщения об ошибках\n",
    " * Собирается Bazel-ем, собрать свои C модули — головная боль\n",
    " * Сложно контролировать объем занятой GPU памяти\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RCrT_AFCyBGk",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**PyTorch**\n",
    "\n",
    "Плюсы:\n",
    " * Сразу начинал с динамических графов. Цельное API\n",
    " * Удобная документация и сообщения об ошибках\n",
    " * Консистентные абстракции среднего уровня в среде (модули)\n",
    " * Относительно удобная отладка средствами pdb (The Python Debugger)\n",
    " * Простое распараллеливание как между несколькими GPU, так и между разными машинами\n",
    "\n",
    "Минусы:\n",
    " * Не все архитектуры поддерживаются\n",
    " * Сложный deploy в production\n",
    " * Сложнее писать свои расширения для операций (например, на C)\n",
    " * API менее стабильно\n",
    " * Не дружественен к типизации\n",
    " * Использует shared memory при тренировке, что усложняет использование в облаке\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7_gIJOpu14ko",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Другие**\n",
    "\n",
    "Значительно меньшее community, а значит проблемы, с высокой вероятностью придется решать наедине с документацией."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ah6XxKJv3mgT",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Ещё пример**\n",
    "\n",
    "Обычно все не так важно :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uy-KgU0a5Kll",
    "outputId": "a636eb13-1632-470d-c704-041fde7d3375",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "\n",
    "_url = 'https://c402277.ssl.cf1.rackcdn.com/photos/14206/images/hero_full/WW187785.jpg?1576774644'\n",
    "\n",
    "with urllib.request.urlopen(_url) as link, open('elephant.jpg', mode='wb') as out:\n",
    "    out.write(link.read())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oikPv_W32dps",
    "outputId": "638a2e31-26dd-490a-d547-1b7697651df6",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels.h5\n",
      "102973440/102967424 [==============================] - 8s 0us/step\n",
      "102981632/102967424 [==============================] - 8s 0us/step\n",
      "Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/imagenet_class_index.json\n",
      "40960/35363 [==================================] - 0s 1us/step\n",
      "49152/35363 [=========================================] - 0s 1us/step\n",
      "Predicted: [('n01871265', 'tusker', 0.602945), ('n02504458', 'African_elephant', 0.37649095), ('n02504013', 'Indian_elephant', 0.019871898)]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions\n",
    "import numpy as np\n",
    "\n",
    "model = ResNet50(weights='imagenet')\n",
    "\n",
    "img_path = 'elephant.jpg'\n",
    "img = image.load_img(img_path, target_size=(224, 224))\n",
    "x = image.img_to_array(img)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "x = preprocess_input(x)\n",
    "\n",
    "preds = model.predict(x)\n",
    "# decode the results into a list of tuples (class, description, probability)\n",
    "# (one such list for each sample in the batch)\n",
    "print('Predicted:', decode_predictions(preds, top=3)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "tusker — an elephant or wild boar with well-developed tusks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0OLY-fsS3491",
    "outputId": "d7efca1c-913a-4d09-f99b-0d68e19b4983"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "\n",
    "# create the base pre-trained model\n",
    "base_model = InceptionV3(weights='imagenet', include_top=False)\n",
    "\n",
    "# add a global spatial average pooling layer\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "# let's add a fully-connected layer\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "# and a logistic layer — let's say we have 200 classes\n",
    "predictions = Dense(200, activation='softmax')(x)\n",
    "\n",
    "# this is the model we will train\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# first: train only the top layers (which were randomly initialized)\n",
    "# i.e. freeze all convolutional InceptionV3 layers\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# compile the model (should be done *after* setting layers to non-trainable)\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy')\n",
    "\n",
    "# train the model on the new data for a few epochs\n",
    "model.fit(...)\n",
    "\n",
    "# at this point, the top layers are well trained and we can start fine-tuning\n",
    "# convolutional layers from inception V3. We will freeze the bottom N layers\n",
    "# and train the remaining top layers.\n",
    "\n",
    "# let's visualize layer names and layer indices to see how many layers\n",
    "# we should freeze:\n",
    "for i, layer in enumerate(base_model.layers):\n",
    "    print(i, layer.name)\n",
    "\n",
    "# we chose to train the top 2 inception blocks, i.e. we will freeze\n",
    "# the first 249 layers and unfreeze the rest:\n",
    "for layer in model.layers[:249]:\n",
    "    layer.trainable = False\n",
    "for layer in model.layers[249:]:\n",
    "    layer.trainable = True\n",
    "\n",
    "# we need to recompile the model for these modifications to take effect\n",
    "# we use SGD with a low learning rate\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "model.compile(optimizer=SGD(lr=0.0001, momentum=0.9), loss='categorical_crossentropy')"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "rise": {
   "transition": "none"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
